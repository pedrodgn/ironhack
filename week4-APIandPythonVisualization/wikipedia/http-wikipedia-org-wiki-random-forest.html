
<!DOCTYPE html>
<html class="client-nojs" lang="en" dir="ltr">
<head>
<meta charset="UTF-8"/>
<title>Random forest - Wikipedia</title>
<script>document.documentElement.className="client-js";RLCONF={"wgBreakFrames":!1,"wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgRequestId":"da548521-a1a3-446e-8662-7f4cdb621fa7","wgCSPNonce":!1,"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":!1,"wgNamespaceNumber":0,"wgPageName":"Random_forest","wgTitle":"Random forest","wgCurRevisionId":966179730,"wgRevisionId":966179730,"wgArticleId":1363880,"wgIsArticle":!0,"wgIsRedirect":!1,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["CS1 maint: uses authors parameter","CS1 errors: missing periodical","All articles with dead external links","Articles with dead external links from May 2017","Articles with permanently dead external links","Articles with short description",
"Articles containing potentially dated statements from 2019","All articles containing potentially dated statements","Articles to be expanded from February 2019","All articles to be expanded","Classification algorithms","Ensemble learning","Decision trees","Decision theory","Computational statistics","Machine learning"],"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgRelevantPageName":"Random_forest","wgRelevantArticleId":1363880,"wgIsProbablyEditable":!0,"wgRelevantPageIsProbablyEditable":!0,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgMediaViewerOnClick":!0,"wgMediaViewerEnabledByDefault":!0,"wgPopupsReferencePreviews":!1,"wgPopupsConflictsWithNavPopupGadget":!1,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":!0,"nearby":!0,"watchlist":!0,"tagline":!1},"wgWMESchemaEditAttemptStepOversample":!1,"wgULSCurrentAutonym":"English","wgNoticeProject":
"wikipedia","wgWikibaseItemId":"Q245748","wgCentralAuthMobileDomain":!1,"wgEditSubmitButtonLabelPublish":!0,"wgULSPosition":"interlanguage"};RLSTATE={"ext.globalCssJs.user.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready","ext.globalCssJs.user":"ready","user":"ready","user.options":"loading","ext.cite.styles":"ready","ext.math.styles":"ready","skins.vector.styles.legacy":"ready","mediawiki.toc.styles":"ready","wikibase.client.init":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","ext.wikimediaBadges":"ready"};RLPAGEMODULES=["ext.cite.ux-enhancements","ext.math.scripts","site","mediawiki.page.startup","mediawiki.page.ready","mediawiki.toc","skins.vector.legacy.js","ext.gadget.ReferenceTooltips","ext.gadget.charinsert","ext.gadget.extra-toolbar-buttons","ext.gadget.refToolbar","ext.gadget.switcher","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups",
"ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.uls.compactlinks","ext.uls.interface","ext.cx.eventlogging.campaigns","ext.quicksurveys.init","ext.centralNotice.geoIP","ext.centralNotice.startUp"];</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.implement("user.options@1hzgi",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({"patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});
});});</script>
<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=ext.cite.styles%7Cext.math.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cmediawiki.toc.styles%7Cskins.vector.styles.legacy%7Cwikibase.client.init&amp;only=styles&amp;skin=vector"/>
<script async="" src="/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector"></script>
<meta name="ResourceLoaderDynamicStyles" content=""/>
<link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector"/>
<meta name="generator" content="MediaWiki 1.35.0-wmf.39"/>
<meta name="referrer" content="origin"/>
<meta name="referrer" content="origin-when-crossorigin"/>
<meta name="referrer" content="origin-when-cross-origin"/>
<link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Random_forest&amp;action=edit"/>
<link rel="edit" title="Edit this page" href="/w/index.php?title=Random_forest&amp;action=edit"/>
<link rel="apple-touch-icon" href="/static/apple-touch/wikipedia.png"/>
<link rel="shortcut icon" href="/static/favicon/wikipedia.ico"/>
<link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)"/>
<link rel="EditURI" type="application/rsd+xml" href="//en.wikipedia.org/w/api.php?action=rsd"/>
<link rel="license" href="//creativecommons.org/licenses/by-sa/3.0/"/>
<link rel="alternate" type="application/atom+xml" title="Wikipedia Atom feed" href="/w/index.php?title=Special:RecentChanges&amp;feed=atom"/>
<link rel="canonical" href="https://en.wikipedia.org/wiki/Random_forest"/>
<link rel="dns-prefetch" href="//login.wikimedia.org"/>
<link rel="dns-prefetch" href="//meta.wikimedia.org" />
<!--[if lt IE 9]><script src="/w/resources/lib/html5shiv/html5shiv.js"></script><![endif]-->
</head>
<body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Random_forest rootpage-Random_forest skin-vector action-view skin-vector-legacy minerva--history-page-action-enabled">
<div id="mw-page-base" class="noprint"></div>
<div id="mw-head-base" class="noprint"></div>
<div id="content" class="mw-body" role="main">
	<a id="top"></a>
		<div id="siteNotice" class="mw-body-content"><!-- CentralNotice --></div>
	<div class="mw-indicators mw-body-content">
	</div>
	<h1 id="firstHeading" class="firstHeading" lang="en">Random forest</h1>
	
	<div id="bodyContent" class="mw-body-content">
		<div id="siteSub" class="noprint">From Wikipedia, the free encyclopedia</div>
		<div id="contentSub"></div>
		
		
		<div id="jump-to-nav"></div>
		<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>
		<a class="mw-jump-link" href="#searchInput">Jump to search</a>
		<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div class="mw-parser-output"><div role="note" class="hatnote navigation-not-searchable">This article is about the machine learning technique. For other kinds of random tree, see <a href="/wiki/Random_tree" title="Random tree">Random tree</a>.</div>
<div class="shortdescription nomobile noexcerpt noprint searchaux" style="display:none">An ensemble machine learning method</div>
<table class="vertical-navbox nowraplinks" style="float:right;clear:right;width:22.0em;margin:0 0 1.0em 1.0em;background:#f8f9fa;border:1px solid #aaa;padding:0.2em;border-spacing:0.4em 0;text-align:center;line-height:1.4em;font-size:88%"><tbody><tr><td style="padding-top:0.4em;line-height:1.2em">Part of a series on</td></tr><tr><th style="padding:0.2em 0.4em 0.2em;padding-top:0;font-size:145%;line-height:1.2em"><a href="/wiki/Machine_learning" title="Machine learning">Machine learning</a><br />and<br /><a href="/wiki/Data_mining" title="Data mining">data mining</a></th></tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Problems</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Statistical_classification" title="Statistical classification">Classification</a></li>
<li><a href="/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></li>
<li><a href="/wiki/Regression_analysis" title="Regression analysis">Regression</a></li>
<li><a href="/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></li>
<li><a href="/wiki/Automated_machine_learning" title="Automated machine learning">AutoML</a></li>
<li><a href="/wiki/Association_rule_learning" title="Association rule learning">Association rules</a></li>
<li><a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></li>
<li><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></li>
<li><a href="/wiki/Feature_engineering" title="Feature engineering">Feature engineering</a></li>
<li><a href="/wiki/Feature_learning" title="Feature learning">Feature learning</a></li>
<li><a href="/wiki/Online_machine_learning" title="Online machine learning">Online learning</a></li>
<li><a href="/wiki/Semi-supervised_learning" title="Semi-supervised learning">Semi-supervised learning</a></li>
<li><a href="/wiki/Unsupervised_learning" title="Unsupervised learning">Unsupervised learning</a></li>
<li><a href="/wiki/Learning_to_rank" title="Learning to rank">Learning to rank</a></li>
<li><a href="/wiki/Grammar_induction" title="Grammar induction">Grammar induction</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><div style="padding:0.1em 0;line-height:1.2em;"><a href="/wiki/Supervised_learning" title="Supervised learning">Supervised learning</a><br /><style data-mw-deduplicate="TemplateStyles:r886047488">.mw-parser-output .nobold{font-weight:normal}</style><span class="nobold"><span style="font-size:85%;">(<b><a href="/wiki/Statistical_classification" title="Statistical classification">classification</a></b>&#160;&#8226;&#32;<b><a href="/wiki/Regression_analysis" title="Regression analysis">regression</a></b>)</span></span> </div></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Decision_tree_learning" title="Decision tree learning">Decision trees</a></li>
<li><a href="/wiki/Ensemble_learning" title="Ensemble learning">Ensembles</a>
<ul><li><a href="/wiki/Bootstrap_aggregating" title="Bootstrap aggregating">Bagging</a></li>
<li><a href="/wiki/Boosting_(machine_learning)" title="Boosting (machine learning)">Boosting</a></li>
<li><a class="mw-selflink selflink">Random forest</a></li></ul></li>
<li><a href="/wiki/K-nearest_neighbors_algorithm" title="K-nearest neighbors algorithm"><i>k</i>-NN</a></li>
<li><a href="/wiki/Linear_regression" title="Linear regression">Linear regression</a></li>
<li><a href="/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier">Naive Bayes</a></li>
<li><a href="/wiki/Artificial_neural_network" title="Artificial neural network">Artificial neural networks</a></li>
<li><a href="/wiki/Logistic_regression" title="Logistic regression">Logistic regression</a></li>
<li><a href="/wiki/Perceptron" title="Perceptron">Perceptron</a></li>
<li><a href="/wiki/Relevance_vector_machine" title="Relevance vector machine">Relevance vector machine (RVM)</a></li>
<li><a href="/wiki/Support-vector_machine" class="mw-redirect" title="Support-vector machine">Support vector machine (SVM)</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Cluster_analysis" title="Cluster analysis">Clustering</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/BIRCH" title="BIRCH">BIRCH</a></li>
<li><a href="/wiki/CURE_data_clustering_algorithm" class="mw-redirect" title="CURE data clustering algorithm">CURE</a></li>
<li><a href="/wiki/Hierarchical_clustering" title="Hierarchical clustering">Hierarchical</a></li>
<li><a href="/wiki/K-means_clustering" title="K-means clustering"><i>k</i>-means</a></li>
<li><a href="/wiki/Expectation%E2%80%93maximization_algorithm" title="Expectation–maximization algorithm">Expectation–maximization (EM)</a></li>
<li><br /><a href="/wiki/DBSCAN" title="DBSCAN">DBSCAN</a></li>
<li><a href="/wiki/OPTICS_algorithm" title="OPTICS algorithm">OPTICS</a></li>
<li><a href="/wiki/Mean-shift" class="mw-redirect" title="Mean-shift">Mean-shift</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Dimensionality_reduction" title="Dimensionality reduction">Dimensionality reduction</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Factor_analysis" title="Factor analysis">Factor analysis</a></li>
<li><a href="/wiki/Canonical_correlation" title="Canonical correlation">CCA</a></li>
<li><a href="/wiki/Independent_component_analysis" title="Independent component analysis">ICA</a></li>
<li><a href="/wiki/Linear_discriminant_analysis" title="Linear discriminant analysis">LDA</a></li>
<li><a href="/wiki/Non-negative_matrix_factorization" title="Non-negative matrix factorization">NMF</a></li>
<li><a href="/wiki/Principal_component_analysis" title="Principal component analysis">PCA</a></li>
<li><a href="/wiki/Proper_generalized_decomposition" title="Proper generalized decomposition">PGD</a></li>
<li><a href="/wiki/T-distributed_stochastic_neighbor_embedding" title="T-distributed stochastic neighbor embedding">t-SNE</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Structured_prediction" title="Structured prediction">Structured prediction</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Graphical_model" title="Graphical model">Graphical models</a>
<ul><li><a href="/wiki/Bayesian_network" title="Bayesian network">Bayes net</a></li>
<li><a href="/wiki/Conditional_random_field" title="Conditional random field">Conditional random field</a></li>
<li><a href="/wiki/Hidden_Markov_model" title="Hidden Markov model">Hidden Markov</a></li></ul></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Anomaly_detection" title="Anomaly detection">Anomaly detection</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/K-nearest_neighbors_classification" class="mw-redirect" title="K-nearest neighbors classification"><i>k</i>-NN</a></li>
<li><a href="/wiki/Local_outlier_factor" title="Local outlier factor">Local outlier factor</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Artificial_neural_network" title="Artificial neural network">Artificial neural network</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Autoencoder" title="Autoencoder">Autoencoder</a></li>
<li><a href="/wiki/Deep_learning" title="Deep learning">Deep learning</a></li>
<li><a href="/wiki/DeepDream" title="DeepDream">DeepDream</a></li>
<li><a href="/wiki/Multilayer_perceptron" title="Multilayer perceptron">Multilayer perceptron</a></li>
<li><a href="/wiki/Recurrent_neural_network" title="Recurrent neural network">RNN</a>
<ul><li><a href="/wiki/Long_short-term_memory" title="Long short-term memory">LSTM</a></li>
<li><a href="/wiki/Gated_recurrent_unit" title="Gated recurrent unit">GRU</a></li></ul></li>
<li><a href="/wiki/Restricted_Boltzmann_machine" title="Restricted Boltzmann machine">Restricted Boltzmann machine</a></li>
<li><a href="/wiki/Generative_adversarial_network" title="Generative adversarial network">GAN</a></li>
<li><a href="/wiki/Self-organizing_map" title="Self-organizing map">SOM</a></li>
<li><a href="/wiki/Convolutional_neural_network" title="Convolutional neural network">Convolutional neural network</a>
<ul><li><a href="/wiki/U-Net" title="U-Net">U-Net</a></li></ul></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Reinforcement_learning" title="Reinforcement learning">Reinforcement learning</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Q-learning" title="Q-learning">Q-learning</a></li>
<li><a href="/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action" title="State–action–reward–state–action">SARSA</a></li>
<li><a href="/wiki/Temporal_difference_learning" title="Temporal difference learning">Temporal difference (TD)</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Theory</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Bias%E2%80%93variance_dilemma" class="mw-redirect" title="Bias–variance dilemma">Bias–variance dilemma</a></li>
<li><a href="/wiki/Computational_learning_theory" title="Computational learning theory">Computational learning theory</a></li>
<li><a href="/wiki/Empirical_risk_minimization" title="Empirical risk minimization">Empirical risk minimization</a></li>
<li><a href="/wiki/Occam_learning" title="Occam learning">Occam learning</a></li>
<li><a href="/wiki/Probably_approximately_correct_learning" title="Probably approximately correct learning">PAC learning</a></li>
<li><a href="/wiki/Statistical_learning_theory" title="Statistical learning theory">Statistical learning</a></li>
<li><a href="/wiki/Vapnik%E2%80%93Chervonenkis_theory" title="Vapnik–Chervonenkis theory">VC theory</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Machine-learning venues</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Conference_on_Neural_Information_Processing_Systems" title="Conference on Neural Information Processing Systems">NeurIPS</a></li>
<li><a href="/wiki/International_Conference_on_Machine_Learning" title="International Conference on Machine Learning">ICML</a></li>
<li><a href="/wiki/Machine_Learning_(journal)" title="Machine Learning (journal)">ML</a></li>
<li><a href="/wiki/Journal_of_Machine_Learning_Research" title="Journal of Machine Learning Research">JMLR</a></li>
<li><a rel="nofollow" class="external text" href="https://arxiv.org/list/cs.LG/recent">ArXiv:cs.LG</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left"><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/Glossary_of_artificial_intelligence" title="Glossary of artificial intelligence">Glossary of artificial intelligence</a></li></ul>
</div></div></div></td>
</tr><tr><td style="padding:0 0.1em 0.4em">
<div class="NavFrame collapsed" style="border:none;padding:0"><div class="NavHead" style="font-size:105%;background:transparent;text-align:left">Related articles</div><div class="NavContent" style="font-size:105%;padding:0.2em 0 0.4em;text-align:center"><div class="hlist">
<ul><li><a href="/wiki/List_of_datasets_for_machine-learning_research" title="List of datasets for machine-learning research">List of datasets for machine-learning research</a></li>
<li><a href="/wiki/Outline_of_machine_learning" title="Outline of machine learning">Outline of machine learning</a></li></ul>
</div></div></div></td>
</tr><tr><td style="text-align:right;font-size:115%;padding-top: 0.6em;"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/Template:Machine_learning_bar" title="Template:Machine learning bar"><abbr title="View this template">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Machine_learning_bar" title="Template talk:Machine learning bar"><abbr title="Discuss this template">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Machine_learning_bar&amp;action=edit"><abbr title="Edit this template">e</abbr></a></li></ul></div></td></tr></tbody></table>
<p><b>Random forests</b> or <b>random decision forests</b> are an <a href="/wiki/Ensemble_learning" title="Ensemble learning">ensemble learning</a> method for <a href="/wiki/Statistical_classification" title="Statistical classification">classification</a>, <a href="/wiki/Regression_analysis" title="Regression analysis">regression</a> and other tasks that operate by constructing a multitude of <a href="/wiki/Decision_tree_learning" title="Decision tree learning">decision trees</a> at training time and outputting the class that is the <a href="/wiki/Mode_(statistics)" title="Mode (statistics)">mode</a> of the classes (classification) or mean prediction (regression) of the individual trees.<sup id="cite_ref-ho1995_1-0" class="reference"><a href="#cite_note-ho1995-1">&#91;1&#93;</a></sup><sup id="cite_ref-ho1998_2-0" class="reference"><a href="#cite_note-ho1998-2">&#91;2&#93;</a></sup> Random decision forests correct for decision trees' habit of <a href="/wiki/Overfitting" title="Overfitting">overfitting</a> to their <a href="/wiki/Test_set" class="mw-redirect" title="Test set">training set</a>.<sup id="cite_ref-elemstatlearn_3-0" class="reference"><a href="#cite_note-elemstatlearn-3">&#91;3&#93;</a></sup><sup class="reference" style="white-space:nowrap;">:<span>587–588</span></sup>
</p><p>The first algorithm for random decision forests was created by <a href="/wiki/Tin_Kam_Ho" title="Tin Kam Ho">Tin Kam Ho</a><sup id="cite_ref-ho1995_1-1" class="reference"><a href="#cite_note-ho1995-1">&#91;1&#93;</a></sup> using the <a href="/wiki/Random_subspace_method" title="Random subspace method">random subspace method</a>,<sup id="cite_ref-ho1998_2-1" class="reference"><a href="#cite_note-ho1998-2">&#91;2&#93;</a></sup> which, in Ho's formulation, is a way to implement the "stochastic discrimination" approach to classification proposed by Eugene Kleinberg.<sup id="cite_ref-kleinberg1990_4-0" class="reference"><a href="#cite_note-kleinberg1990-4">&#91;4&#93;</a></sup><sup id="cite_ref-kleinberg1996_5-0" class="reference"><a href="#cite_note-kleinberg1996-5">&#91;5&#93;</a></sup><sup id="cite_ref-kleinberg2000_6-0" class="reference"><a href="#cite_note-kleinberg2000-6">&#91;6&#93;</a></sup>
</p><p>An extension of the algorithm was developed by <a href="/wiki/Leo_Breiman" title="Leo Breiman">Leo Breiman</a><sup id="cite_ref-breiman2001_7-0" class="reference"><a href="#cite_note-breiman2001-7">&#91;7&#93;</a></sup> and <a href="/wiki/Adele_Cutler" title="Adele Cutler">Adele Cutler</a>,<sup id="cite_ref-rpackage_8-0" class="reference"><a href="#cite_note-rpackage-8">&#91;8&#93;</a></sup> who registered<sup id="cite_ref-9" class="reference"><a href="#cite_note-9">&#91;9&#93;</a></sup> "Random Forests" as a <a href="/wiki/Trademark" title="Trademark">trademark</a> (as of 2019<sup class="plainlinks noexcerpt noprint asof-tag update" style="display:none;"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Random_forest&amp;action=edit">&#91;update&#93;</a></sup>, owned by <a href="/wiki/Minitab" title="Minitab">Minitab, Inc.</a>).<sup id="cite_ref-10" class="reference"><a href="#cite_note-10">&#91;10&#93;</a></sup> The extension combines Breiman's "<a href="/wiki/Bootstrap_aggregating" title="Bootstrap aggregating">bagging</a>" idea and random selection of features, introduced first by Ho<sup id="cite_ref-ho1995_1-2" class="reference"><a href="#cite_note-ho1995-1">&#91;1&#93;</a></sup> and later independently by Amit and <a href="/wiki/Donald_Geman" title="Donald Geman">Geman</a><sup id="cite_ref-amitgeman1997_11-0" class="reference"><a href="#cite_note-amitgeman1997-11">&#91;11&#93;</a></sup> in order to construct a collection of decision trees with controlled variance.
</p>
<div id="toc" class="toc" role="navigation" aria-labelledby="mw-toc-heading"><input type="checkbox" role="button" id="toctogglecheckbox" class="toctogglecheckbox" style="display:none" /><div class="toctitle" lang="en" dir="ltr"><h2 id="mw-toc-heading">Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#History"><span class="tocnumber">1</span> <span class="toctext">History</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#Algorithm"><span class="tocnumber">2</span> <span class="toctext">Algorithm</span></a>
<ul>
<li class="toclevel-2 tocsection-3"><a href="#Preliminaries:_decision_tree_learning"><span class="tocnumber">2.1</span> <span class="toctext">Preliminaries: decision tree learning</span></a></li>
<li class="toclevel-2 tocsection-4"><a href="#Bagging"><span class="tocnumber">2.2</span> <span class="toctext">Bagging</span></a></li>
<li class="toclevel-2 tocsection-5"><a href="#From_bagging_to_random_forests"><span class="tocnumber">2.3</span> <span class="toctext">From bagging to random forests</span></a></li>
<li class="toclevel-2 tocsection-6"><a href="#ExtraTrees"><span class="tocnumber">2.4</span> <span class="toctext">ExtraTrees</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-7"><a href="#Properties"><span class="tocnumber">3</span> <span class="toctext">Properties</span></a>
<ul>
<li class="toclevel-2 tocsection-8"><a href="#Variable_importance"><span class="tocnumber">3.1</span> <span class="toctext">Variable importance</span></a></li>
<li class="toclevel-2 tocsection-9"><a href="#Relationship_to_nearest_neighbors"><span class="tocnumber">3.2</span> <span class="toctext">Relationship to nearest neighbors</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-10"><a href="#Unsupervised_learning_with_random_forests"><span class="tocnumber">4</span> <span class="toctext">Unsupervised learning with random forests</span></a></li>
<li class="toclevel-1 tocsection-11"><a href="#Variants"><span class="tocnumber">5</span> <span class="toctext">Variants</span></a></li>
<li class="toclevel-1 tocsection-12"><a href="#Kernel_random_forest"><span class="tocnumber">6</span> <span class="toctext">Kernel random forest</span></a>
<ul>
<li class="toclevel-2 tocsection-13"><a href="#History_2"><span class="tocnumber">6.1</span> <span class="toctext">History</span></a></li>
<li class="toclevel-2 tocsection-14"><a href="#Notations_and_definitions"><span class="tocnumber">6.2</span> <span class="toctext">Notations and definitions</span></a>
<ul>
<li class="toclevel-3 tocsection-15"><a href="#Preliminaries:_Centered_forests"><span class="tocnumber">6.2.1</span> <span class="toctext">Preliminaries: Centered forests</span></a></li>
<li class="toclevel-3 tocsection-16"><a href="#Uniform_forest"><span class="tocnumber">6.2.2</span> <span class="toctext">Uniform forest</span></a></li>
<li class="toclevel-3 tocsection-17"><a href="#From_random_forest_to_KeRF"><span class="tocnumber">6.2.3</span> <span class="toctext">From random forest to KeRF</span></a></li>
<li class="toclevel-3 tocsection-18"><a href="#Centered_KeRF"><span class="tocnumber">6.2.4</span> <span class="toctext">Centered KeRF</span></a></li>
<li class="toclevel-3 tocsection-19"><a href="#Uniform_KeRF"><span class="tocnumber">6.2.5</span> <span class="toctext">Uniform KeRF</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-20"><a href="#Properties_2"><span class="tocnumber">6.3</span> <span class="toctext">Properties</span></a>
<ul>
<li class="toclevel-3 tocsection-21"><a href="#Relation_between_KeRF_and_random_forest"><span class="tocnumber">6.3.1</span> <span class="toctext">Relation between KeRF and random forest</span></a></li>
<li class="toclevel-3 tocsection-22"><a href="#Relation_between_infinite_KeRF_and_infinite_random_forest"><span class="tocnumber">6.3.2</span> <span class="toctext">Relation between infinite KeRF and infinite random forest</span></a></li>
</ul>
</li>
<li class="toclevel-2 tocsection-23"><a href="#Consistency_results"><span class="tocnumber">6.4</span> <span class="toctext">Consistency results</span></a>
<ul>
<li class="toclevel-3 tocsection-24"><a href="#Consistency_of_centered_KeRF"><span class="tocnumber">6.4.1</span> <span class="toctext">Consistency of centered KeRF</span></a></li>
<li class="toclevel-3 tocsection-25"><a href="#Consistency_of_uniform_KeRF"><span class="tocnumber">6.4.2</span> <span class="toctext">Consistency of uniform KeRF</span></a></li>
</ul>
</li>
</ul>
</li>
<li class="toclevel-1 tocsection-26"><a href="#RF_in_scientific_works"><span class="tocnumber">7</span> <span class="toctext">RF in scientific works</span></a></li>
<li class="toclevel-1 tocsection-27"><a href="#Open_source_implementations"><span class="tocnumber">8</span> <span class="toctext">Open source implementations</span></a></li>
<li class="toclevel-1 tocsection-28"><a href="#See_also"><span class="tocnumber">9</span> <span class="toctext">See also</span></a></li>
<li class="toclevel-1 tocsection-29"><a href="#References"><span class="tocnumber">10</span> <span class="toctext">References</span></a></li>
<li class="toclevel-1 tocsection-30"><a href="#Further_reading"><span class="tocnumber">11</span> <span class="toctext">Further reading</span></a></li>
<li class="toclevel-1 tocsection-31"><a href="#External_links"><span class="tocnumber">12</span> <span class="toctext">External links</span></a></li>
</ul>
</div>

<h2><span class="mw-headline" id="History">History</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=1" title="Edit section: History">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>The general method of random decision forests was first proposed by Ho in 1995.<sup id="cite_ref-ho1995_1-3" class="reference"><a href="#cite_note-ho1995-1">&#91;1&#93;</a></sup> Ho established that forests of trees splitting with oblique hyperplanes can gain accuracy as they grow without suffering from overtraining, as long as the forests are randomly restricted to be sensitive to only selected <a href="/wiki/Feature_(machine_learning)" title="Feature (machine learning)">feature</a> dimensions.  A subsequent work along the same lines<sup id="cite_ref-ho1998_2-2" class="reference"><a href="#cite_note-ho1998-2">&#91;2&#93;</a></sup> concluded that other splitting methods behave similarly, as long as they are randomly forced to be insensitive to some feature dimensions.  Note that this observation of a more complex classifier (a larger forest) getting more accurate nearly monotonically is in sharp contrast to the common belief that the complexity of a classifier can only grow to a certain level of accuracy before being hurt by overfitting.  The explanation of the forest method's resistance to overtraining can be found in Kleinberg's theory of stochastic discrimination.<sup id="cite_ref-kleinberg1990_4-1" class="reference"><a href="#cite_note-kleinberg1990-4">&#91;4&#93;</a></sup><sup id="cite_ref-kleinberg1996_5-1" class="reference"><a href="#cite_note-kleinberg1996-5">&#91;5&#93;</a></sup><sup id="cite_ref-kleinberg2000_6-1" class="reference"><a href="#cite_note-kleinberg2000-6">&#91;6&#93;</a></sup>
</p><p>The early development of Breiman's notion of random forests was influenced by the work of Amit and
Geman<sup id="cite_ref-amitgeman1997_11-1" class="reference"><a href="#cite_note-amitgeman1997-11">&#91;11&#93;</a></sup> who introduced the idea of searching over a random subset of the
available decisions when splitting a node, in the context of growing a single
<a href="/wiki/Decision_tree" title="Decision tree">tree</a>.  The idea of random subspace selection from Ho<sup id="cite_ref-ho1998_2-3" class="reference"><a href="#cite_note-ho1998-2">&#91;2&#93;</a></sup> was also influential in the design of random forests.  In this method a forest of trees is grown,
and variation among the trees is introduced by projecting the training data
into a randomly chosen <a href="/wiki/Linear_subspace" title="Linear subspace">subspace</a> before fitting each tree or each node.  Finally, the idea of
randomized node optimization, where the decision at each node is selected by a
randomized procedure, rather than a deterministic optimization was first
introduced by Dietterich.<sup id="cite_ref-12" class="reference"><a href="#cite_note-12">&#91;12&#93;</a></sup>
</p><p>The introduction of random forests proper was first made in a paper
by <a href="/wiki/Leo_Breiman" title="Leo Breiman">Leo Breiman</a>.<sup id="cite_ref-breiman2001_7-1" class="reference"><a href="#cite_note-breiman2001-7">&#91;7&#93;</a></sup>  This paper describes a method of building a forest of
uncorrelated trees using a <a href="/wiki/Classification_and_regression_tree" class="mw-redirect" title="Classification and regression tree">CART</a> like procedure, combined with randomized node
optimization and <a href="/wiki/Bootstrap_aggregating" title="Bootstrap aggregating">bagging</a>.  In addition, this paper combines several
ingredients, some previously known and some novel, which form the basis of the
modern practice of random forests, in particular:
</p>
<ol><li>Using <a href="/wiki/Out-of-bag_error" title="Out-of-bag error">out-of-bag error</a> as an estimate of the <a href="/wiki/Generalization_error" title="Generalization error">generalization error</a>.</li>
<li>Measuring variable importance through permutation.</li></ol>
<p>The report also offers the first theoretical result for random forests in the
form of a bound on the <a href="/wiki/Generalization_error" title="Generalization error">generalization error</a> which depends on the strength of the
trees in the forest and their <a href="/wiki/Correlation" class="mw-redirect" title="Correlation">correlation</a>.
</p>
<h2><span class="mw-headline" id="Algorithm">Algorithm</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=2" title="Edit section: Algorithm">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span class="mw-headline" id="Preliminaries:_decision_tree_learning">Preliminaries: decision tree learning</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=3" title="Edit section: Preliminaries: decision tree learning">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Decision_tree_learning" title="Decision tree learning">Decision tree learning</a></div>
<p>Decision trees are a popular method for various machine learning tasks. Tree learning "come[s] closest to meeting the requirements for serving as an off-the-shelf procedure for data mining", say <a href="/wiki/Trevor_Hastie" title="Trevor Hastie">Hastie</a> <i>et al.</i>, "because it is invariant under scaling and various other transformations of feature values, is robust to inclusion of irrelevant features, and produces inspectable models. However, they are seldom accurate".<sup id="cite_ref-elemstatlearn_3-1" class="reference"><a href="#cite_note-elemstatlearn-3">&#91;3&#93;</a></sup><sup class="reference" style="white-space:nowrap;">:<span>352</span></sup>
</p><p>In particular, trees that are grown very deep tend to learn highly irregular patterns: they <a href="/wiki/Overfitting" title="Overfitting">overfit</a> their training sets, i.e. have <a href="/wiki/Bias%E2%80%93variance_tradeoff" title="Bias–variance tradeoff">low bias, but very high variance</a>. Random forests are a way of averaging multiple deep decision trees, trained on different parts of the same training set, with the goal of reducing the variance.<sup id="cite_ref-elemstatlearn_3-2" class="reference"><a href="#cite_note-elemstatlearn-3">&#91;3&#93;</a></sup><sup class="reference" style="white-space:nowrap;">:<span>587–588</span></sup> This comes at the expense of a small increase in the bias and some loss of interpretability, but generally greatly boosts the performance in the final model.
</p><p>Forests are like the pulling together of decision tree algorithm efforts. Taking the teamwork of many trees thus improving the performance of a single random tree. Though not quite similar, forests give the effects of a K-fold cross validation.
</p>
<h3><span class="mw-headline" id="Bagging">Bagging</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=4" title="Edit section: Bagging">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Bootstrap_aggregating" title="Bootstrap aggregating">Bootstrap aggregating</a></div>
<p>The training algorithm for random forests applies the general technique of <a href="/wiki/Bootstrap_aggregating" title="Bootstrap aggregating">bootstrap aggregating</a>, or bagging, to tree learners. Given a training set <span class="texhtml mvar" style="font-style:italic;">X</span> = <span class="texhtml mvar" style="font-style:italic;">x<sub>1</sub></span>, ..., <span class="texhtml mvar" style="font-style:italic;">x<sub>n</sub></span> with responses <span class="texhtml mvar" style="font-style:italic;">Y</span> = <span class="texhtml mvar" style="font-style:italic;">y<sub>1</sub></span>, ..., <span class="texhtml mvar" style="font-style:italic;">y<sub>n</sub></span>, bagging repeatedly (<i>B</i> times) selects a <a href="/wiki/Sampling_(statistics)#Replacement_of_selected_units" title="Sampling (statistics)">random sample with replacement</a> of the training set and fits trees to these samples:
</p>
<dl><dd>For <span class="texhtml mvar" style="font-style:italic;">b</span> = 1, ..., <span class="texhtml mvar" style="font-style:italic;">B</span>:
<ol><li>Sample, with replacement, <span class="texhtml mvar" style="font-style:italic;">n</span> training examples from <span class="texhtml mvar" style="font-style:italic;">X</span>, <span class="texhtml mvar" style="font-style:italic;">Y</span>; call these <span class="texhtml mvar" style="font-style:italic;">X<sub>b</sub></span>, <span class="texhtml mvar" style="font-style:italic;">Y<sub>b</sub></span>.</li>
<li>Train a classification or regression tree <span class="texhtml mvar" style="font-style:italic;">f<sub>b</sub></span> on <span class="texhtml mvar" style="font-style:italic;">X<sub>b</sub></span>, <span class="texhtml mvar" style="font-style:italic;">Y<sub>b</sub></span>.</li></ol></dd></dl>
<p>After training, predictions for unseen samples <span class="texhtml mvar" style="font-style:italic;">x'</span> can be made by averaging the predictions from all the individual regression trees on <span class="texhtml mvar" style="font-style:italic;">x'</span>:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\hat {f}}={\frac {1}{B}}\sum _{b=1}^{B}f_{b}(x')}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>f</mi>
              <mo stretchy="false">&#x005E;<!-- ^ --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <mi>B</mi>
          </mfrac>
        </mrow>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>b</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>B</mi>
          </mrow>
        </munderover>
        <msub>
          <mi>f</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>b</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <msup>
          <mi>x</mi>
          <mo>&#x2032;</mo>
        </msup>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\hat {f}}={\frac {1}{B}}\sum _{b=1}^{B}f_{b}(x')}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b54befce12aefdb29442bfc71cb5ad452364e8d8" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.005ex; width:17.427ex; height:7.343ex;" alt="{\displaystyle {\hat {f}}={\frac {1}{B}}\sum _{b=1}^{B}f_{b}(x&#039;)}"/></span></dd></dl>
<p>or by taking the majority vote in the case of classification trees.
</p><p>This bootstrapping procedure leads to better model performance because it decreases the <a href="/wiki/Bias%E2%80%93variance_dilemma" class="mw-redirect" title="Bias–variance dilemma">variance</a> of the model, without increasing the bias. This means that while the predictions of a single tree are highly sensitive to noise in its training set, the average of many trees is not, as long as the trees are not correlated. Simply training many trees on a single training set would give strongly correlated trees (or even the same tree many times, if the training algorithm is deterministic); bootstrap sampling is a way of de-correlating the trees by showing them different training sets.
</p><p>Additionally, an estimate of the uncertainty of the prediction can be made as the standard deviation of the predictions from all the individual regression trees on <span class="texhtml mvar" style="font-style:italic;">x'</span>:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \sigma ={\sqrt {\frac {\sum _{b=1}^{B}(f_{b}(x')-{\hat {f}})^{2}}{B-1}}}.}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>&#x03C3;<!-- σ --></mi>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <msqrt>
            <mfrac>
              <mrow>
                <munderover>
                  <mo>&#x2211;<!-- ∑ --></mo>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>b</mi>
                    <mo>=</mo>
                    <mn>1</mn>
                  </mrow>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>B</mi>
                  </mrow>
                </munderover>
                <mo stretchy="false">(</mo>
                <msub>
                  <mi>f</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>b</mi>
                  </mrow>
                </msub>
                <mo stretchy="false">(</mo>
                <msup>
                  <mi>x</mi>
                  <mo>&#x2032;</mo>
                </msup>
                <mo stretchy="false">)</mo>
                <mo>&#x2212;<!-- − --></mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow class="MJX-TeXAtom-ORD">
                    <mover>
                      <mi>f</mi>
                      <mo stretchy="false">&#x005E;<!-- ^ --></mo>
                    </mover>
                  </mrow>
                </mrow>
                <msup>
                  <mo stretchy="false">)</mo>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn>2</mn>
                  </mrow>
                </msup>
              </mrow>
              <mrow>
                <mi>B</mi>
                <mo>&#x2212;<!-- − --></mo>
                <mn>1</mn>
              </mrow>
            </mfrac>
          </msqrt>
        </mrow>
        <mo>.</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \sigma ={\sqrt {\frac {\sum _{b=1}^{B}(f_{b}(x')-{\hat {f}})^{2}}{B-1}}}.}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/11e64a440f8625c492d848b38785f833a5882432" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.671ex; width:27.03ex; height:7.676ex;" alt="{\displaystyle \sigma ={\sqrt {\frac {\sum _{b=1}^{B}(f_{b}(x&#039;)-{\hat {f}})^{2}}{B-1}}}.}"/></span></dd></dl>
<p>The number of samples/trees, <span class="texhtml mvar" style="font-style:italic;">B</span>, is a free parameter. Typically, a few hundred to several thousand trees are used, depending on the size and nature of the training set. An optimal number of trees <span class="texhtml mvar" style="font-style:italic;">B</span> can be found using <a href="/wiki/Cross-validation_(statistics)" title="Cross-validation (statistics)">cross-validation</a>, or by observing the <i><a href="/wiki/Out-of-bag_error" title="Out-of-bag error">out-of-bag error</a></i>: the mean prediction error on each training sample <span class="texhtml mvar" style="font-style:italic;">xᵢ</span>, using only the trees that did not have <span class="texhtml mvar" style="font-style:italic;">xᵢ</span> in their bootstrap sample.<sup id="cite_ref-islr_13-0" class="reference"><a href="#cite_note-islr-13">&#91;13&#93;</a></sup>
The training and test error tend to level off after some number of trees have been fit.
</p>
<h3><span class="mw-headline" id="From_bagging_to_random_forests">From bagging to random forests</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=5" title="Edit section: From bagging to random forests">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Random_subspace_method" title="Random subspace method">Random subspace method</a></div>
<p>The above procedure describes the original bagging algorithm for trees. Random forests differ in only one way from this general scheme: they use a modified tree learning algorithm that selects, at each candidate split in the learning process, a <a href="/wiki/Random_subspace_method" title="Random subspace method">random subset of the features</a>. This process is sometimes called "feature bagging". The reason for doing this is the correlation of the trees in an ordinary bootstrap sample: if one or a few <a href="/wiki/Feature_(machine_learning)" title="Feature (machine learning)">features</a> are very strong predictors for the response variable (target output), these features will be selected in many of the <span class="texhtml mvar" style="font-style:italic;">B</span> trees, causing them to become correlated. An analysis of how bagging and random subspace projection contribute to accuracy gains under different conditions is given by Ho.<sup id="cite_ref-ho2002_14-0" class="reference"><a href="#cite_note-ho2002-14">&#91;14&#93;</a></sup>
</p><p>Typically, for a classification problem with <span class="texhtml mvar" style="font-style:italic;">p</span> features, <span class="nowrap">&#8730;<span style="border-top:1px solid; padding:0 0.1em;"><span class="texhtml mvar" style="font-style:italic;">p</span></span></span> (rounded down) features are used in each split.<sup id="cite_ref-elemstatlearn_3-3" class="reference"><a href="#cite_note-elemstatlearn-3">&#91;3&#93;</a></sup><sup class="reference" style="white-space:nowrap;">:<span>592</span></sup>  For regression problems the inventors recommend <span class="texhtml mvar" style="font-style:italic;">p/3</span> (rounded down) with a minimum node size of 5 as the default.<sup id="cite_ref-elemstatlearn_3-4" class="reference"><a href="#cite_note-elemstatlearn-3">&#91;3&#93;</a></sup><sup class="reference" style="white-space:nowrap;">:<span>592</span></sup> In practice the best values for these parameters will depend on the problem, and they should be treated as tuning parameters.<sup id="cite_ref-elemstatlearn_3-5" class="reference"><a href="#cite_note-elemstatlearn-3">&#91;3&#93;</a></sup><sup class="reference" style="white-space:nowrap;">:<span>592</span></sup>
</p>
<h3><span class="mw-headline" id="ExtraTrees">ExtraTrees</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=6" title="Edit section: ExtraTrees">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Adding one further step of randomization yields <i>extremely randomized trees</i>, or ExtraTrees. While similar to ordinary random forests in that they are an ensemble of individual trees, there are two main differences: first, each tree is trained using the whole learning sample (rather than a bootstrap sample), and second, the top-down splitting in the tree learner is randomized. Instead of computing the locally <i>optimal</i> cut-point for each feature under consideration (based on, e.g., <a href="/wiki/Information_gain" class="mw-redirect" title="Information gain">information gain</a> or the <a href="/wiki/Gini_impurity" class="mw-redirect" title="Gini impurity">Gini impurity</a>), a <i>random</i> cut-point is selected. This value is selected from a uniform distribution within the feature's empirical range (in the tree's training set). Then, of all the randomly generated splits, the split that yields the highest score is chosen to split the node. Similar to ordinary random forests, the number of randomly selected features to be considered at each node can be specified. Default values for this parameter are <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\sqrt {p}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <msqrt>
            <mi>p</mi>
          </msqrt>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\sqrt {p}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0527785cd1ad7fa60789e172c720affdcdb28b7f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.171ex; width:3.105ex; height:3.009ex;" alt="{\sqrt {p}}"/></span> for classification and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/81eac1e205430d1f40810df36a0edffdc367af36" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; margin-left: -0.089ex; width:1.259ex; height:2.009ex;" alt="p"/></span> for regression, where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle p}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>p</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle p}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/81eac1e205430d1f40810df36a0edffdc367af36" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; margin-left: -0.089ex; width:1.259ex; height:2.009ex;" alt="p"/></span> is the number of features in the model.<sup id="cite_ref-15" class="reference"><a href="#cite_note-15">&#91;15&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Properties">Properties</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=7" title="Edit section: Properties">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<h3><span class="mw-headline" id="Variable_importance">Variable importance</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=8" title="Edit section: Variable importance">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Random forests can be used to rank the importance of variables in a regression or classification problem in a natural way.  The following technique was described in Breiman's original paper<sup id="cite_ref-breiman2001_7-2" class="reference"><a href="#cite_note-breiman2001-7">&#91;7&#93;</a></sup> and is implemented in the <a href="/wiki/R_(programming_language)" title="R (programming language)">R</a> package randomForest.<sup id="cite_ref-rpackage_8-1" class="reference"><a href="#cite_note-rpackage-8">&#91;8&#93;</a></sup>
</p><p>The first step in measuring the variable importance in a data set <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\mathcal {D}}_{n}=\{(X_{i},Y_{i})\}_{i=1}^{n}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mi class="MJX-tex-caligraphic" mathvariant="script">D</mi>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo>=</mo>
        <mo fence="false" stretchy="false">{</mo>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>X</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mi>Y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <msubsup>
          <mo fence="false" stretchy="false">}</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msubsup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\mathcal {D}}_{n}=\{(X_{i},Y_{i})\}_{i=1}^{n}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ee98824c21c5539b16d0c560a1445101f74898ba" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:19.051ex; height:3.009ex;" alt="{\mathcal {D}}_{n}=\{(X_{i},Y_{i})\}_{i=1}^{n}"/></span> is to fit a random forest to the data.  During the fitting process the <a href="/wiki/Out-of-bag_error" title="Out-of-bag error">out-of-bag error</a> for each data point is recorded and averaged over the forest (errors on an independent test set can be substituted if bagging is not used during training).
</p><p>To measure the importance of the <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle j}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>j</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle j}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2f461e54f5c093e92a55547b9764291390f0b5d0" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; margin-left: -0.027ex; width:0.985ex; height:2.509ex;" alt="j"/></span>-th feature after training, the values of the <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle j}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>j</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle j}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2f461e54f5c093e92a55547b9764291390f0b5d0" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; margin-left: -0.027ex; width:0.985ex; height:2.509ex;" alt="j"/></span>-th feature are permuted among the training data and the out-of-bag error is again computed on this perturbed data set.  The importance score for the <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle j}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>j</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle j}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2f461e54f5c093e92a55547b9764291390f0b5d0" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; margin-left: -0.027ex; width:0.985ex; height:2.509ex;" alt="j"/></span>-th feature is computed by averaging the difference in out-of-bag error before and after the permutation over all trees.  The score is normalized by the standard deviation of these differences.
</p><p>Features which produce large values for this score are ranked as more important than features which produce small values. The statistical definition of the variable importance measure was given and analyzed by Zhu <i>et al.</i><sup id="cite_ref-16" class="reference"><a href="#cite_note-16">&#91;16&#93;</a></sup>
</p><p>This method of determining variable importance has some drawbacks.  For data including categorical variables with different number of levels, random forests are biased in favor of those attributes with more levels. Methods such as <a href="/wiki/Partial_permutation" title="Partial permutation">partial permutations</a><sup id="cite_ref-17" class="reference"><a href="#cite_note-17">&#91;17&#93;</a></sup><sup id="cite_ref-18" class="reference"><a href="#cite_note-18">&#91;18&#93;</a></sup>
and growing unbiased trees<sup id="cite_ref-19" class="reference"><a href="#cite_note-19">&#91;19&#93;</a></sup><sup id="cite_ref-20" class="reference"><a href="#cite_note-20">&#91;20&#93;</a></sup> can be used to solve the problem.  If the data contain groups of correlated features of similar relevance for the output, then smaller groups are favored over larger groups.<sup id="cite_ref-21" class="reference"><a href="#cite_note-21">&#91;21&#93;</a></sup>
</p>
<h3><span class="mw-headline" id="Relationship_to_nearest_neighbors">Relationship to nearest neighbors</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=9" title="Edit section: Relationship to nearest neighbors">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>A relationship between random forests and the <a href="/wiki/K-nearest_neighbor_algorithm" class="mw-redirect" title="K-nearest neighbor algorithm"><span class="texhtml mvar" style="font-style:italic;">k</span>-nearest neighbor algorithm</a> (<span class="texhtml mvar" style="font-style:italic;">k</span>-NN) was pointed out by Lin and Jeon in 2002.<sup id="cite_ref-linjeon02_22-0" class="reference"><a href="#cite_note-linjeon02-22">&#91;22&#93;</a></sup> It turns out that both can be viewed as so-called <i>weighted neighborhoods schemes</i>. These are models built from a training set <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \{(x_{i},y_{i})\}_{i=1}^{n}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo fence="false" stretchy="false">{</mo>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mi>y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <msubsup>
          <mo fence="false" stretchy="false">}</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msubsup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \{(x_{i},y_{i})\}_{i=1}^{n}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0a9e0a59cd73d8fb11a10caa787512bf93af04b4" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:12.137ex; height:3.009ex;" alt="\{(x_{i},y_{i})\}_{i=1}^{n}"/></span> that make predictions <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\hat {y}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>y</mi>
              <mo stretchy="false">&#x005E;<!-- ^ --></mo>
            </mover>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\hat {y}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3dc8de3d8ea01304329ef9518fad7a6d196c4c01" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.302ex; height:2.509ex;" alt="{\hat {y}}"/></span> for new points <span class="texhtml mvar" style="font-style:italic;">x'</span> by looking at the "neighborhood" of the point, formalized by a weight function <span class="texhtml mvar" style="font-style:italic;">W</span>:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\hat {y}}=\sum _{i=1}^{n}W(x_{i},x')\,y_{i}.}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>y</mi>
              <mo stretchy="false">&#x005E;<!-- ^ --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>=</mo>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </munderover>
        <mi>W</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>,</mo>
        <msup>
          <mi>x</mi>
          <mo>&#x2032;</mo>
        </msup>
        <mo stretchy="false">)</mo>
        <mspace width="thinmathspace" />
        <msub>
          <mi>y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>.</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\hat {y}}=\sum _{i=1}^{n}W(x_{i},x')\,y_{i}.}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f9cd87e3168f0200bd67d04530ab9124dcb8cafc" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.005ex; width:20.538ex; height:6.843ex;" alt="{\hat {y}}=\sum _{i=1}^{n}W(x_{i},x&#039;)\,y_{i}."/></span></dd></dl>
<p>Here, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle W(x_{i},x')}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>W</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>,</mo>
        <msup>
          <mi>x</mi>
          <mo>&#x2032;</mo>
        </msup>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle W(x_{i},x')}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f87df356c5a2445516fca56d2df6eb73e64e48ce" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:9.422ex; height:3.009ex;" alt="W(x_{i},x&#039;)"/></span> is the non-negative weight of the <span class="texhtml mvar" style="font-style:italic;">i</span>'th training point relative to the new point <span class="texhtml mvar" style="font-style:italic;">x'</span> in the same tree. For any particular <span class="texhtml mvar" style="font-style:italic;">x'</span>, the weights for points <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle x_{i}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x_{i}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e87000dd6142b81d041896a30fe58f0c3acb2158" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.129ex; height:2.009ex;" alt="x_{i}"/></span> must sum to one. Weight functions are given as follows:
</p>
<ul><li>In <span class="texhtml mvar" style="font-style:italic;">k</span>-NN, the weights are <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle W(x_{i},x')={\frac {1}{k}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>W</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>,</mo>
        <msup>
          <mi>x</mi>
          <mo>&#x2032;</mo>
        </msup>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <mi>k</mi>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle W(x_{i},x')={\frac {1}{k}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ae3098adcbde36fd1253a0ee85a3868d67b1861f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.005ex; width:14.568ex; height:5.343ex;" alt="W(x_{i},x&#039;)={\frac {1}{k}}"/></span> if <span class="texhtml mvar" style="font-style:italic;">x<sub>i</sub></span> is one of the <span class="texhtml mvar" style="font-style:italic;">k</span> points closest to <span class="texhtml mvar" style="font-style:italic;">x'</span>, and zero otherwise.</li>
<li>In a tree, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle W(x_{i},x')={\frac {1}{k'}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>W</mi>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>,</mo>
        <msup>
          <mi>x</mi>
          <mo>&#x2032;</mo>
        </msup>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <msup>
              <mi>k</mi>
              <mo>&#x2032;</mo>
            </msup>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle W(x_{i},x')={\frac {1}{k'}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d80899c24f8d4488f56290ae99cfe61558667873" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.005ex; width:15.253ex; height:5.343ex;" alt="W(x_{i},x&#039;)={\frac {1}{k&#039;}}"/></span> if <span class="texhtml mvar" style="font-style:italic;">x<sub>i</sub></span> is one of the <span class="texhtml mvar" style="font-style:italic;">k'</span> points in the same leaf as <span class="texhtml mvar" style="font-style:italic;">x'</span>, and zero otherwise.</li></ul>
<p>Since a forest averages the predictions of a set of <span class="texhtml mvar" style="font-style:italic;">m</span> trees with individual weight functions <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle W_{j}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>W</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle W_{j}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/fa98874e6beb16373e8d0e056ba550cf653676a1" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:3.103ex; height:2.843ex;" alt="W_{j}"/></span>, its predictions are
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\hat {y}}={\frac {1}{m}}\sum _{j=1}^{m}\sum _{i=1}^{n}W_{j}(x_{i},x')\,y_{i}=\sum _{i=1}^{n}\left({\frac {1}{m}}\sum _{j=1}^{m}W_{j}(x_{i},x')\right)\,y_{i}.}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mover>
              <mi>y</mi>
              <mo stretchy="false">&#x005E;<!-- ^ --></mo>
            </mover>
          </mrow>
        </mrow>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <mi>m</mi>
          </mfrac>
        </mrow>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>m</mi>
          </mrow>
        </munderover>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </munderover>
        <msub>
          <mi>W</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>,</mo>
        <msup>
          <mi>x</mi>
          <mo>&#x2032;</mo>
        </msup>
        <mo stretchy="false">)</mo>
        <mspace width="thinmathspace" />
        <msub>
          <mi>y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>=</mo>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </munderover>
        <mrow>
          <mo>(</mo>
          <mrow>
            <mrow class="MJX-TeXAtom-ORD">
              <mfrac>
                <mn>1</mn>
                <mi>m</mi>
              </mfrac>
            </mrow>
            <munderover>
              <mo>&#x2211;<!-- ∑ --></mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>j</mi>
                <mo>=</mo>
                <mn>1</mn>
              </mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>m</mi>
              </mrow>
            </munderover>
            <msub>
              <mi>W</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>j</mi>
              </mrow>
            </msub>
            <mo stretchy="false">(</mo>
            <msub>
              <mi>x</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
              </mrow>
            </msub>
            <mo>,</mo>
            <msup>
              <mi>x</mi>
              <mo>&#x2032;</mo>
            </msup>
            <mo stretchy="false">)</mo>
          </mrow>
          <mo>)</mo>
        </mrow>
        <mspace width="thinmathspace" />
        <msub>
          <mi>y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>.</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\hat {y}}={\frac {1}{m}}\sum _{j=1}^{m}\sum _{i=1}^{n}W_{j}(x_{i},x')\,y_{i}=\sum _{i=1}^{n}\left({\frac {1}{m}}\sum _{j=1}^{m}W_{j}(x_{i},x')\right)\,y_{i}.}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8b819eff4f3bb5ee472825d9996c3fd5f6b18ed7" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.338ex; width:58.543ex; height:7.676ex;" alt="{\hat {y}}={\frac {1}{m}}\sum _{j=1}^{m}\sum _{i=1}^{n}W_{j}(x_{i},x&#039;)\,y_{i}=\sum _{i=1}^{n}\left({\frac {1}{m}}\sum _{j=1}^{m}W_{j}(x_{i},x&#039;)\right)\,y_{i}."/></span></dd></dl>
<p>This shows that the whole forest is again a weighted neighborhood scheme, with weights that average those of the individual trees. The neighbors of <span class="texhtml mvar" style="font-style:italic;">x'</span> in this interpretation are the points <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle x_{i}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>x</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x_{i}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e87000dd6142b81d041896a30fe58f0c3acb2158" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.129ex; height:2.009ex;" alt="x_{i}"/></span> sharing the same leaf in any tree <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle j}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>j</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle j}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2f461e54f5c093e92a55547b9764291390f0b5d0" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; margin-left: -0.027ex; width:0.985ex; height:2.509ex;" alt="j"/></span>. In this way, the neighborhood of <span class="texhtml mvar" style="font-style:italic;">x'</span> depends in a complex way on the structure of the trees, and thus on the structure of the training set. Lin and Jeon show that the shape of the neighborhood used by a random forest adapts to the local importance of each feature.<sup id="cite_ref-linjeon02_22-1" class="reference"><a href="#cite_note-linjeon02-22">&#91;22&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Unsupervised_learning_with_random_forests">Unsupervised learning with random forests</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=10" title="Edit section: Unsupervised learning with random forests">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>As part of their construction, random forest predictors naturally lead to a dissimilarity measure among the observations. One can also define a random forest dissimilarity measure between unlabeled data: the idea is to construct a random forest predictor that distinguishes the “observed” data from suitably generated synthetic data.<sup id="cite_ref-breiman2001_7-3" class="reference"><a href="#cite_note-breiman2001-7">&#91;7&#93;</a></sup><sup id="cite_ref-23" class="reference"><a href="#cite_note-23">&#91;23&#93;</a></sup>
The observed data are the original unlabeled data and the synthetic data are drawn from a reference distribution. A random forest dissimilarity can be attractive because it handles mixed variable types very well, is invariant to monotonic transformations of the input variables, and is robust to outlying observations. The random forest dissimilarity easily deals with a large number of semi-continuous variables due to its intrinsic variable selection; for example, the "Addcl 1" random forest dissimilarity weighs the contribution of each variable according to how dependent it is on other variables. The random forest dissimilarity has been used in a variety of applications, e.g. to find clusters of patients based on tissue marker data.<sup id="cite_ref-24" class="reference"><a href="#cite_note-24">&#91;24&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Variants">Variants</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=11" title="Edit section: Variants">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>Instead of decision trees, linear models have been proposed and evaluated as base estimators in random forests, in particular <a href="/wiki/Multinomial_logistic_regression" title="Multinomial logistic regression">multinomial logistic regression</a> and <a href="/wiki/Naive_Bayes_classifier" title="Naive Bayes classifier">naive Bayes classifiers</a>.<sup id="cite_ref-25" class="reference"><a href="#cite_note-25">&#91;25&#93;</a></sup><sup id="cite_ref-26" class="reference"><a href="#cite_note-26">&#91;26&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Kernel_random_forest">Kernel random forest</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=12" title="Edit section: Kernel random forest">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<p>In machine learning, kernel random forests establish the connection between random forests and <a href="/wiki/Kernel_method" title="Kernel method">kernel methods</a>. By slightly modifying their definition, random forests can be rewritten as <a href="/wiki/Kernel_method" title="Kernel method">kernel methods</a>, which are more interpretable and easier to analyze.<sup id="cite_ref-scornet2015random_27-0" class="reference"><a href="#cite_note-scornet2015random-27">&#91;27&#93;</a></sup>
</p>
<h3><span class="mw-headline" id="History_2">History</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=13" title="Edit section: History">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p><a href="/wiki/Leo_Breiman" title="Leo Breiman">Leo Breiman</a><sup id="cite_ref-breiman2000some_28-0" class="reference"><a href="#cite_note-breiman2000some-28">&#91;28&#93;</a></sup> was the first person to notice the link between random forest and <a href="/wiki/Kernel_methods" class="mw-redirect" title="Kernel methods">kernel methods</a>. He pointed out that random forests which are grown using <a href="/wiki/I.i.d." class="mw-redirect" title="I.i.d.">i.i.d.</a> random vectors in the tree construction are equivalent to a kernel acting on the true margin. Lin and Jeon<sup id="cite_ref-lin2006random_29-0" class="reference"><a href="#cite_note-lin2006random-29">&#91;29&#93;</a></sup> established the connection between random forests and adaptive nearest neighbor, implying that random forests can be seen as adaptive kernel estimates. Davies and Ghahramani<sup id="cite_ref-davies2014random_30-0" class="reference"><a href="#cite_note-davies2014random-30">&#91;30&#93;</a></sup> proposed Random Forest Kernel and show that it can empirically outperform state-of-art kernel methods. Scornet<sup id="cite_ref-scornet2015random_27-1" class="reference"><a href="#cite_note-scornet2015random-27">&#91;27&#93;</a></sup> first defined KeRF estimates and gave the explicit link between KeRF estimates and random forest. He also gave explicit expressions for kernels based on centered random forest<sup id="cite_ref-breiman2004consistency_31-0" class="reference"><a href="#cite_note-breiman2004consistency-31">&#91;31&#93;</a></sup> and uniform random forest,<sup id="cite_ref-arlot2014analysis_32-0" class="reference"><a href="#cite_note-arlot2014analysis-32">&#91;32&#93;</a></sup> two simplified models of random forest. He named these two KeRFs Centered KeRF and Uniform KeRF, and proved upper bounds on their rates of consistency.
</p>
<h3><span class="mw-headline" id="Notations_and_definitions">Notations and definitions</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=14" title="Edit section: Notations and definitions">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<h4><span class="mw-headline" id="Preliminaries:_Centered_forests">Preliminaries: Centered forests</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=15" title="Edit section: Preliminaries: Centered forests">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Centered forest<sup id="cite_ref-breiman2004consistency_31-1" class="reference"><a href="#cite_note-breiman2004consistency-31">&#91;31&#93;</a></sup> is a simplified model for Breiman's original random forest, which uniformly selects an attribute among all attributes and performs splits at the center of the cell along the pre-chosen attribute. The algorithm stops when a fully binary tree of level <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle k}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>k</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle k}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c3c9a2c7b599b37105512c5d570edc034056dd40" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.211ex; height:2.176ex;" alt="k"/></span> is built, where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle k\in \mathbb {N} }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>k</mi>
        <mo>&#x2208;<!-- ∈ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="double-struck">N</mi>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle k\in \mathbb {N} }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2a5bc4b7383031ba693b7433198ead7170954c1d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:5.73ex; height:2.176ex;" alt="k\in {\mathbb  {N}}"/></span> is a parameter of the algorithm.
</p>
<h4><span class="mw-headline" id="Uniform_forest">Uniform forest</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=16" title="Edit section: Uniform forest">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Uniform forest<sup id="cite_ref-arlot2014analysis_32-1" class="reference"><a href="#cite_note-arlot2014analysis-32">&#91;32&#93;</a></sup> is another simplified model for Breiman's original random forest, which uniformly selects a feature among all features and performs splits at a point uniformly drawn on the side of the cell, along the preselected feature.
</p>
<h4><span class="mw-headline" id="From_random_forest_to_KeRF">From random forest to KeRF</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=17" title="Edit section: From random forest to KeRF">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Given a training sample  <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\mathcal {D}}_{n}=\{(\mathbf {X} _{i},Y_{i})\}_{i=1}^{n}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mi class="MJX-tex-caligraphic" mathvariant="script">D</mi>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo>=</mo>
        <mo fence="false" stretchy="false">{</mo>
        <mo stretchy="false">(</mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="bold">X</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo>,</mo>
        <msub>
          <mi>Y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <msubsup>
          <mo fence="false" stretchy="false">}</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msubsup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\mathcal {D}}_{n}=\{(\mathbf {X} _{i},Y_{i})\}_{i=1}^{n}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c67c8cf7d7485be2a566d02284d9bc27a3f61241" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:19.147ex; height:3.009ex;" alt="{\mathcal  {D}}_{n}=\{({\mathbf  {X}}_{i},Y_{i})\}_{{i=1}}^{n}"/></span> of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle [0,1]^{p}\times \mathbb {R} }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo stretchy="false">[</mo>
        <mn>0</mn>
        <mo>,</mo>
        <mn>1</mn>
        <msup>
          <mo stretchy="false">]</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>p</mi>
          </mrow>
        </msup>
        <mo>&#x00D7;<!-- × --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="double-struck">R</mi>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle [0,1]^{p}\times \mathbb {R} }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6724c5c806dd7cee08c1f2133fc89f94ed0c2e91" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:10.23ex; height:2.843ex;" alt="[0,1]^{p}\times {\mathbb  {R}}"/></span>-valued independent random variables distributed as the independent prototype pair <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle (\mathbf {X} ,Y)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">X</mi>
        </mrow>
        <mo>,</mo>
        <mi>Y</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle (\mathbf {X} ,Y)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f50eb05dacdb567fc019a3bbcd44b596a1c59a13" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:6.636ex; height:2.843ex;" alt="({\mathbf  {X}},Y)"/></span>, where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \operatorname {E} [Y^{2}]&lt;\infty }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi mathvariant="normal">E</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mo stretchy="false">[</mo>
        <msup>
          <mi>Y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msup>
        <mo stretchy="false">]</mo>
        <mo>&lt;</mo>
        <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \operatorname {E} [Y^{2}]&lt;\infty }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/07a863a618762e9fecf30fadce90c3f6484db196" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:11.253ex; height:3.176ex;" alt="{\displaystyle \operatorname {E} [Y^{2}]&lt;\infty }"/></span>. We aim at predicting the response <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle Y}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>Y</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Y}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/961d67d6b454b4df2301ac571808a3538b3a6d3f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.171ex; width:1.773ex; height:2.009ex;" alt="Y"/></span>, associated with the random variable <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mathbf {X} }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">X</mi>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mathbf {X} }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9f75966a2f9d5672136fa9401ee1e75008f95ffd" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:2.019ex; height:2.176ex;" alt="\mathbf {X} "/></span>, by estimating the regression function <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle m(\mathbf {x} )=\operatorname {E} [Y\mid \mathbf {X} =\mathbf {x} ]}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>m</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mi mathvariant="normal">E</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mo stretchy="false">[</mo>
        <mi>Y</mi>
        <mo>&#x2223;<!-- ∣ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">X</mi>
        </mrow>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo stretchy="false">]</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle m(\mathbf {x} )=\operatorname {E} [Y\mid \mathbf {X} =\mathbf {x} ]}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0c097ce105048693746d5524ac0ef9fc514da53b" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:21.475ex; height:2.843ex;" alt="{\displaystyle m(\mathbf {x} )=\operatorname {E} [Y\mid \mathbf {X} =\mathbf {x} ]}"/></span>. A random regression forest is an ensemble of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle M}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>M</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle M}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f82cade9898ced02fdd08712e5f0c0151758a0dd" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:2.442ex; height:2.176ex;" alt="M"/></span> randomized regression trees. Denote <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle m_{n}(\mathbf {x} ,\mathbf {\Theta } _{j})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>m</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo>,</mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="bold">&#x0398;<!-- Θ --></mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle m_{n}(\mathbf {x} ,\mathbf {\Theta } _{j})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/95ad3dfa3a0ed6fc135df01b527d6be634ff9d07" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:10.5ex; height:3.009ex;" alt="m_{n}({\mathbf  {x}},{\mathbf  {\Theta }}_{j})"/></span> the predicted value at point <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mathbf {x} }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mathbf {x} }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/32adf004df5eb0a8c7fd8c0b6b7405183c5a5ef2" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.411ex; height:1.676ex;" alt="\mathbf {x} "/></span> by the <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle j}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>j</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle j}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2f461e54f5c093e92a55547b9764291390f0b5d0" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; margin-left: -0.027ex; width:0.985ex; height:2.509ex;" alt="j"/></span>-th tree, where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mathbf {\Theta } _{1},\ldots ,\mathbf {\Theta } _{M}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="bold">&#x0398;<!-- Θ --></mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <mo>&#x2026;<!-- … --></mo>
        <mo>,</mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="bold">&#x0398;<!-- Θ --></mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>M</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mathbf {\Theta } _{1},\ldots ,\mathbf {\Theta } _{M}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8588793690df49c9b10f8c44499b1ee82106867f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:12.347ex; height:2.509ex;" alt="{\displaystyle \mathbf {\Theta } _{1},\ldots ,\mathbf {\Theta } _{M}}"/></span> are independent random variables, distributed as a generic random variable <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mathbf {\Theta } }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">&#x0398;<!-- Θ --></mi>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mathbf {\Theta } }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1a15b5576ec407e52c5fdfc21c5d7bf45402406a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:2.078ex; height:2.176ex;" alt="{\mathbf  {\Theta }}"/></span>, independent of the sample <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\mathcal {D}}_{n}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mi class="MJX-tex-caligraphic" mathvariant="script">D</mi>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\mathcal {D}}_{n}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4ba7d8da2372a68d034e848dbd973b7f173769fe" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:3.01ex; height:2.509ex;" alt="\mathcal{D}_n"/></span>. This random variable can be used to describe the randomness induced by node splitting and the sampling procedure for tree construction. The trees are combined to form the finite forest estimate <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle m_{M,n}(\mathbf {x} ,\Theta _{1},\ldots ,\Theta _{M})={\frac {1}{M}}\sum _{j=1}^{M}m_{n}(\mathbf {x} ,\Theta _{j})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>m</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>M</mi>
            <mo>,</mo>
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo>,</mo>
        <msub>
          <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <mo>&#x2026;<!-- … --></mo>
        <mo>,</mo>
        <msub>
          <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>M</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <mi>M</mi>
          </mfrac>
        </mrow>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>M</mi>
          </mrow>
        </munderover>
        <msub>
          <mi>m</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo>,</mo>
        <msub>
          <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle m_{M,n}(\mathbf {x} ,\Theta _{1},\ldots ,\Theta _{M})={\frac {1}{M}}\sum _{j=1}^{M}m_{n}(\mathbf {x} ,\Theta _{j})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e1cd03b3dba46782bb60f083359fd8e77250024c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.338ex; width:42.242ex; height:7.676ex;" alt="{\displaystyle m_{M,n}(\mathbf {x} ,\Theta _{1},\ldots ,\Theta _{M})={\frac {1}{M}}\sum _{j=1}^{M}m_{n}(\mathbf {x} ,\Theta _{j})}"/></span>.
For regression trees, we have <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle m_{n}=\sum _{i=1}^{n}{\frac {Y_{i}\mathbf {1} _{\mathbf {X} _{i}\in A_{n}(\mathbf {x} ,\Theta _{j})}}{N_{n}(\mathbf {x} ,\Theta _{j})}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>m</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo>=</mo>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </munderover>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <msub>
                <mi>Y</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>i</mi>
                </mrow>
              </msub>
              <msub>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn mathvariant="bold">1</mn>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <msub>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mi mathvariant="bold">X</mi>
                    </mrow>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mi>i</mi>
                    </mrow>
                  </msub>
                  <mo>&#x2208;<!-- ∈ --></mo>
                  <msub>
                    <mi>A</mi>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mi>n</mi>
                    </mrow>
                  </msub>
                  <mo stretchy="false">(</mo>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi mathvariant="bold">x</mi>
                  </mrow>
                  <mo>,</mo>
                  <msub>
                    <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mi>j</mi>
                    </mrow>
                  </msub>
                  <mo stretchy="false">)</mo>
                </mrow>
              </msub>
            </mrow>
            <mrow>
              <msub>
                <mi>N</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>n</mi>
                </mrow>
              </msub>
              <mo stretchy="false">(</mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mi mathvariant="bold">x</mi>
              </mrow>
              <mo>,</mo>
              <msub>
                <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>j</mi>
                </mrow>
              </msub>
              <mo stretchy="false">)</mo>
            </mrow>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle m_{n}=\sum _{i=1}^{n}{\frac {Y_{i}\mathbf {1} _{\mathbf {X} _{i}\in A_{n}(\mathbf {x} ,\Theta _{j})}}{N_{n}(\mathbf {x} ,\Theta _{j})}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d1ad1f4a5e0e849bfbf10492b08e5e9b55b6c711" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.005ex; width:24.729ex; height:7.009ex;" alt="m_{n}=\sum _{{i=1}}^{n}{\frac  {Y_{i}{\mathbf  {1}}_{{{\mathbf  {X}}_{i}\in A_{n}({\mathbf  {x}},\Theta _{j})}}}{N_{n}({\mathbf  {x}},\Theta _{j})}}"/></span>, where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle A_{n}(\mathbf {x} ,\Theta _{j})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>A</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo>,</mo>
        <msub>
          <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle A_{n}(\mathbf {x} ,\Theta _{j})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1811d33726c0ea70d83e6f5ee5228d82e6229300" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:9.934ex; height:3.009ex;" alt="A_{n}({\mathbf  {x}},\Theta _{j})"/></span> is the cell containing <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mathbf {x} }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mathbf {x} }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/32adf004df5eb0a8c7fd8c0b6b7405183c5a5ef2" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.411ex; height:1.676ex;" alt="\mathbf {x} "/></span>, designed with randomness <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \Theta _{j}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \Theta _{j}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/10b9d5bab99a44d98171cce92f04d0e700060512" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:2.718ex; height:2.843ex;" alt="\Theta _{j}"/></span> and dataset <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\mathcal {D}}_{n}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mi class="MJX-tex-caligraphic" mathvariant="script">D</mi>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\mathcal {D}}_{n}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4ba7d8da2372a68d034e848dbd973b7f173769fe" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:3.01ex; height:2.509ex;" alt="\mathcal{D}_n"/></span>, and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle N_{n}(\mathbf {x} ,\Theta _{j})=\sum _{i=1}^{n}\mathbf {1} _{\mathbf {X} _{i}\in A_{n}(\mathbf {x} ,\Theta _{j})}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>N</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo>,</mo>
        <msub>
          <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </munderover>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mn mathvariant="bold">1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <msub>
              <mrow class="MJX-TeXAtom-ORD">
                <mi mathvariant="bold">X</mi>
              </mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
              </mrow>
            </msub>
            <mo>&#x2208;<!-- ∈ --></mo>
            <msub>
              <mi>A</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>n</mi>
              </mrow>
            </msub>
            <mo stretchy="false">(</mo>
            <mrow class="MJX-TeXAtom-ORD">
              <mi mathvariant="bold">x</mi>
            </mrow>
            <mo>,</mo>
            <msub>
              <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>j</mi>
              </mrow>
            </msub>
            <mo stretchy="false">)</mo>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle N_{n}(\mathbf {x} ,\Theta _{j})=\sum _{i=1}^{n}\mathbf {1} _{\mathbf {X} _{i}\in A_{n}(\mathbf {x} ,\Theta _{j})}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2c13629db1ca0ba725280a4f2bbf7adfc5c9f8a5" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.005ex; width:28.54ex; height:6.843ex;" alt="N_{n}({\mathbf  {x}},\Theta _{j})=\sum _{{i=1}}^{n}{\mathbf  {1}}_{{{\mathbf  {X}}_{i}\in A_{n}({\mathbf  {x}},\Theta _{j})}}"/></span>.
</p><p>Thus random forest estimates satisfy, for all <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mathbf {x} \in [0,1]^{d}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo>&#x2208;<!-- ∈ --></mo>
        <mo stretchy="false">[</mo>
        <mn>0</mn>
        <mo>,</mo>
        <mn>1</mn>
        <msup>
          <mo stretchy="false">]</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>d</mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mathbf {x} \in [0,1]^{d}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/691c9727c059400e1d15031c7e0e08fbd6774282" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:9.996ex; height:3.176ex;" alt="{\mathbf  {x}}\in [0,1]^{d}"/></span>, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle m_{M,n}(\mathbf {x} ,\Theta _{1},\ldots ,\Theta _{M})={\frac {1}{M}}\sum _{j=1}^{M}\left(\sum _{i=1}^{n}{\frac {Y_{i}\mathbf {1} _{\mathbf {X} _{i}\in A_{n}(\mathbf {x} ,\Theta _{j})}}{N_{n}(\mathbf {x} ,\Theta _{j})}}\right)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>m</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>M</mi>
            <mo>,</mo>
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo>,</mo>
        <msub>
          <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <mo>&#x2026;<!-- … --></mo>
        <mo>,</mo>
        <msub>
          <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>M</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <mi>M</mi>
          </mfrac>
        </mrow>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>M</mi>
          </mrow>
        </munderover>
        <mrow>
          <mo>(</mo>
          <mrow>
            <munderover>
              <mo>&#x2211;<!-- ∑ --></mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
                <mo>=</mo>
                <mn>1</mn>
              </mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>n</mi>
              </mrow>
            </munderover>
            <mrow class="MJX-TeXAtom-ORD">
              <mfrac>
                <mrow>
                  <msub>
                    <mi>Y</mi>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mi>i</mi>
                    </mrow>
                  </msub>
                  <msub>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mn mathvariant="bold">1</mn>
                    </mrow>
                    <mrow class="MJX-TeXAtom-ORD">
                      <msub>
                        <mrow class="MJX-TeXAtom-ORD">
                          <mi mathvariant="bold">X</mi>
                        </mrow>
                        <mrow class="MJX-TeXAtom-ORD">
                          <mi>i</mi>
                        </mrow>
                      </msub>
                      <mo>&#x2208;<!-- ∈ --></mo>
                      <msub>
                        <mi>A</mi>
                        <mrow class="MJX-TeXAtom-ORD">
                          <mi>n</mi>
                        </mrow>
                      </msub>
                      <mo stretchy="false">(</mo>
                      <mrow class="MJX-TeXAtom-ORD">
                        <mi mathvariant="bold">x</mi>
                      </mrow>
                      <mo>,</mo>
                      <msub>
                        <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
                        <mrow class="MJX-TeXAtom-ORD">
                          <mi>j</mi>
                        </mrow>
                      </msub>
                      <mo stretchy="false">)</mo>
                    </mrow>
                  </msub>
                </mrow>
                <mrow>
                  <msub>
                    <mi>N</mi>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mi>n</mi>
                    </mrow>
                  </msub>
                  <mo stretchy="false">(</mo>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi mathvariant="bold">x</mi>
                  </mrow>
                  <mo>,</mo>
                  <msub>
                    <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mi>j</mi>
                    </mrow>
                  </msub>
                  <mo stretchy="false">)</mo>
                </mrow>
              </mfrac>
            </mrow>
          </mrow>
          <mo>)</mo>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle m_{M,n}(\mathbf {x} ,\Theta _{1},\ldots ,\Theta _{M})={\frac {1}{M}}\sum _{j=1}^{M}\left(\sum _{i=1}^{n}{\frac {Y_{i}\mathbf {1} _{\mathbf {X} _{i}\in A_{n}(\mathbf {x} ,\Theta _{j})}}{N_{n}(\mathbf {x} ,\Theta _{j})}}\right)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/671426d343ccaba3944706fd2517e5f7035f674c" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.338ex; width:54.064ex; height:7.676ex;" alt="m_{{M,n}}({\mathbf  {x}},\Theta _{1},\ldots ,\Theta _{M})={\frac  {1}{M}}\sum _{{j=1}}^{M}\left(\sum _{{i=1}}^{n}{\frac  {Y_{i}{\mathbf  {1}}_{{{\mathbf  {X}}_{i}\in A_{n}({\mathbf  {x}},\Theta _{j})}}}{N_{n}({\mathbf  {x}},\Theta _{j})}}\right)"/></span>. Random regression forest has two level of averaging, first over the samples in the target cell of a tree, then over all trees. Thus the contributions of observations that are in cells with a high density of data points are smaller than that of observations which belong to less populated cells. In order to improve the random forest methods and compensate the misestimation, Scornet<sup id="cite_ref-scornet2015random_27-2" class="reference"><a href="#cite_note-scornet2015random-27">&#91;27&#93;</a></sup> defined KeRF by
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\tilde {m}}_{M,n}(\mathbf {x} ,\Theta _{1},\ldots ,\Theta _{M})={\frac {1}{\sum _{j=1}^{M}N_{n}(\mathbf {x} ,\Theta _{j})}}\sum _{j=1}^{M}\sum _{i=1}^{n}Y_{i}\mathbf {1} _{\mathbf {X} _{i}\in A_{n}(\mathbf {x} ,\Theta _{j})},}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>m</mi>
                <mo stretchy="false">&#x007E;<!-- ~ --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>M</mi>
            <mo>,</mo>
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo>,</mo>
        <msub>
          <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <mo>&#x2026;<!-- … --></mo>
        <mo>,</mo>
        <msub>
          <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>M</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <mrow>
              <munderover>
                <mo>&#x2211;<!-- ∑ --></mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>j</mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>M</mi>
                </mrow>
              </munderover>
              <msub>
                <mi>N</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>n</mi>
                </mrow>
              </msub>
              <mo stretchy="false">(</mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mi mathvariant="bold">x</mi>
              </mrow>
              <mo>,</mo>
              <msub>
                <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>j</mi>
                </mrow>
              </msub>
              <mo stretchy="false">)</mo>
            </mrow>
          </mfrac>
        </mrow>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>M</mi>
          </mrow>
        </munderover>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </munderover>
        <msub>
          <mi>Y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mn mathvariant="bold">1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <msub>
              <mrow class="MJX-TeXAtom-ORD">
                <mi mathvariant="bold">X</mi>
              </mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
              </mrow>
            </msub>
            <mo>&#x2208;<!-- ∈ --></mo>
            <msub>
              <mi>A</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>n</mi>
              </mrow>
            </msub>
            <mo stretchy="false">(</mo>
            <mrow class="MJX-TeXAtom-ORD">
              <mi mathvariant="bold">x</mi>
            </mrow>
            <mo>,</mo>
            <msub>
              <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>j</mi>
              </mrow>
            </msub>
            <mo stretchy="false">)</mo>
          </mrow>
        </msub>
        <mo>,</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\tilde {m}}_{M,n}(\mathbf {x} ,\Theta _{1},\ldots ,\Theta _{M})={\frac {1}{\sum _{j=1}^{M}N_{n}(\mathbf {x} ,\Theta _{j})}}\sum _{j=1}^{M}\sum _{i=1}^{n}Y_{i}\mathbf {1} _{\mathbf {X} _{i}\in A_{n}(\mathbf {x} ,\Theta _{j})},}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/565e75beaa1dd3b92753899bfa390abba19af5fc" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.505ex; width:63.659ex; height:7.843ex;" alt="{\displaystyle {\tilde {m}}_{M,n}(\mathbf {x} ,\Theta _{1},\ldots ,\Theta _{M})={\frac {1}{\sum _{j=1}^{M}N_{n}(\mathbf {x} ,\Theta _{j})}}\sum _{j=1}^{M}\sum _{i=1}^{n}Y_{i}\mathbf {1} _{\mathbf {X} _{i}\in A_{n}(\mathbf {x} ,\Theta _{j})},}"/></span></dd></dl>
<p>which is equal to the mean of the <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle Y_{i}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>Y</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>i</mi>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Y_{i}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d57be496fff95ee2a97ee43c7f7fe244b4dbf8ae" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:2.15ex; height:2.509ex;" alt="Y_{i}"/></span>'s falling in the cells containing <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mathbf {x} }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mathbf {x} }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/32adf004df5eb0a8c7fd8c0b6b7405183c5a5ef2" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.411ex; height:1.676ex;" alt="\mathbf {x} "/></span> in the forest. If we define the connection function of the <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle M}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>M</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle M}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f82cade9898ced02fdd08712e5f0c0151758a0dd" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:2.442ex; height:2.176ex;" alt="M"/></span> finite forest as <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle K_{M,n}(\mathbf {x} ,\mathbf {z} )={\frac {1}{M}}\sum _{j=1}^{M}\mathbf {1} _{\mathbf {z} \in A_{n}(\mathbf {x} ,\Theta _{j})}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>K</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>M</mi>
            <mo>,</mo>
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo>,</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">z</mi>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <mi>M</mi>
          </mfrac>
        </mrow>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>j</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>M</mi>
          </mrow>
        </munderover>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mn mathvariant="bold">1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mi mathvariant="bold">z</mi>
            </mrow>
            <mo>&#x2208;<!-- ∈ --></mo>
            <msub>
              <mi>A</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>n</mi>
              </mrow>
            </msub>
            <mo stretchy="false">(</mo>
            <mrow class="MJX-TeXAtom-ORD">
              <mi mathvariant="bold">x</mi>
            </mrow>
            <mo>,</mo>
            <msub>
              <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>j</mi>
              </mrow>
            </msub>
            <mo stretchy="false">)</mo>
          </mrow>
        </msub>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle K_{M,n}(\mathbf {x} ,\mathbf {z} )={\frac {1}{M}}\sum _{j=1}^{M}\mathbf {1} _{\mathbf {z} \in A_{n}(\mathbf {x} ,\Theta _{j})}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7723dd64358a146a8bc819a79f9c15266b4d37dc" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.338ex; width:31.754ex; height:7.676ex;" alt="{\displaystyle K_{M,n}(\mathbf {x} ,\mathbf {z} )={\frac {1}{M}}\sum _{j=1}^{M}\mathbf {1} _{\mathbf {z} \in A_{n}(\mathbf {x} ,\Theta _{j})}}"/></span>, i.e. the proportion of cells shared between <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mathbf {x} }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mathbf {x} }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/32adf004df5eb0a8c7fd8c0b6b7405183c5a5ef2" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.411ex; height:1.676ex;" alt="\mathbf {x} "/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mathbf {z} }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">z</mi>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mathbf {z} }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/82eca5d0928078d5a61b9e7e98cc73db31070909" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.188ex; height:1.676ex;" alt="\mathbf {z} "/></span>, then almost surely we have <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\tilde {m}}_{M,n}(\mathbf {x} ,\Theta _{1},\ldots ,\Theta _{M})={\frac {\sum _{i=1}^{n}Y_{i}K_{M,n}(\mathbf {x} ,\mathbf {x} _{i})}{\sum _{\ell =1}^{n}K_{M,n}(\mathbf {x} ,\mathbf {x} _{\ell })}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>m</mi>
                <mo stretchy="false">&#x007E;<!-- ~ --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>M</mi>
            <mo>,</mo>
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo>,</mo>
        <msub>
          <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <mo>&#x2026;<!-- … --></mo>
        <mo>,</mo>
        <msub>
          <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>M</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <munderover>
                <mo>&#x2211;<!-- ∑ --></mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>i</mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>n</mi>
                </mrow>
              </munderover>
              <msub>
                <mi>Y</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>i</mi>
                </mrow>
              </msub>
              <msub>
                <mi>K</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>M</mi>
                  <mo>,</mo>
                  <mi>n</mi>
                </mrow>
              </msub>
              <mo stretchy="false">(</mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mi mathvariant="bold">x</mi>
              </mrow>
              <mo>,</mo>
              <msub>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi mathvariant="bold">x</mi>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>i</mi>
                </mrow>
              </msub>
              <mo stretchy="false">)</mo>
            </mrow>
            <mrow>
              <munderover>
                <mo>&#x2211;<!-- ∑ --></mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>&#x2113;<!-- ℓ --></mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>n</mi>
                </mrow>
              </munderover>
              <msub>
                <mi>K</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>M</mi>
                  <mo>,</mo>
                  <mi>n</mi>
                </mrow>
              </msub>
              <mo stretchy="false">(</mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mi mathvariant="bold">x</mi>
              </mrow>
              <mo>,</mo>
              <msub>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi mathvariant="bold">x</mi>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>&#x2113;<!-- ℓ --></mi>
                </mrow>
              </msub>
              <mo stretchy="false">)</mo>
            </mrow>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\tilde {m}}_{M,n}(\mathbf {x} ,\Theta _{1},\ldots ,\Theta _{M})={\frac {\sum _{i=1}^{n}Y_{i}K_{M,n}(\mathbf {x} ,\mathbf {x} _{i})}{\sum _{\ell =1}^{n}K_{M,n}(\mathbf {x} ,\mathbf {x} _{\ell })}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7ea4edc4c4ad2b30acfe0b5898862397424612eb" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.838ex; width:45.172ex; height:6.843ex;" alt="{\displaystyle {\tilde {m}}_{M,n}(\mathbf {x} ,\Theta _{1},\ldots ,\Theta _{M})={\frac {\sum _{i=1}^{n}Y_{i}K_{M,n}(\mathbf {x} ,\mathbf {x} _{i})}{\sum _{\ell =1}^{n}K_{M,n}(\mathbf {x} ,\mathbf {x} _{\ell })}}}"/></span>, which defines the KeRF.
</p>
<h4><span class="mw-headline" id="Centered_KeRF">Centered KeRF</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=18" title="Edit section: Centered KeRF">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>The construction of Centered KeRF of level <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle k}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>k</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle k}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c3c9a2c7b599b37105512c5d570edc034056dd40" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.211ex; height:2.176ex;" alt="k"/></span> is the same as for centered forest, except that predictions are made by <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\tilde {m}}_{M,n}(\mathbf {x} ,\Theta _{1},\ldots ,\Theta _{M})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>m</mi>
                <mo stretchy="false">&#x007E;<!-- ~ --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>M</mi>
            <mo>,</mo>
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo>,</mo>
        <msub>
          <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <mo>&#x2026;<!-- … --></mo>
        <mo>,</mo>
        <msub>
          <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>M</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\tilde {m}}_{M,n}(\mathbf {x} ,\Theta _{1},\ldots ,\Theta _{M})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3939edfe84d8ece5969248f08b77f0b23843ad3e" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:21.505ex; height:3.009ex;" alt="{\tilde  {m}}_{{M,n}}({\mathbf  {x}},\Theta _{1},\ldots ,\Theta _{M})"/></span>, the corresponding kernel function, or connection function is
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\begin{aligned}K_{k}^{cc}(\mathbf {x} ,\mathbf {z} )=\sum _{k_{1},\ldots ,k_{d},\sum _{j=1}^{d}k_{j}=k}&amp;{\frac {k!}{k_{1}!\cdots k_{d}!}}\left({\frac {1}{d}}\right)^{k}\prod _{j=1}^{d}\mathbf {1} _{\lceil 2^{k_{j}}x_{j}\rceil =\lceil 2^{k_{j}}z_{j}\rceil },\\&amp;{\text{ for all }}\mathbf {x} ,\mathbf {z} \in [0,1]^{d}.\end{aligned}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true">
            <mtr>
              <mtd>
                <msubsup>
                  <mi>K</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>k</mi>
                  </mrow>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>c</mi>
                    <mi>c</mi>
                  </mrow>
                </msubsup>
                <mo stretchy="false">(</mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi mathvariant="bold">x</mi>
                </mrow>
                <mo>,</mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi mathvariant="bold">z</mi>
                </mrow>
                <mo stretchy="false">)</mo>
                <mo>=</mo>
                <munder>
                  <mo>&#x2211;<!-- ∑ --></mo>
                  <mrow class="MJX-TeXAtom-ORD">
                    <msub>
                      <mi>k</mi>
                      <mrow class="MJX-TeXAtom-ORD">
                        <mn>1</mn>
                      </mrow>
                    </msub>
                    <mo>,</mo>
                    <mo>&#x2026;<!-- … --></mo>
                    <mo>,</mo>
                    <msub>
                      <mi>k</mi>
                      <mrow class="MJX-TeXAtom-ORD">
                        <mi>d</mi>
                      </mrow>
                    </msub>
                    <mo>,</mo>
                    <munderover>
                      <mo>&#x2211;<!-- ∑ --></mo>
                      <mrow class="MJX-TeXAtom-ORD">
                        <mi>j</mi>
                        <mo>=</mo>
                        <mn>1</mn>
                      </mrow>
                      <mrow class="MJX-TeXAtom-ORD">
                        <mi>d</mi>
                      </mrow>
                    </munderover>
                    <msub>
                      <mi>k</mi>
                      <mrow class="MJX-TeXAtom-ORD">
                        <mi>j</mi>
                      </mrow>
                    </msub>
                    <mo>=</mo>
                    <mi>k</mi>
                  </mrow>
                </munder>
              </mtd>
              <mtd>
                <mrow class="MJX-TeXAtom-ORD">
                  <mfrac>
                    <mrow>
                      <mi>k</mi>
                      <mo>!</mo>
                    </mrow>
                    <mrow>
                      <msub>
                        <mi>k</mi>
                        <mrow class="MJX-TeXAtom-ORD">
                          <mn>1</mn>
                        </mrow>
                      </msub>
                      <mo>!</mo>
                      <mo>&#x22EF;<!-- ⋯ --></mo>
                      <msub>
                        <mi>k</mi>
                        <mrow class="MJX-TeXAtom-ORD">
                          <mi>d</mi>
                        </mrow>
                      </msub>
                      <mo>!</mo>
                    </mrow>
                  </mfrac>
                </mrow>
                <msup>
                  <mrow>
                    <mo>(</mo>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mfrac>
                        <mn>1</mn>
                        <mi>d</mi>
                      </mfrac>
                    </mrow>
                    <mo>)</mo>
                  </mrow>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>k</mi>
                  </mrow>
                </msup>
                <munderover>
                  <mo>&#x220F;<!-- ∏ --></mo>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>j</mi>
                    <mo>=</mo>
                    <mn>1</mn>
                  </mrow>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>d</mi>
                  </mrow>
                </munderover>
                <msub>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mn mathvariant="bold">1</mn>
                  </mrow>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mo fence="false" stretchy="false">&#x2308;<!-- ⌈ --></mo>
                    <msup>
                      <mn>2</mn>
                      <mrow class="MJX-TeXAtom-ORD">
                        <msub>
                          <mi>k</mi>
                          <mrow class="MJX-TeXAtom-ORD">
                            <mi>j</mi>
                          </mrow>
                        </msub>
                      </mrow>
                    </msup>
                    <msub>
                      <mi>x</mi>
                      <mrow class="MJX-TeXAtom-ORD">
                        <mi>j</mi>
                      </mrow>
                    </msub>
                    <mo fence="false" stretchy="false">&#x2309;<!-- ⌉ --></mo>
                    <mo>=</mo>
                    <mo fence="false" stretchy="false">&#x2308;<!-- ⌈ --></mo>
                    <msup>
                      <mn>2</mn>
                      <mrow class="MJX-TeXAtom-ORD">
                        <msub>
                          <mi>k</mi>
                          <mrow class="MJX-TeXAtom-ORD">
                            <mi>j</mi>
                          </mrow>
                        </msub>
                      </mrow>
                    </msup>
                    <msub>
                      <mi>z</mi>
                      <mrow class="MJX-TeXAtom-ORD">
                        <mi>j</mi>
                      </mrow>
                    </msub>
                    <mo fence="false" stretchy="false">&#x2309;<!-- ⌉ --></mo>
                  </mrow>
                </msub>
                <mo>,</mo>
              </mtd>
            </mtr>
            <mtr>
              <mtd />
              <mtd>
                <mrow class="MJX-TeXAtom-ORD">
                  <mtext>&#xA0;for all&#xA0;</mtext>
                </mrow>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi mathvariant="bold">x</mi>
                </mrow>
                <mo>,</mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi mathvariant="bold">z</mi>
                </mrow>
                <mo>&#x2208;<!-- ∈ --></mo>
                <mo stretchy="false">[</mo>
                <mn>0</mn>
                <mo>,</mo>
                <mn>1</mn>
                <msup>
                  <mo stretchy="false">]</mo>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>d</mi>
                  </mrow>
                </msup>
                <mo>.</mo>
              </mtd>
            </mtr>
          </mtable>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\begin{aligned}K_{k}^{cc}(\mathbf {x} ,\mathbf {z} )=\sum _{k_{1},\ldots ,k_{d},\sum _{j=1}^{d}k_{j}=k}&amp;{\frac {k!}{k_{1}!\cdots k_{d}!}}\left({\frac {1}{d}}\right)^{k}\prod _{j=1}^{d}\mathbf {1} _{\lceil 2^{k_{j}}x_{j}\rceil =\lceil 2^{k_{j}}z_{j}\rceil },\\&amp;{\text{ for all }}\mathbf {x} ,\mathbf {z} \in [0,1]^{d}.\end{aligned}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c5c5223ec3c01012f989e01ac149302fbc49161d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -5.166ex; margin-bottom: -0.172ex; width:62.773ex; height:11.843ex;" alt="{\displaystyle {\begin{aligned}K_{k}^{cc}(\mathbf {x} ,\mathbf {z} )=\sum _{k_{1},\ldots ,k_{d},\sum _{j=1}^{d}k_{j}=k}&amp;{\frac {k!}{k_{1}!\cdots k_{d}!}}\left({\frac {1}{d}}\right)^{k}\prod _{j=1}^{d}\mathbf {1} _{\lceil 2^{k_{j}}x_{j}\rceil =\lceil 2^{k_{j}}z_{j}\rceil },\\&amp;{\text{ for all }}\mathbf {x} ,\mathbf {z} \in [0,1]^{d}.\end{aligned}}}"/></span></dd></dl>
<h4><span class="mw-headline" id="Uniform_KeRF">Uniform KeRF</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=19" title="Edit section: Uniform KeRF">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Uniform KeRF is built in the same way as uniform forest, except that predictions are made by <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\tilde {m}}_{M,n}(\mathbf {x} ,\Theta _{1},\ldots ,\Theta _{M})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>m</mi>
                <mo stretchy="false">&#x007E;<!-- ~ --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>M</mi>
            <mo>,</mo>
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo>,</mo>
        <msub>
          <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>,</mo>
        <mo>&#x2026;<!-- … --></mo>
        <mo>,</mo>
        <msub>
          <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>M</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\tilde {m}}_{M,n}(\mathbf {x} ,\Theta _{1},\ldots ,\Theta _{M})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3939edfe84d8ece5969248f08b77f0b23843ad3e" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -1.005ex; width:21.505ex; height:3.009ex;" alt="{\tilde  {m}}_{{M,n}}({\mathbf  {x}},\Theta _{1},\ldots ,\Theta _{M})"/></span>, the corresponding kernel function, or connection function is
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle K_{k}^{uf}(\mathbf {0} ,\mathbf {x} )=\sum _{k_{1},\ldots ,k_{d},\sum _{j=1}^{d}k_{j}=k}{\frac {k!}{k_{1}!\ldots k_{d}!}}\left({\frac {1}{d}}\right)^{k}\prod _{m=1}^{d}\left(1-|x_{m}|\sum _{j=0}^{k_{m}-1}{\frac {(-\ln |x_{m}|)^{j}}{j!}}\right){\text{ for all }}\mathbf {x} \in [0,1]^{d}.}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msubsup>
          <mi>K</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>u</mi>
            <mi>f</mi>
          </mrow>
        </msubsup>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mn mathvariant="bold">0</mn>
        </mrow>
        <mo>,</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <munder>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <msub>
              <mi>k</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mn>1</mn>
              </mrow>
            </msub>
            <mo>,</mo>
            <mo>&#x2026;<!-- … --></mo>
            <mo>,</mo>
            <msub>
              <mi>k</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>d</mi>
              </mrow>
            </msub>
            <mo>,</mo>
            <munderover>
              <mo>&#x2211;<!-- ∑ --></mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>j</mi>
                <mo>=</mo>
                <mn>1</mn>
              </mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>d</mi>
              </mrow>
            </munderover>
            <msub>
              <mi>k</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>j</mi>
              </mrow>
            </msub>
            <mo>=</mo>
            <mi>k</mi>
          </mrow>
        </munder>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mi>k</mi>
              <mo>!</mo>
            </mrow>
            <mrow>
              <msub>
                <mi>k</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>1</mn>
                </mrow>
              </msub>
              <mo>!</mo>
              <mo>&#x2026;<!-- … --></mo>
              <msub>
                <mi>k</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>d</mi>
                </mrow>
              </msub>
              <mo>!</mo>
            </mrow>
          </mfrac>
        </mrow>
        <msup>
          <mrow>
            <mo>(</mo>
            <mrow class="MJX-TeXAtom-ORD">
              <mfrac>
                <mn>1</mn>
                <mi>d</mi>
              </mfrac>
            </mrow>
            <mo>)</mo>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msup>
        <munderover>
          <mo>&#x220F;<!-- ∏ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>m</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>d</mi>
          </mrow>
        </munderover>
        <mrow>
          <mo>(</mo>
          <mrow>
            <mn>1</mn>
            <mo>&#x2212;<!-- − --></mo>
            <mrow class="MJX-TeXAtom-ORD">
              <mo stretchy="false">|</mo>
            </mrow>
            <msub>
              <mi>x</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>m</mi>
              </mrow>
            </msub>
            <mrow class="MJX-TeXAtom-ORD">
              <mo stretchy="false">|</mo>
            </mrow>
            <munderover>
              <mo>&#x2211;<!-- ∑ --></mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>j</mi>
                <mo>=</mo>
                <mn>0</mn>
              </mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <msub>
                  <mi>k</mi>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mi>m</mi>
                  </mrow>
                </msub>
                <mo>&#x2212;<!-- − --></mo>
                <mn>1</mn>
              </mrow>
            </munderover>
            <mrow class="MJX-TeXAtom-ORD">
              <mfrac>
                <mrow>
                  <mo stretchy="false">(</mo>
                  <mo>&#x2212;<!-- − --></mo>
                  <mi>ln</mi>
                  <mo>&#x2061;<!-- ⁡ --></mo>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mo stretchy="false">|</mo>
                  </mrow>
                  <msub>
                    <mi>x</mi>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mi>m</mi>
                    </mrow>
                  </msub>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mo stretchy="false">|</mo>
                  </mrow>
                  <msup>
                    <mo stretchy="false">)</mo>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mi>j</mi>
                    </mrow>
                  </msup>
                </mrow>
                <mrow>
                  <mi>j</mi>
                  <mo>!</mo>
                </mrow>
              </mfrac>
            </mrow>
          </mrow>
          <mo>)</mo>
        </mrow>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>&#xA0;for all&#xA0;</mtext>
        </mrow>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo>&#x2208;<!-- ∈ --></mo>
        <mo stretchy="false">[</mo>
        <mn>0</mn>
        <mo>,</mo>
        <mn>1</mn>
        <msup>
          <mo stretchy="false">]</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>d</mi>
          </mrow>
        </msup>
        <mo>.</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle K_{k}^{uf}(\mathbf {0} ,\mathbf {x} )=\sum _{k_{1},\ldots ,k_{d},\sum _{j=1}^{d}k_{j}=k}{\frac {k!}{k_{1}!\ldots k_{d}!}}\left({\frac {1}{d}}\right)^{k}\prod _{m=1}^{d}\left(1-|x_{m}|\sum _{j=0}^{k_{m}-1}{\frac {(-\ln |x_{m}|)^{j}}{j!}}\right){\text{ for all }}\mathbf {x} \in [0,1]^{d}.}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/579a334c0c00016a31e72f5376399c37a30a12b7" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -4.338ex; width:96.713ex; height:8.676ex;" alt="{\displaystyle K_{k}^{uf}(\mathbf {0} ,\mathbf {x} )=\sum _{k_{1},\ldots ,k_{d},\sum _{j=1}^{d}k_{j}=k}{\frac {k!}{k_{1}!\ldots k_{d}!}}\left({\frac {1}{d}}\right)^{k}\prod _{m=1}^{d}\left(1-|x_{m}|\sum _{j=0}^{k_{m}-1}{\frac {(-\ln |x_{m}|)^{j}}{j!}}\right){\text{ for all }}\mathbf {x} \in [0,1]^{d}.}"/></span></dd></dl>
<h3><span class="mw-headline" id="Properties_2">Properties</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=20" title="Edit section: Properties">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<h4><span class="mw-headline" id="Relation_between_KeRF_and_random_forest">Relation between KeRF and random forest</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=21" title="Edit section: Relation between KeRF and random forest">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Predictions given by KeRF and random forests are close if the number of points in each cell is controlled:
</p>
<blockquote>
<p>Assume that there exist sequences <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle (a_{n}),(b_{n})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo stretchy="false">(</mo>
        <msub>
          <mi>a</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>,</mo>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>b</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle (a_{n}),(b_{n})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6d8157b9b64afbd714b16ed6b8de06c32afb696a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:9.317ex; height:2.843ex;" alt="{\displaystyle (a_{n}),(b_{n})}"/></span> such that, almost surely,
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle a_{n}\leq N_{n}(\mathbf {x} ,\Theta )\leq b_{n}{\text{ and }}a_{n}\leq {\frac {1}{M}}\sum _{m=1}^{M}N_{n}{\mathbf {x} ,\Theta _{m}}\leq b_{n}.}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>a</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo>&#x2264;<!-- ≤ --></mo>
        <msub>
          <mi>N</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo>,</mo>
        <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
        <mo stretchy="false">)</mo>
        <mo>&#x2264;<!-- ≤ --></mo>
        <msub>
          <mi>b</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mrow class="MJX-TeXAtom-ORD">
          <mtext>&#xA0;and&#xA0;</mtext>
        </mrow>
        <msub>
          <mi>a</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo>&#x2264;<!-- ≤ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <mi>M</mi>
          </mfrac>
        </mrow>
        <munderover>
          <mo>&#x2211;<!-- ∑ --></mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>m</mi>
            <mo>=</mo>
            <mn>1</mn>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>M</mi>
          </mrow>
        </munderover>
        <msub>
          <mi>N</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="bold">x</mi>
          </mrow>
          <mo>,</mo>
          <msub>
            <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
            <mrow class="MJX-TeXAtom-ORD">
              <mi>m</mi>
            </mrow>
          </msub>
        </mrow>
        <mo>&#x2264;<!-- ≤ --></mo>
        <msub>
          <mi>b</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo>.</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle a_{n}\leq N_{n}(\mathbf {x} ,\Theta )\leq b_{n}{\text{ and }}a_{n}\leq {\frac {1}{M}}\sum _{m=1}^{M}N_{n}{\mathbf {x} ,\Theta _{m}}\leq b_{n}.}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/139dc876ec018ffab1c1d499f269b95a6e8c245a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.005ex; width:53.034ex; height:7.343ex;" alt="{\displaystyle a_{n}\leq N_{n}(\mathbf {x} ,\Theta )\leq b_{n}{\text{ and }}a_{n}\leq {\frac {1}{M}}\sum _{m=1}^{M}N_{n}{\mathbf {x} ,\Theta _{m}}\leq b_{n}.}"/></span></dd></dl>
<p>Then almost surely,
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle |m_{M,n}(\mathbf {x} )-{\tilde {m}}_{M,n}(\mathbf {x} )|\leq {\frac {b_{n}-a_{n}}{a_{n}}}{\tilde {m}}_{M,n}(\mathbf {x} ).}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <msub>
          <mi>m</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>M</mi>
            <mo>,</mo>
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo>&#x2212;<!-- − --></mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>m</mi>
                <mo stretchy="false">&#x007E;<!-- ~ --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>M</mi>
            <mo>,</mo>
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo stretchy="false">)</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mo>&#x2264;<!-- ≤ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <msub>
                <mi>b</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>n</mi>
                </mrow>
              </msub>
              <mo>&#x2212;<!-- − --></mo>
              <msub>
                <mi>a</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>n</mi>
                </mrow>
              </msub>
            </mrow>
            <msub>
              <mi>a</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>n</mi>
              </mrow>
            </msub>
          </mfrac>
        </mrow>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>m</mi>
                <mo stretchy="false">&#x007E;<!-- ~ --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>M</mi>
            <mo>,</mo>
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo>.</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle |m_{M,n}(\mathbf {x} )-{\tilde {m}}_{M,n}(\mathbf {x} )|\leq {\frac {b_{n}-a_{n}}{a_{n}}}{\tilde {m}}_{M,n}(\mathbf {x} ).}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ad592965613268c7026f8f57701caba977fd34ed" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.171ex; width:42.21ex; height:5.676ex;" alt="{\displaystyle |m_{M,n}(\mathbf {x} )-{\tilde {m}}_{M,n}(\mathbf {x} )|\leq {\frac {b_{n}-a_{n}}{a_{n}}}{\tilde {m}}_{M,n}(\mathbf {x} ).}"/></span></dd></dl>
</blockquote>
<h4><span class="mw-headline" id="Relation_between_infinite_KeRF_and_infinite_random_forest">Relation between infinite KeRF and infinite random forest</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=22" title="Edit section: Relation between infinite KeRF and infinite random forest">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>When the number of trees <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle M}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>M</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle M}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f82cade9898ced02fdd08712e5f0c0151758a0dd" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:2.442ex; height:2.176ex;" alt="M"/></span> goes to infinity, then we have infinite random forest and infinite KeRF. Their estimates are close if the number of observations in each cell is bounded:
</p>
<blockquote>
<p>Assume that there exist sequences <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle (\varepsilon _{n}),(a_{n}),(b_{n})}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo stretchy="false">(</mo>
        <msub>
          <mi>&#x03B5;<!-- ε --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>,</mo>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>a</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
        <mo>,</mo>
        <mo stretchy="false">(</mo>
        <msub>
          <mi>b</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle (\varepsilon _{n}),(a_{n}),(b_{n})}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/67e5f769151263bad5a8d716a2c6af2686687855" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:14.462ex; height:2.843ex;" alt="{\displaystyle (\varepsilon _{n}),(a_{n}),(b_{n})}"/></span> such that, almost surely
</p>
<ul><li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \operatorname {E} [N_{n}(\mathbf {x} ,\Theta )]\geq 1,}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi mathvariant="normal">E</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mo stretchy="false">[</mo>
        <msub>
          <mi>N</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo>,</mo>
        <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">]</mo>
        <mo>&#x2265;<!-- ≥ --></mo>
        <mn>1</mn>
        <mo>,</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \operatorname {E} [N_{n}(\mathbf {x} ,\Theta )]\geq 1,}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/07f5beb5ef7860bc9f527fb5b01fbed3dc0fc716" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:16.931ex; height:2.843ex;" alt="{\displaystyle \operatorname {E} [N_{n}(\mathbf {x} ,\Theta )]\geq 1,}"/></span></li>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \operatorname {P} [a_{n}\leq N_{n}(\mathbf {x} ,\Theta )\leq b_{n}\mid {\mathcal {D}}_{n}]\geq 1-\varepsilon _{n}/2,}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi mathvariant="normal">P</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mo stretchy="false">[</mo>
        <msub>
          <mi>a</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo>&#x2264;<!-- ≤ --></mo>
        <msub>
          <mi>N</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo>,</mo>
        <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
        <mo stretchy="false">)</mo>
        <mo>&#x2264;<!-- ≤ --></mo>
        <msub>
          <mi>b</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo>&#x2223;<!-- ∣ --></mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mi class="MJX-tex-caligraphic" mathvariant="script">D</mi>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">]</mo>
        <mo>&#x2265;<!-- ≥ --></mo>
        <mn>1</mn>
        <mo>&#x2212;<!-- − --></mo>
        <msub>
          <mi>&#x03B5;<!-- ε --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <mn>2</mn>
        <mo>,</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \operatorname {P} [a_{n}\leq N_{n}(\mathbf {x} ,\Theta )\leq b_{n}\mid {\mathcal {D}}_{n}]\geq 1-\varepsilon _{n}/2,}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4bad78155a4139322247009072e48d6b7bf8c5b9" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:40.207ex; height:2.843ex;" alt="{\displaystyle \operatorname {P} [a_{n}\leq N_{n}(\mathbf {x} ,\Theta )\leq b_{n}\mid {\mathcal {D}}_{n}]\geq 1-\varepsilon _{n}/2,}"/></span></li>
<li><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \operatorname {P} [a_{n}\leq \operatorname {E} _{\Theta }[N_{n}(\mathbf {x} ,\Theta )]\leq b_{n}\mid {\mathcal {D}}_{n}]\geq 1-\varepsilon _{n}/2,}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi mathvariant="normal">P</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mo stretchy="false">[</mo>
        <msub>
          <mi>a</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo>&#x2264;<!-- ≤ --></mo>
        <msub>
          <mi mathvariant="normal">E</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
          </mrow>
        </msub>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mo stretchy="false">[</mo>
        <msub>
          <mi>N</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo>,</mo>
        <mi mathvariant="normal">&#x0398;<!-- Θ --></mi>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">]</mo>
        <mo>&#x2264;<!-- ≤ --></mo>
        <msub>
          <mi>b</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo>&#x2223;<!-- ∣ --></mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mi class="MJX-tex-caligraphic" mathvariant="script">D</mi>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">]</mo>
        <mo>&#x2265;<!-- ≥ --></mo>
        <mn>1</mn>
        <mo>&#x2212;<!-- − --></mo>
        <msub>
          <mi>&#x03B5;<!-- ε --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <mn>2</mn>
        <mo>,</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \operatorname {P} [a_{n}\leq \operatorname {E} _{\Theta }[N_{n}(\mathbf {x} ,\Theta )]\leq b_{n}\mid {\mathcal {D}}_{n}]\geq 1-\varepsilon _{n}/2,}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/71711062ff59f3d2075162074e8f94f917a0cdad" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:44.595ex; height:2.843ex;" alt="{\displaystyle \operatorname {P} [a_{n}\leq \operatorname {E} _{\Theta }[N_{n}(\mathbf {x} ,\Theta )]\leq b_{n}\mid {\mathcal {D}}_{n}]\geq 1-\varepsilon _{n}/2,}"/></span></li></ul>
<p>Then almost surely,
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle |m_{\infty ,n}(\mathbf {x} )-{\tilde {m}}_{\infty ,n}(\mathbf {x} )|\leq {\frac {b_{n}-a_{n}}{a_{n}}}{\tilde {m}}_{\infty ,n}(\mathbf {x} )+n\varepsilon _{n}\left(\max _{1\leq i\leq n}Y_{i}\right).}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <msub>
          <mi>m</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
            <mo>,</mo>
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo>&#x2212;<!-- − --></mo>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>m</mi>
                <mo stretchy="false">&#x007E;<!-- ~ --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
            <mo>,</mo>
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo stretchy="false">)</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mo stretchy="false">|</mo>
        </mrow>
        <mo>&#x2264;<!-- ≤ --></mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <msub>
                <mi>b</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>n</mi>
                </mrow>
              </msub>
              <mo>&#x2212;<!-- − --></mo>
              <msub>
                <mi>a</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>n</mi>
                </mrow>
              </msub>
            </mrow>
            <msub>
              <mi>a</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>n</mi>
              </mrow>
            </msub>
          </mfrac>
        </mrow>
        <msub>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>m</mi>
                <mo stretchy="false">&#x007E;<!-- ~ --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
            <mo>,</mo>
            <mi>n</mi>
          </mrow>
        </msub>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">x</mi>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo>+</mo>
        <mi>n</mi>
        <msub>
          <mi>&#x03B5;<!-- ε --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
        </msub>
        <mrow>
          <mo>(</mo>
          <mrow>
            <munder>
              <mo movablelimits="true" form="prefix">max</mo>
              <mrow class="MJX-TeXAtom-ORD">
                <mn>1</mn>
                <mo>&#x2264;<!-- ≤ --></mo>
                <mi>i</mi>
                <mo>&#x2264;<!-- ≤ --></mo>
                <mi>n</mi>
              </mrow>
            </munder>
            <msub>
              <mi>Y</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>i</mi>
              </mrow>
            </msub>
          </mrow>
          <mo>)</mo>
        </mrow>
        <mo>.</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle |m_{\infty ,n}(\mathbf {x} )-{\tilde {m}}_{\infty ,n}(\mathbf {x} )|\leq {\frac {b_{n}-a_{n}}{a_{n}}}{\tilde {m}}_{\infty ,n}(\mathbf {x} )+n\varepsilon _{n}\left(\max _{1\leq i\leq n}Y_{i}\right).}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/26197c8d5ca305f9a7a922c4227c5daa11350e76" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.505ex; width:60.162ex; height:6.176ex;" alt="{\displaystyle |m_{\infty ,n}(\mathbf {x} )-{\tilde {m}}_{\infty ,n}(\mathbf {x} )|\leq {\frac {b_{n}-a_{n}}{a_{n}}}{\tilde {m}}_{\infty ,n}(\mathbf {x} )+n\varepsilon _{n}\left(\max _{1\leq i\leq n}Y_{i}\right).}"/></span></dd></dl>
</blockquote>
<h3><span class="mw-headline" id="Consistency_results">Consistency results</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=23" title="Edit section: Consistency results">edit</a><span class="mw-editsection-bracket">]</span></span></h3>
<p>Assume that <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle Y=m(\mathbf {X} )+\varepsilon }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>Y</mi>
        <mo>=</mo>
        <mi>m</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">X</mi>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo>+</mo>
        <mi>&#x03B5;<!-- ε --></mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle Y=m(\mathbf {X} )+\varepsilon }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d8617bcdd783f680a6c45c9d8c627a5730a878e5" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:14.665ex; height:2.843ex;" alt="Y=m({\mathbf  {X}})+\varepsilon "/></span>, where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \varepsilon }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>&#x03B5;<!-- ε --></mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \varepsilon }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a30c89172e5b88edbd45d3e2772c7f5e562e5173" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.083ex; height:1.676ex;" alt="\varepsilon "/></span> is a centered Gaussian noise, independent of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mathbf {X} }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">X</mi>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mathbf {X} }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9f75966a2f9d5672136fa9401ee1e75008f95ffd" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:2.019ex; height:2.176ex;" alt="\mathbf {X} "/></span>, with finite variance <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \sigma ^{2}&lt;\infty }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mi>&#x03C3;<!-- σ --></mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msup>
        <mo>&lt;</mo>
        <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \sigma ^{2}&lt;\infty }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f9c01c50d5825dbb5b11add552a422af72a9664f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:7.807ex; height:2.676ex;" alt="\sigma ^{2}&lt;\infty "/></span>. Moreover, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mathbf {X} }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">X</mi>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mathbf {X} }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9f75966a2f9d5672136fa9401ee1e75008f95ffd" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:2.019ex; height:2.176ex;" alt="\mathbf {X} "/></span> is uniformly distributed on <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle [0,1]^{d}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo stretchy="false">[</mo>
        <mn>0</mn>
        <mo>,</mo>
        <mn>1</mn>
        <msup>
          <mo stretchy="false">]</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>d</mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle [0,1]^{d}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e13ae4917276744b214714a20b3cb8ee305e309d" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:5.745ex; height:3.176ex;" alt="[0,1]^{d}"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle m}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>m</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle m}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0a07d98bb302f3856cbabc47b2b9016692e3f7bc" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:2.04ex; height:1.676ex;" alt="m"/></span> is <a href="/wiki/Lipschitz" title="Lipschitz">Lipschitz</a>. Scornet<sup id="cite_ref-scornet2015random_27-3" class="reference"><a href="#cite_note-scornet2015random-27">&#91;27&#93;</a></sup> proved upper bounds on the rates of consistency for centered KeRF and uniform KeRF.
</p>
<h4><span class="mw-headline" id="Consistency_of_centered_KeRF">Consistency of centered KeRF</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=24" title="Edit section: Consistency of centered KeRF">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Providing <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle k\rightarrow \infty }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>k</mi>
        <mo stretchy="false">&#x2192;<!-- → --></mo>
        <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle k\rightarrow \infty }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/612a3ec99f1c9f12de1cfab011e306ae799858ce" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:7.149ex; height:2.176ex;" alt="k\rightarrow\infty"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle n/2^{k}\rightarrow \infty }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>n</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <msup>
          <mn>2</mn>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msup>
        <mo stretchy="false">&#x2192;<!-- → --></mo>
        <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle n/2^{k}\rightarrow \infty }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9fbec163fbc2ac671e4c9f78bdc70a985599dc19" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:10.746ex; height:3.176ex;" alt="n/2^{k}\rightarrow \infty "/></span>, there exists a constant <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle C_{1}&gt;0}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <mo>&gt;</mo>
        <mn>0</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C_{1}&gt;0}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c7f2ff302742806f4db7411f29e54944b4d9bda7" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:6.977ex; height:2.509ex;" alt="C_{1}&gt;0"/></span> such that, for all <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle n}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>n</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle n}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.395ex; height:1.676ex;" alt="n"/></span>,
<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mathbb {E} [{\tilde {m}}_{n}^{cc}(\mathbf {X} )-m(\mathbf {X} )]^{2}\leq C_{1}n^{-1/(3+d\log 2)}(\log n)^{2}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="double-struck">E</mi>
        </mrow>
        <mo stretchy="false">[</mo>
        <msubsup>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>m</mi>
                <mo stretchy="false">&#x007E;<!-- ~ --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>c</mi>
            <mi>c</mi>
          </mrow>
        </msubsup>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">X</mi>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo>&#x2212;<!-- − --></mo>
        <mi>m</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">X</mi>
        </mrow>
        <mo stretchy="false">)</mo>
        <msup>
          <mo stretchy="false">]</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msup>
        <mo>&#x2264;<!-- ≤ --></mo>
        <msub>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>1</mn>
          </mrow>
        </msub>
        <msup>
          <mi>n</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
            <mrow class="MJX-TeXAtom-ORD">
              <mo>/</mo>
            </mrow>
            <mo stretchy="false">(</mo>
            <mn>3</mn>
            <mo>+</mo>
            <mi>d</mi>
            <mi>log</mi>
            <mo>&#x2061;<!-- ⁡ --></mo>
            <mn>2</mn>
            <mo stretchy="false">)</mo>
          </mrow>
        </msup>
        <mo stretchy="false">(</mo>
        <mi>log</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mi>n</mi>
        <msup>
          <mo stretchy="false">)</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mathbb {E} [{\tilde {m}}_{n}^{cc}(\mathbf {X} )-m(\mathbf {X} )]^{2}\leq C_{1}n^{-1/(3+d\log 2)}(\log n)^{2}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/bbd76dd80031cfdb1b8042faeab38ecaafefa2e3" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:46.051ex; height:3.343ex;" alt="{\mathbb  {E}}[{\tilde  {m}}_{n}^{{cc}}({\mathbf  {X}})-m({\mathbf  {X}})]^{2}\leq C_{1}n^{{-1/(3+d\log 2)}}(\log n)^{2}"/></span>.
</p>
<h4><span class="mw-headline" id="Consistency_of_uniform_KeRF">Consistency of uniform KeRF</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=25" title="Edit section: Consistency of uniform KeRF">edit</a><span class="mw-editsection-bracket">]</span></span></h4>
<p>Providing <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle k\rightarrow \infty }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>k</mi>
        <mo stretchy="false">&#x2192;<!-- → --></mo>
        <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle k\rightarrow \infty }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/612a3ec99f1c9f12de1cfab011e306ae799858ce" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:7.149ex; height:2.176ex;" alt="k\rightarrow\infty"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle n/2^{k}\rightarrow \infty }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>n</mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mo>/</mo>
        </mrow>
        <msup>
          <mn>2</mn>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>k</mi>
          </mrow>
        </msup>
        <mo stretchy="false">&#x2192;<!-- → --></mo>
        <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle n/2^{k}\rightarrow \infty }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9fbec163fbc2ac671e4c9f78bdc70a985599dc19" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:10.746ex; height:3.176ex;" alt="n/2^{k}\rightarrow \infty "/></span>, there exists a constant <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle C&gt;0}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>C</mi>
        <mo>&gt;</mo>
        <mn>0</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C&gt;0}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c84d4126c6df243734f9355927c026df6b0d3859" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:6.027ex; height:2.176ex;" alt="C&gt;0"/></span> such that,
<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \mathbb {E} [{\tilde {m}}_{n}^{uf}(\mathbf {X} )-m(\mathbf {X} )]^{2}\leq Cn^{-2/(6+3d\log 2)}(\log n)^{2}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="double-struck">E</mi>
        </mrow>
        <mo stretchy="false">[</mo>
        <msubsup>
          <mrow class="MJX-TeXAtom-ORD">
            <mrow class="MJX-TeXAtom-ORD">
              <mover>
                <mi>m</mi>
                <mo stretchy="false">&#x007E;<!-- ~ --></mo>
              </mover>
            </mrow>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>n</mi>
          </mrow>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>u</mi>
            <mi>f</mi>
          </mrow>
        </msubsup>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">X</mi>
        </mrow>
        <mo stretchy="false">)</mo>
        <mo>&#x2212;<!-- − --></mo>
        <mi>m</mi>
        <mo stretchy="false">(</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mi mathvariant="bold">X</mi>
        </mrow>
        <mo stretchy="false">)</mo>
        <msup>
          <mo stretchy="false">]</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msup>
        <mo>&#x2264;<!-- ≤ --></mo>
        <mi>C</mi>
        <msup>
          <mi>n</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>2</mn>
            <mrow class="MJX-TeXAtom-ORD">
              <mo>/</mo>
            </mrow>
            <mo stretchy="false">(</mo>
            <mn>6</mn>
            <mo>+</mo>
            <mn>3</mn>
            <mi>d</mi>
            <mi>log</mi>
            <mo>&#x2061;<!-- ⁡ --></mo>
            <mn>2</mn>
            <mo stretchy="false">)</mo>
          </mrow>
        </msup>
        <mo stretchy="false">(</mo>
        <mi>log</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mi>n</mi>
        <msup>
          <mo stretchy="false">)</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \mathbb {E} [{\tilde {m}}_{n}^{uf}(\mathbf {X} )-m(\mathbf {X} )]^{2}\leq Cn^{-2/(6+3d\log 2)}(\log n)^{2}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/51b3c9f4980f936fc01a73621cc56e9857059da4" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:46.344ex; height:3.343ex;" alt="{\mathbb  {E}}[{\tilde  {m}}_{n}^{{uf}}({\mathbf  {X}})-m({\mathbf  {X}})]^{2}\leq Cn^{{-2/(6+3d\log 2)}}(\log n)^{2}"/></span>.
</p>
<h2><span class="mw-headline" id="RF_in_scientific_works">RF in scientific works</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=26" title="Edit section: RF in scientific works">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<table class="box-Expand_section plainlinks metadata ambox ambox-content" role="presentation"><tbody><tr><td class="mbox-image"><div style="width:52px"><a href="/wiki/File:Wiki_letter_w_cropped.svg" class="image"><img alt="[icon]" src="//upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/44px-Wiki_letter_w_cropped.svg.png" decoding="async" width="44" height="31" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/66px-Wiki_letter_w_cropped.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Wiki_letter_w_cropped.svg/88px-Wiki_letter_w_cropped.svg.png 2x" data-file-width="44" data-file-height="31" /></a></div></td><td class="mbox-text"><div class="mbox-text-span">This section <b>needs expansion</b>&#32;with: additional examples and clarification. <small>You can help by <a class="external text" href="https://en.wikipedia.org/w/index.php?title=Random_forest&amp;action=edit&amp;section=">adding to it</a>.</small><span class="hide-when-compact"> Relevant discussion may be found on the <a href="/wiki/Talk:Random_forest#Expand_section" title="Talk:Random forest">talk page</a>.</span>  <small class="date-container"><i>(<span class="date">February 2019</span>)</i></small></div></td></tr></tbody></table>
<p>The algorithm is often used in scientific works because of its advantages. For example, it can be used for quality assessment of <a href="/wiki/Wikipedia" title="Wikipedia">Wikipedia</a> articles.<sup id="cite_ref-33" class="reference"><a href="#cite_note-33">&#91;33&#93;</a></sup><sup id="cite_ref-34" class="reference"><a href="#cite_note-34">&#91;34&#93;</a></sup><sup id="cite_ref-35" class="reference"><a href="#cite_note-35">&#91;35&#93;</a></sup>
</p>
<h2><span class="mw-headline" id="Open_source_implementations">Open source implementations</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=27" title="Edit section: Open source implementations">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a rel="nofollow" class="external text" href="http://www.stat.berkeley.edu/~breiman/RandomForests/cc_software.htm">The Original RF</a> by Breiman and Cutler written in Fortran 77.</li>
<li><a rel="nofollow" class="external text" href="http://www.alglib.net/dataanalysis/decisionforest.php">ALGLIB</a> contains a modification of the random forest in C#, C++, Pascal, VBA.</li>
<li><a rel="nofollow" class="external text" href="http://cran.r-project.org/web/packages/party/index.html">party</a> Implementation based on the conditional inference trees in <a href="/wiki/R_(programming_language)" title="R (programming language)">R</a>.</li>
<li><a rel="nofollow" class="external text" href="http://cran.r-project.org/web/packages/randomForest/index.html">randomForest</a> for classification and regression in <a href="/wiki/R_(programming_language)" title="R (programming language)">R</a>.</li>
<li><a rel="nofollow" class="external text" href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html">Python implementation</a> with examples in <a href="/wiki/Scikit-learn" title="Scikit-learn">scikit-learn</a>.</li>
<li><a href="/wiki/Orange_(software)" title="Orange (software)">Orange data mining</a> suite includes random forest learner and can visualize the trained forest.</li>
<li><a rel="nofollow" class="external text" href="https://code.google.com/p/randomforest-matlab">Matlab</a> implementation.</li>
<li><a rel="nofollow" class="external text" href="http://sqp.upf.edu">SQP</a> software uses random forest algorithm to predict the quality of survey questions, depending on formal and linguistic characteristics of the question.</li>
<li><a rel="nofollow" class="external text" href="http://weka.sourceforge.net/doc.dev/weka/classifiers/trees/RandomForest.html">Weka RandomForest</a> in Java library and GUI.</li>
<li><a rel="nofollow" class="external text" href="https://github.com/imbs-hl/ranger">ranger</a> A C++ implementation of random forest for classification, regression, probability and survival. Includes interface for <a href="/wiki/R_(programming_language)" title="R (programming language)">R</a>.</li></ul>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=28" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a href="/wiki/Boosting_(machine_learning)" title="Boosting (machine learning)">Boosting</a></li>
<li><a href="/wiki/Decision_tree_learning" title="Decision tree learning">Decision tree learning</a></li>
<li><a href="/wiki/Ensemble_learning" title="Ensemble learning">Ensemble learning</a></li>
<li><a href="/wiki/Gradient_boosting" title="Gradient boosting">Gradient boosting</a></li>
<li><a href="/wiki/Non-parametric_statistics" class="mw-redirect" title="Non-parametric statistics">Non-parametric statistics</a></li>
<li><a href="/wiki/Randomized_algorithm" title="Randomized algorithm">Randomized algorithm</a></li></ul>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=29" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<div class="reflist columns references-column-width" style="-moz-column-width: 32em; -webkit-column-width: 32em; column-width: 32em; list-style-type: decimal;">
<ol class="references">
<li id="cite_note-ho1995-1"><span class="mw-cite-backlink">^ <a href="#cite_ref-ho1995_1-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-ho1995_1-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-ho1995_1-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-ho1995_1-3"><sup><i><b>d</b></i></sup></a></span> <span class="reference-text"><cite id="CITEREFHo1995" class="citation conference">Ho, Tin Kam (1995). <a rel="nofollow" class="external text" href="https://web.archive.org/web/20160417030218/http://ect.bell-labs.com/who/tkh/publications/papers/odt.pdf"><i>Random Decision Forests</i></a> <span class="cs1-format">(PDF)</span>. Proceedings of the 3rd International Conference on Document Analysis and Recognition, Montreal, QC, 14–16 August 1995. pp.&#160;278–282. Archived from <a rel="nofollow" class="external text" href="http://ect.bell-labs.com/who/tkh/publications/papers/odt.pdf">the original</a> <span class="cs1-format">(PDF)</span> on 17 April 2016<span class="reference-accessdate">. Retrieved <span class="nowrap">5 June</span> 2016</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=Random+Decision+Forests&amp;rft.pages=278-282&amp;rft.date=1995&amp;rft.aulast=Ho&amp;rft.aufirst=Tin+Kam&amp;rft_id=http%3A%2F%2Fect.bell-labs.com%2Fwho%2Ftkh%2Fpublications%2Fpapers%2Fodt.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><style data-mw-deduplicate="TemplateStyles:r951705291">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background-image:url("//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png");background-image:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg");background-repeat:no-repeat;background-size:9px;background-position:right .1em center}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background-image:url("//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png");background-image:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg");background-repeat:no-repeat;background-size:9px;background-position:right .1em center}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background-image:url("//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png");background-image:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg");background-repeat:no-repeat;background-size:9px;background-position:right .1em center}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background-image:url("//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/12px-Wikisource-logo.svg.png");background-image:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg");background-repeat:no-repeat;background-size:12px;background-position:right .1em center}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}</style></span>
</li>
<li id="cite_note-ho1998-2"><span class="mw-cite-backlink">^ <a href="#cite_ref-ho1998_2-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-ho1998_2-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-ho1998_2-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-ho1998_2-3"><sup><i><b>d</b></i></sup></a></span> <span class="reference-text"><cite id="CITEREFHo1998" class="citation journal">Ho TK (1998). <a rel="nofollow" class="external text" href="http://ect.bell-labs.com/who/tkh/publications/papers/df.pdf">"The Random Subspace Method for Constructing Decision Forests"</a> <span class="cs1-format">(PDF)</span>. <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>. <b>20</b> (8): 832–844. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2F34.709601">10.1109/34.709601</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Pattern+Analysis+and+Machine+Intelligence&amp;rft.atitle=The+Random+Subspace+Method+for+Constructing+Decision+Forests&amp;rft.volume=20&amp;rft.issue=8&amp;rft.pages=832-844&amp;rft.date=1998&amp;rft_id=info%3Adoi%2F10.1109%2F34.709601&amp;rft.aulast=Ho&amp;rft.aufirst=Tin+Kam&amp;rft_id=http%3A%2F%2Fect.bell-labs.com%2Fwho%2Ftkh%2Fpublications%2Fpapers%2Fdf.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-elemstatlearn-3"><span class="mw-cite-backlink">^ <a href="#cite_ref-elemstatlearn_3-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-elemstatlearn_3-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-elemstatlearn_3-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-elemstatlearn_3-3"><sup><i><b>d</b></i></sup></a> <a href="#cite_ref-elemstatlearn_3-4"><sup><i><b>e</b></i></sup></a> <a href="#cite_ref-elemstatlearn_3-5"><sup><i><b>f</b></i></sup></a></span> <span class="reference-text"><cite id="CITEREFHastieTibshiraniFriedman2008" class="citation book"><a href="/wiki/Trevor_Hastie" title="Trevor Hastie">Hastie, Trevor</a>; <a href="/wiki/Robert_Tibshirani" title="Robert Tibshirani">Tibshirani, Robert</a>; <a href="/wiki/Jerome_H._Friedman" title="Jerome H. Friedman">Friedman, Jerome</a> (2008). <a rel="nofollow" class="external text" href="http://www-stat.stanford.edu/~tibs/ElemStatLearn/"><i>The Elements of Statistical Learning</i></a> (2nd ed.). Springer. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/0-387-95284-5" title="Special:BookSources/0-387-95284-5"><bdi>0-387-95284-5</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Elements+of+Statistical+Learning&amp;rft.edition=2nd&amp;rft.pub=Springer&amp;rft.date=2008&amp;rft.isbn=0-387-95284-5&amp;rft.aulast=Hastie&amp;rft.aufirst=Trevor&amp;rft.au=Tibshirani%2C+Robert&amp;rft.au=Friedman%2C+Jerome&amp;rft_id=http%3A%2F%2Fwww-stat.stanford.edu%2F~tibs%2FElemStatLearn%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-kleinberg1990-4"><span class="mw-cite-backlink">^ <a href="#cite_ref-kleinberg1990_4-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-kleinberg1990_4-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite id="CITEREFKleinberg1990" class="citation journal">Kleinberg E (1990). <a rel="nofollow" class="external text" href="https://pdfs.semanticscholar.org/faa4/c502a824a9d64bf3dc26eb90a2c32367921f.pdf">"Stochastic Discrimination"</a> <span class="cs1-format">(PDF)</span>. <i><a href="/w/index.php?title=Annals_of_Mathematics_and_Artificial_Intelligence&amp;action=edit&amp;redlink=1" class="new" title="Annals of Mathematics and Artificial Intelligence (page does not exist)">Annals of Mathematics and Artificial Intelligence</a></i>. <b>1</b> (1–4): 207–239. <a href="/wiki/CiteSeerX_(identifier)" class="mw-redirect" title="CiteSeerX (identifier)">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.25.6750">10.1.1.25.6750</a></span>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2FBF01531079">10.1007/BF01531079</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Annals+of+Mathematics+and+Artificial+Intelligence&amp;rft.atitle=Stochastic+Discrimination&amp;rft.volume=1&amp;rft.issue=1%E2%80%934&amp;rft.pages=207-239&amp;rft.date=1990&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.25.6750&amp;rft_id=info%3Adoi%2F10.1007%2FBF01531079&amp;rft.aulast=Kleinberg&amp;rft.aufirst=Eugene&amp;rft_id=https%3A%2F%2Fpdfs.semanticscholar.org%2Ffaa4%2Fc502a824a9d64bf3dc26eb90a2c32367921f.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-kleinberg1996-5"><span class="mw-cite-backlink">^ <a href="#cite_ref-kleinberg1996_5-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-kleinberg1996_5-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite id="CITEREFKleinberg1996" class="citation journal">Kleinberg E (1996). "An Overtraining-Resistant Stochastic Modeling Method for Pattern Recognition". <i><a href="/wiki/Annals_of_Statistics" title="Annals of Statistics">Annals of Statistics</a></i>. <b>24</b> (6): 2319–2349. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1214%2Faos%2F1032181157">10.1214/aos/1032181157</a></span>. <a href="/wiki/MR_(identifier)" class="mw-redirect" title="MR (identifier)">MR</a>&#160;<a rel="nofollow" class="external text" href="//www.ams.org/mathscinet-getitem?mr=1425956">1425956</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Annals+of+Statistics&amp;rft.atitle=An+Overtraining-Resistant+Stochastic+Modeling+Method+for+Pattern+Recognition&amp;rft.volume=24&amp;rft.issue=6&amp;rft.pages=2319-2349&amp;rft.date=1996&amp;rft_id=info%3Adoi%2F10.1214%2Faos%2F1032181157&amp;rft_id=%2F%2Fwww.ams.org%2Fmathscinet-getitem%3Fmr%3D1425956&amp;rft.aulast=Kleinberg&amp;rft.aufirst=Eugene&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-kleinberg2000-6"><span class="mw-cite-backlink">^ <a href="#cite_ref-kleinberg2000_6-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-kleinberg2000_6-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite id="CITEREFKleinberg2000" class="citation journal">Kleinberg E (2000). <a rel="nofollow" class="external text" href="https://pdfs.semanticscholar.org/8956/845b0701ec57094c7a8b4ab1f41386899aea.pdf">"On the Algorithmic Implementation of Stochastic Discrimination"</a> <span class="cs1-format">(PDF)</span>. <i>IEEE Transactions on PAMI</i>. <b>22</b> (5): 473–490. <a href="/wiki/CiteSeerX_(identifier)" class="mw-redirect" title="CiteSeerX (identifier)">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.33.4131">10.1.1.33.4131</a></span>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2F34.857004">10.1109/34.857004</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+PAMI&amp;rft.atitle=On+the+Algorithmic+Implementation+of+Stochastic+Discrimination&amp;rft.volume=22&amp;rft.issue=5&amp;rft.pages=473-490&amp;rft.date=2000&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.33.4131&amp;rft_id=info%3Adoi%2F10.1109%2F34.857004&amp;rft.aulast=Kleinberg&amp;rft.aufirst=Eugene&amp;rft_id=https%3A%2F%2Fpdfs.semanticscholar.org%2F8956%2F845b0701ec57094c7a8b4ab1f41386899aea.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-breiman2001-7"><span class="mw-cite-backlink">^ <a href="#cite_ref-breiman2001_7-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-breiman2001_7-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-breiman2001_7-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-breiman2001_7-3"><sup><i><b>d</b></i></sup></a></span> <span class="reference-text"><cite id="CITEREFBreiman2001" class="citation journal"><a href="/wiki/Leo_Breiman" title="Leo Breiman">Breiman L</a> (2001). "Random Forests". <i><a href="/wiki/Machine_Learning_(journal)" title="Machine Learning (journal)">Machine Learning</a></i>. <b>45</b> (1): 5–32. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1023%2FA%3A1010933404324">10.1023/A:1010933404324</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Machine+Learning&amp;rft.atitle=Random+Forests&amp;rft.volume=45&amp;rft.issue=1&amp;rft.pages=5-32&amp;rft.date=2001&amp;rft_id=info%3Adoi%2F10.1023%2FA%3A1010933404324&amp;rft.aulast=Breiman&amp;rft.aufirst=Leo&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-rpackage-8"><span class="mw-cite-backlink">^ <a href="#cite_ref-rpackage_8-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-rpackage_8-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite id="CITEREFLiaw2012" class="citation web">Liaw A (16 October 2012). <a rel="nofollow" class="external text" href="https://cran.r-project.org/web/packages/randomForest/randomForest.pdf">"Documentation for R package randomForest"</a> <span class="cs1-format">(PDF)</span><span class="reference-accessdate">. Retrieved <span class="nowrap">15 March</span> 2013</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Documentation+for+R+package+randomForest&amp;rft.date=2012-10-16&amp;rft.aulast=Liaw&amp;rft.aufirst=Andy&amp;rft_id=https%3A%2F%2Fcran.r-project.org%2Fweb%2Fpackages%2FrandomForest%2FrandomForest.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-9"><span class="mw-cite-backlink"><b><a href="#cite_ref-9">^</a></b></span> <span class="reference-text">U.S. trademark registration number 3185828, registered 2006/12/19.</span>
</li>
<li id="cite_note-10"><span class="mw-cite-backlink"><b><a href="#cite_ref-10">^</a></b></span> <span class="reference-text"><cite class="citation web"><a rel="nofollow" class="external text" href="https://trademarks.justia.com/786/42/random-78642027.html">"RANDOM FORESTS Trademark of Health Care Productivity, Inc. - Registration Number 3185828 - Serial Number 78642027&#160;:: Justia Trademarks"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=RANDOM+FORESTS+Trademark+of+Health+Care+Productivity%2C+Inc.+-+Registration+Number+3185828+-+Serial+Number+78642027+%3A%3A+Justia+Trademarks&amp;rft_id=https%3A%2F%2Ftrademarks.justia.com%2F786%2F42%2Frandom-78642027.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-amitgeman1997-11"><span class="mw-cite-backlink">^ <a href="#cite_ref-amitgeman1997_11-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-amitgeman1997_11-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite id="CITEREFAmitGeman1997" class="citation journal">Amit Y, <a href="/wiki/Donald_Geman" title="Donald Geman">Geman D</a> (1997). <a rel="nofollow" class="external text" href="http://www.cis.jhu.edu/publications/papers_in_database/GEMAN/shape.pdf">"Shape quantization and recognition with randomized trees"</a> <span class="cs1-format">(PDF)</span>. <i><a href="/wiki/Neural_Computation_(journal)" title="Neural Computation (journal)">Neural Computation</a></i>. <b>9</b> (7): 1545–1588. <a href="/wiki/CiteSeerX_(identifier)" class="mw-redirect" title="CiteSeerX (identifier)">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.57.6069">10.1.1.57.6069</a></span>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1162%2Fneco.1997.9.7.1545">10.1162/neco.1997.9.7.1545</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Neural+Computation&amp;rft.atitle=Shape+quantization+and+recognition+with+randomized+trees&amp;rft.volume=9&amp;rft.issue=7&amp;rft.pages=1545-1588&amp;rft.date=1997&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.57.6069&amp;rft_id=info%3Adoi%2F10.1162%2Fneco.1997.9.7.1545&amp;rft.aulast=Amit&amp;rft.aufirst=Yali&amp;rft.au=Geman%2C+Donald&amp;rft_id=http%3A%2F%2Fwww.cis.jhu.edu%2Fpublications%2Fpapers_in_database%2FGEMAN%2Fshape.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-12"><span class="mw-cite-backlink"><b><a href="#cite_ref-12">^</a></b></span> <span class="reference-text"><cite id="CITEREFDietterich2000" class="citation journal">Dietterich, Thomas (2000). "An Experimental Comparison of Three Methods for Constructing Ensembles of Decision Trees: Bagging, Boosting, and Randomization". <i><a href="/wiki/Machine_Learning_(journal)" title="Machine Learning (journal)">Machine Learning</a></i>. <b>40</b> (2): 139–157. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1023%2FA%3A1007607513941">10.1023/A:1007607513941</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Machine+Learning&amp;rft.atitle=An+Experimental+Comparison+of+Three+Methods+for+Constructing+Ensembles+of+Decision+Trees%3A+Bagging%2C+Boosting%2C+and+Randomization&amp;rft.volume=40&amp;rft.issue=2&amp;rft.pages=139-157&amp;rft.date=2000&amp;rft_id=info%3Adoi%2F10.1023%2FA%3A1007607513941&amp;rft.aulast=Dietterich&amp;rft.aufirst=Thomas&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-islr-13"><span class="mw-cite-backlink"><b><a href="#cite_ref-islr_13-0">^</a></b></span> <span class="reference-text"><cite id="CITEREFGareth_JamesDaniela_WittenTrevor_HastieRobert_Tibshirani2013" class="citation book">Gareth James; Daniela Witten; Trevor Hastie; Robert Tibshirani (2013). <a rel="nofollow" class="external text" href="http://www-bcf.usc.edu/~gareth/ISL/"><i>An Introduction to Statistical Learning</i></a>. Springer. pp.&#160;316–321.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=An+Introduction+to+Statistical+Learning&amp;rft.pages=316-321&amp;rft.pub=Springer&amp;rft.date=2013&amp;rft.au=Gareth+James&amp;rft.au=Daniela+Witten&amp;rft.au=Trevor+Hastie&amp;rft.au=Robert+Tibshirani&amp;rft_id=http%3A%2F%2Fwww-bcf.usc.edu%2F~gareth%2FISL%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-ho2002-14"><span class="mw-cite-backlink"><b><a href="#cite_ref-ho2002_14-0">^</a></b></span> <span class="reference-text">
<cite id="CITEREFHo2002" class="citation journal">Ho, Tin Kam (2002). <a rel="nofollow" class="external text" href="http://ect.bell-labs.com/who/tkh/publications/papers/compare.pdf">"A Data Complexity Analysis of Comparative Advantages of Decision Forest Constructors"</a> <span class="cs1-format">(PDF)</span>. <i>Pattern Analysis and Applications</i>. <b>5</b> (2): 102–112. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2Fs100440200009">10.1007/s100440200009</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Pattern+Analysis+and+Applications&amp;rft.atitle=A+Data+Complexity+Analysis+of+Comparative+Advantages+of+Decision+Forest+Constructors&amp;rft.volume=5&amp;rft.issue=2&amp;rft.pages=102-112&amp;rft.date=2002&amp;rft_id=info%3Adoi%2F10.1007%2Fs100440200009&amp;rft.aulast=Ho&amp;rft.aufirst=Tin+Kam&amp;rft_id=http%3A%2F%2Fect.bell-labs.com%2Fwho%2Ftkh%2Fpublications%2Fpapers%2Fcompare.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-15"><span class="mw-cite-backlink"><b><a href="#cite_ref-15">^</a></b></span> <span class="reference-text"><cite id="CITEREFGeurtsErnstWehenkel2006" class="citation journal">Geurts P, Ernst D, Wehenkel L (2006). <a rel="nofollow" class="external text" href="http://orbi.ulg.ac.be/bitstream/2268/9357/1/geurts-mlj-advance.pdf">"Extremely randomized trees"</a> <span class="cs1-format">(PDF)</span>. <i>Machine Learning</i>. <b>63</b>: 3–42. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2Fs10994-006-6226-1">10.1007/s10994-006-6226-1</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Machine+Learning&amp;rft.atitle=Extremely+randomized+trees&amp;rft.volume=63&amp;rft.pages=3-42&amp;rft.date=2006&amp;rft_id=info%3Adoi%2F10.1007%2Fs10994-006-6226-1&amp;rft.aulast=Geurts&amp;rft.aufirst=P&amp;rft.au=Ernst%2C+D&amp;rft.au=Wehenkel%2C+L&amp;rft_id=http%3A%2F%2Forbi.ulg.ac.be%2Fbitstream%2F2268%2F9357%2F1%2Fgeurts-mlj-advance.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-16"><span class="mw-cite-backlink"><b><a href="#cite_ref-16">^</a></b></span> <span class="reference-text"><cite id="CITEREFZhuZengKosorok2015" class="citation journal">Zhu R, Zeng D, Kosorok MR (2015). <a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC4760114">"Reinforcement Learning Trees"</a>. <i>Journal of the American Statistical Association</i>. <b>110</b> (512): 1770–1784. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1080%2F01621459.2015.1036994">10.1080/01621459.2015.1036994</a>. <a href="/wiki/PMC_(identifier)" class="mw-redirect" title="PMC (identifier)">PMC</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC4760114">4760114</a></span>. <a href="/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/26903687">26903687</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+American+Statistical+Association&amp;rft.atitle=Reinforcement+Learning+Trees&amp;rft.volume=110&amp;rft.issue=512&amp;rft.pages=1770-1784&amp;rft.date=2015&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4760114&amp;rft_id=info%3Apmid%2F26903687&amp;rft_id=info%3Adoi%2F10.1080%2F01621459.2015.1036994&amp;rft.aulast=Zhu&amp;rft.aufirst=R&amp;rft.au=Zeng%2C+D&amp;rft.au=Kosorok%2C+MR&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC4760114&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-17"><span class="mw-cite-backlink"><b><a href="#cite_ref-17">^</a></b></span> <span class="reference-text"><cite id="CITEREFDeng,H.Runger,_G.Tuv,_E.2011" class="citation conference">Deng,H.; Runger, G.; Tuv, E. (2011). <a rel="nofollow" class="external text" href="https://www.researchgate.net/publication/221079908"><i>Bias of importance measures for multi-valued attributes and solutions</i></a>. Proceedings of the 21st International Conference on Artificial Neural Networks (ICANN). pp.&#160;293–300.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.btitle=Bias+of+importance+measures+for+multi-valued+attributes+and+solutions&amp;rft.pages=293-300&amp;rft.date=2011&amp;rft.au=Deng%2CH.&amp;rft.au=Runger%2C+G.&amp;rft.au=Tuv%2C+E.&amp;rft_id=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F221079908&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-18"><span class="mw-cite-backlink"><b><a href="#cite_ref-18">^</a></b></span> <span class="reference-text"><cite id="CITEREFAltmannToloşiSanderLengauer2010" class="citation journal">Altmann A, Toloşi L, Sander O, Lengauer T (May 2010). <a rel="nofollow" class="external text" href="http://bioinformatics.oxfordjournals.org/content/early/2010/04/12/bioinformatics.btq134.abstract">"Permutation importance: a corrected feature importance measure"</a>. <i>Bioinformatics</i>. <b>26</b> (10): 1340–7. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1093%2Fbioinformatics%2Fbtq134">10.1093/bioinformatics/btq134</a></span>. <a href="/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/20385727">20385727</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Bioinformatics&amp;rft.atitle=Permutation+importance%3A+a+corrected+feature+importance+measure&amp;rft.volume=26&amp;rft.issue=10&amp;rft.pages=1340-7&amp;rft.date=2010-05&amp;rft_id=info%3Adoi%2F10.1093%2Fbioinformatics%2Fbtq134&amp;rft_id=info%3Apmid%2F20385727&amp;rft.aulast=Altmann&amp;rft.aufirst=A&amp;rft.au=Tolo%C5%9Fi%2C+L&amp;rft.au=Sander%2C+O&amp;rft.au=Lengauer%2C+T&amp;rft_id=http%3A%2F%2Fbioinformatics.oxfordjournals.org%2Fcontent%2Fearly%2F2010%2F04%2F12%2Fbioinformatics.btq134.abstract&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-19"><span class="mw-cite-backlink"><b><a href="#cite_ref-19">^</a></b></span> <span class="reference-text"><cite id="CITEREFStroblBoulesteixAugustin2007" class="citation journal">Strobl C, Boulesteix A, Augustin T (2007). <a rel="nofollow" class="external text" href="https://epub.ub.uni-muenchen.de/1833/1/paper_464.pdf">"Unbiased split selection for classification trees based on the Gini index"</a> <span class="cs1-format">(PDF)</span>. <i>Computational Statistics &amp; Data Analysis</i>. <b>52</b>: 483–501. <a href="/wiki/CiteSeerX_(identifier)" class="mw-redirect" title="CiteSeerX (identifier)">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.525.3178">10.1.1.525.3178</a></span>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.csda.2006.12.030">10.1016/j.csda.2006.12.030</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Computational+Statistics+%26+Data+Analysis&amp;rft.atitle=Unbiased+split+selection+for+classification+trees+based+on+the+Gini+index&amp;rft.volume=52&amp;rft.pages=483-501&amp;rft.date=2007&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.525.3178&amp;rft_id=info%3Adoi%2F10.1016%2Fj.csda.2006.12.030&amp;rft.aulast=Strobl&amp;rft.aufirst=Carolin&amp;rft.au=Boulesteix%2C+Anne-Laure&amp;rft.au=Augustin%2C+Thomas&amp;rft_id=https%3A%2F%2Fepub.ub.uni-muenchen.de%2F1833%2F1%2Fpaper_464.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-20"><span class="mw-cite-backlink"><b><a href="#cite_ref-20">^</a></b></span> <span class="reference-text"><cite id="CITEREFPainskyRosset2017" class="citation journal">Painsky A, Rosset S (2017). "Cross-Validated Variable Selection in Tree-Based Methods Improves Predictive Performance". <i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i>. <b>39</b> (11): 2142–2153. <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/1512.03444">1512.03444</a></span>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2Ftpami.2016.2636831">10.1109/tpami.2016.2636831</a>. <a href="/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/28114007">28114007</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Transactions+on+Pattern+Analysis+and+Machine+Intelligence&amp;rft.atitle=Cross-Validated+Variable+Selection+in+Tree-Based+Methods+Improves+Predictive+Performance&amp;rft.volume=39&amp;rft.issue=11&amp;rft.pages=2142-2153&amp;rft.date=2017&amp;rft_id=info%3Aarxiv%2F1512.03444&amp;rft_id=info%3Apmid%2F28114007&amp;rft_id=info%3Adoi%2F10.1109%2Ftpami.2016.2636831&amp;rft.aulast=Painsky&amp;rft.aufirst=Amichai&amp;rft.au=Rosset%2C+Saharon&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-21"><span class="mw-cite-backlink"><b><a href="#cite_ref-21">^</a></b></span> <span class="reference-text"><cite id="CITEREFTolosiLengauer2011" class="citation journal">Tolosi L, Lengauer T (July 2011). <a rel="nofollow" class="external text" href="http://bioinformatics.oxfordjournals.org/content/27/14/1986.abstract">"Classification with correlated features: unreliability of feature ranking and solutions"</a>. <i>Bioinformatics</i>. <b>27</b> (14): 1986–94. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1093%2Fbioinformatics%2Fbtr300">10.1093/bioinformatics/btr300</a></span>. <a href="/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/21576180">21576180</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Bioinformatics&amp;rft.atitle=Classification+with+correlated+features%3A+unreliability+of+feature+ranking+and+solutions&amp;rft.volume=27&amp;rft.issue=14&amp;rft.pages=1986-94&amp;rft.date=2011-07&amp;rft_id=info%3Adoi%2F10.1093%2Fbioinformatics%2Fbtr300&amp;rft_id=info%3Apmid%2F21576180&amp;rft.aulast=Tolosi&amp;rft.aufirst=L&amp;rft.au=Lengauer%2C+T&amp;rft_id=http%3A%2F%2Fbioinformatics.oxfordjournals.org%2Fcontent%2F27%2F14%2F1986.abstract&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-linjeon02-22"><span class="mw-cite-backlink">^ <a href="#cite_ref-linjeon02_22-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-linjeon02_22-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite id="CITEREFLinJeon2002" class="citation techreport">Lin, Yi; Jeon, Yongho (2002). <i>Random forests and adaptive nearest neighbors</i> (Technical report). Technical Report No. 1055. University of Wisconsin. <a href="/wiki/CiteSeerX_(identifier)" class="mw-redirect" title="CiteSeerX (identifier)">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.153.9168">10.1.1.153.9168</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=report&amp;rft.btitle=Random+forests+and+adaptive+nearest+neighbors&amp;rft.series=Technical+Report+No.+1055&amp;rft.pub=University+of+Wisconsin&amp;rft.date=2002&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.153.9168&amp;rft.aulast=Lin&amp;rft.aufirst=Yi&amp;rft.au=Jeon%2C+Yongho&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-23"><span class="mw-cite-backlink"><b><a href="#cite_ref-23">^</a></b></span> <span class="reference-text"><cite class="citation journal">Shi, T., Horvath, S. (2006). "Unsupervised Learning with Random Forest Predictors". <i>Journal of Computational and Graphical Statistics</i>. <b>15</b> (1): 118–138. <a href="/wiki/CiteSeerX_(identifier)" class="mw-redirect" title="CiteSeerX (identifier)">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.698.2365">10.1.1.698.2365</a></span>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1198%2F106186006X94072">10.1198/106186006X94072</a>. <a href="/wiki/JSTOR_(identifier)" class="mw-redirect" title="JSTOR (identifier)">JSTOR</a>&#160;<a rel="nofollow" class="external text" href="//www.jstor.org/stable/27594168">27594168</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Computational+and+Graphical+Statistics&amp;rft.atitle=Unsupervised+Learning+with+Random+Forest+Predictors&amp;rft.volume=15&amp;rft.issue=1&amp;rft.pages=118-138&amp;rft.date=2006&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.698.2365&amp;rft_id=%2F%2Fwww.jstor.org%2Fstable%2F27594168&amp;rft_id=info%3Adoi%2F10.1198%2F106186006X94072&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><span class="cs1-maint citation-comment">CS1 maint: uses authors parameter (<a href="/wiki/Category:CS1_maint:_uses_authors_parameter" title="Category:CS1 maint: uses authors parameter">link</a>)</span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-24"><span class="mw-cite-backlink"><b><a href="#cite_ref-24">^</a></b></span> <span class="reference-text"><cite id="CITEREFShiSeligsonBelldegrunPalotie2005" class="citation journal">Shi T, Seligson D, Belldegrun AS, Palotie A, Horvath S (April 2005). "Tumor classification by tissue microarray profiling: random forest clustering applied to renal cell carcinoma". <i>Modern Pathology</i>. <b>18</b> (4): 547–57. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="https://doi.org/10.1038%2Fmodpathol.3800322">10.1038/modpathol.3800322</a></span>. <a href="/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/15529185">15529185</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Modern+Pathology&amp;rft.atitle=Tumor+classification+by+tissue+microarray+profiling%3A+random+forest+clustering+applied+to+renal+cell+carcinoma&amp;rft.volume=18&amp;rft.issue=4&amp;rft.pages=547-57&amp;rft.date=2005-04&amp;rft_id=info%3Adoi%2F10.1038%2Fmodpathol.3800322&amp;rft_id=info%3Apmid%2F15529185&amp;rft.aulast=Shi&amp;rft.aufirst=T&amp;rft.au=Seligson%2C+D&amp;rft.au=Belldegrun%2C+AS&amp;rft.au=Palotie%2C+A&amp;rft.au=Horvath%2C+S&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-25"><span class="mw-cite-backlink"><b><a href="#cite_ref-25">^</a></b></span> <span class="reference-text"><cite class="citation journal">Prinzie, A., Van den Poel, D. (2008). "Random Forests for multiclass classification: Random MultiNomial Logit". <i>Expert Systems with Applications</i>. <b>34</b> (3): 1721–1732. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1016%2Fj.eswa.2007.01.029">10.1016/j.eswa.2007.01.029</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Expert+Systems+with+Applications&amp;rft.atitle=Random+Forests+for+multiclass+classification%3A+Random+MultiNomial+Logit&amp;rft.volume=34&amp;rft.issue=3&amp;rft.pages=1721-1732&amp;rft.date=2008&amp;rft_id=info%3Adoi%2F10.1016%2Fj.eswa.2007.01.029&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><span class="cs1-maint citation-comment">CS1 maint: uses authors parameter (<a href="/wiki/Category:CS1_maint:_uses_authors_parameter" title="Category:CS1 maint: uses authors parameter">link</a>)</span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-26"><span class="mw-cite-backlink"><b><a href="#cite_ref-26">^</a></b></span> <span class="reference-text"><cite id="CITEREFPrinzie2007" class="citation conference">Prinzie, Anita (2007). "Random Multiclass Classification: Generalizing Random Forests to Random MNL and Random NB".  In Roland Wagner; Norman Revell; Günther Pernul (eds.). <i>Database and Expert Systems Applications: 18th International Conference, DEXA 2007, Regensburg, Germany, September 3-7, 2007, Proceedings</i>. Lecture Notes in Computer Science. <b>4653</b>. pp.&#160;349–358. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2F978-3-540-74469-6_35">10.1007/978-3-540-74469-6_35</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-3-540-74467-2" title="Special:BookSources/978-3-540-74467-2"><bdi>978-3-540-74467-2</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.atitle=Random+Multiclass+Classification%3A+Generalizing+Random+Forests+to+Random+MNL+and+Random+NB&amp;rft.btitle=Database+and+Expert+Systems+Applications%3A+18th+International+Conference%2C+DEXA+2007%2C+Regensburg%2C+Germany%2C+September+3-7%2C+2007%2C+Proceedings&amp;rft.series=Lecture+Notes+in+Computer+Science&amp;rft.pages=349-358&amp;rft.date=2007&amp;rft_id=info%3Adoi%2F10.1007%2F978-3-540-74469-6_35&amp;rft.isbn=978-3-540-74467-2&amp;rft.aulast=Prinzie&amp;rft.aufirst=Anita&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-scornet2015random-27"><span class="mw-cite-backlink">^ <a href="#cite_ref-scornet2015random_27-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-scornet2015random_27-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-scornet2015random_27-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-scornet2015random_27-3"><sup><i><b>d</b></i></sup></a></span> <span class="reference-text"><cite id="CITEREFScornet2015" class="citation arxiv">Scornet, Erwan (2015). "Random forests and kernel methods". <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/1502.03836">1502.03836</a></span> [<a rel="nofollow" class="external text" href="//arxiv.org/archive/math.ST">math.ST</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Random+forests+and+kernel+methods&amp;rft.date=2015&amp;rft_id=info%3Aarxiv%2F1502.03836&amp;rft.aulast=Scornet&amp;rft.aufirst=Erwan&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-breiman2000some-28"><span class="mw-cite-backlink"><b><a href="#cite_ref-breiman2000some_28-0">^</a></b></span> <span class="reference-text"><cite id="CITEREFBreiman2000" class="citation journal"><a href="/wiki/Leo_Breiman" title="Leo Breiman">Breiman, Leo</a> (2000). <a rel="nofollow" class="external text" href="http://oz.berkeley.edu/~breiman/some_theory2000.pdf">"Some infinity theory for predictor ensembles"</a> <span class="cs1-format">(PDF)</span>. Technical Report 579, Statistics Dept. UCB.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Some+infinity+theory+for+predictor+ensembles&amp;rft.date=2000&amp;rft.aulast=Breiman&amp;rft.aufirst=Leo&amp;rft_id=http%3A%2F%2Foz.berkeley.edu%2F~breiman%2Fsome_theory2000.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span> <span class="cs1-hidden-error error citation-comment">Cite journal requires <code class="cs1-code">&#124;journal=</code> (<a href="/wiki/Help:CS1_errors#missing_periodical" title="Help:CS1 errors">help</a>)</span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/><sup class="noprint Inline-Template"><span style="white-space: nowrap;">&#91;<i><a href="/wiki/Wikipedia:Link_rot" title="Wikipedia:Link rot"><span title="&#160;Dead link since May 2017">permanent dead link</span></a></i>&#93;</span></sup></span>
</li>
<li id="cite_note-lin2006random-29"><span class="mw-cite-backlink"><b><a href="#cite_ref-lin2006random_29-0">^</a></b></span> <span class="reference-text"><cite id="CITEREFLinJeon2006" class="citation journal">Lin, Yi; Jeon, Yongho (2006). "Random forests and adaptive nearest neighbors". <i>Journal of the American Statistical Association</i>. <b>101</b> (474): 578–590. <a href="/wiki/CiteSeerX_(identifier)" class="mw-redirect" title="CiteSeerX (identifier)">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.153.9168">10.1.1.153.9168</a></span>. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1198%2F016214505000001230">10.1198/016214505000001230</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+the+American+Statistical+Association&amp;rft.atitle=Random+forests+and+adaptive+nearest+neighbors&amp;rft.volume=101&amp;rft.issue=474&amp;rft.pages=578-590&amp;rft.date=2006&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.153.9168&amp;rft_id=info%3Adoi%2F10.1198%2F016214505000001230&amp;rft.aulast=Lin&amp;rft.aufirst=Yi&amp;rft.au=Jeon%2C+Yongho&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-davies2014random-30"><span class="mw-cite-backlink"><b><a href="#cite_ref-davies2014random_30-0">^</a></b></span> <span class="reference-text"><cite id="CITEREFDaviesGhahramani2014" class="citation arxiv">Davies, Alex; Ghahramani, Zoubin (2014). "The Random Forest Kernel and other kernels for big data from random partitions". <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/1402.4293">1402.4293</a></span> [<a rel="nofollow" class="external text" href="//arxiv.org/archive/stat.ML">stat.ML</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=The+Random+Forest+Kernel+and+other+kernels+for+big+data+from+random+partitions&amp;rft.date=2014&amp;rft_id=info%3Aarxiv%2F1402.4293&amp;rft.aulast=Davies&amp;rft.aufirst=Alex&amp;rft.au=Ghahramani%2C+Zoubin&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-breiman2004consistency-31"><span class="mw-cite-backlink">^ <a href="#cite_ref-breiman2004consistency_31-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-breiman2004consistency_31-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite id="CITEREFBreimanGhahramani2004" class="citation journal">Breiman L, Ghahramani Z (2004). "Consistency for a simple model of random forests". <i>Statistical Department, University of California at Berkeley. Technical Report</i> (670). <a href="/wiki/CiteSeerX_(identifier)" class="mw-redirect" title="CiteSeerX (identifier)">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.618.90">10.1.1.618.90</a></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Statistical+Department%2C+University+of+California+at+Berkeley.+Technical+Report&amp;rft.atitle=Consistency+for+a+simple+model+of+random+forests&amp;rft.issue=670&amp;rft.date=2004&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.618.90&amp;rft.aulast=Breiman&amp;rft.aufirst=Leo&amp;rft.au=Ghahramani%2C+Zoubin&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-arlot2014analysis-32"><span class="mw-cite-backlink">^ <a href="#cite_ref-arlot2014analysis_32-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-arlot2014analysis_32-1"><sup><i><b>b</b></i></sup></a></span> <span class="reference-text"><cite id="CITEREFArlotGenuer2014" class="citation arxiv">Arlot S, Genuer R (2014). "Analysis of purely random forests bias". <a href="/wiki/ArXiv_(identifier)" class="mw-redirect" title="ArXiv (identifier)">arXiv</a>:<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//arxiv.org/abs/1407.3939">1407.3939</a></span> [<a rel="nofollow" class="external text" href="//arxiv.org/archive/math.ST">math.ST</a>].</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=preprint&amp;rft.jtitle=arXiv&amp;rft.atitle=Analysis+of+purely+random+forests+bias&amp;rft.date=2014&amp;rft_id=info%3Aarxiv%2F1407.3939&amp;rft.aulast=Arlot&amp;rft.aufirst=Sylvain&amp;rft.au=Genuer%2C+Robin&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-33"><span class="mw-cite-backlink"><b><a href="#cite_ref-33">^</a></b></span> <span class="reference-text"><cite id="CITEREFWęcelLewoniewski2015" class="citation book">Węcel K, Lewoniewski W (2015-12-02). <i>Modelling the Quality of Attributes in Wikipedia Infoboxes</i>. <i>Lecture Notes in Business Information Processing</i>. <b>228</b>. pp.&#160;308–320. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2F978-3-319-26762-3_27">10.1007/978-3-319-26762-3_27</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-3-319-26761-6" title="Special:BookSources/978-3-319-26761-6"><bdi>978-3-319-26761-6</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Modelling+the+Quality+of+Attributes+in+Wikipedia+Infoboxes&amp;rft.pages=308-320&amp;rft.date=2015-12-02&amp;rft_id=info%3Adoi%2F10.1007%2F978-3-319-26762-3_27&amp;rft.isbn=978-3-319-26761-6&amp;rft.aulast=W%C4%99cel&amp;rft.aufirst=Krzysztof&amp;rft.au=Lewoniewski%2C+W%C5%82odzimierz&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-34"><span class="mw-cite-backlink"><b><a href="#cite_ref-34">^</a></b></span> <span class="reference-text"><cite id="CITEREFLewoniewskiWęcelAbramowicz2016" class="citation book">Lewoniewski W, Węcel K, Abramowicz W (2016-09-22). <i>Quality and Importance of Wikipedia Articles in Different Languages</i>. <i>Information and Software Technologies. ICIST 2016. Communications in Computer and Information Science</i>. Communications in Computer and Information Science. <b>639</b>. pp.&#160;613–624. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2F978-3-319-46254-7_50">10.1007/978-3-319-46254-7_50</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-3-319-46253-0" title="Special:BookSources/978-3-319-46253-0"><bdi>978-3-319-46253-0</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Quality+and+Importance+of+Wikipedia+Articles+in+Different+Languages&amp;rft.series=Communications+in+Computer+and+Information+Science&amp;rft.pages=613-624&amp;rft.date=2016-09-22&amp;rft_id=info%3Adoi%2F10.1007%2F978-3-319-46254-7_50&amp;rft.isbn=978-3-319-46253-0&amp;rft.aulast=Lewoniewski&amp;rft.aufirst=W%C5%82odzimierz&amp;rft.au=W%C4%99cel%2C+Krzysztof&amp;rft.au=Abramowicz%2C+Witold&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
<li id="cite_note-35"><span class="mw-cite-backlink"><b><a href="#cite_ref-35">^</a></b></span> <span class="reference-text"><cite id="CITEREFWarncke-WangCosleyRiedl2013" class="citation book">Warncke-Wang M, Cosley D, Riedl J (2013). <i>Tell me more: An actionable quality model for wikipedia</i>. <i>WikiSym '13 Proceedings of the 9th International Symposium on Open Collaboration</i>. WikiSym '13. pp.&#160;8:1–8:10. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1145%2F2491055.2491063">10.1145/2491055.2491063</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/9781450318525" title="Special:BookSources/9781450318525"><bdi>9781450318525</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Tell+me+more%3A+An+actionable+quality+model+for+wikipedia&amp;rft.series=WikiSym+%2713&amp;rft.pages=8%3A1-8%3A10&amp;rft.date=2013&amp;rft_id=info%3Adoi%2F10.1145%2F2491055.2491063&amp;rft.isbn=9781450318525&amp;rft.aulast=Warncke-Wang&amp;rft.aufirst=Morten&amp;rft.au=Cosley%2C+Dan&amp;rft.au=Riedl%2C+John&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></span>
</li>
</ol></div>
<h2><span class="mw-headline" id="Further_reading">Further reading</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=30" title="Edit section: Further reading">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<table role="presentation" class="metadata mbox-small" style="background-color:#f9f9f9;border:1px solid #aaa;color:#000">
<tbody><tr>
<td class="mbox-image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/3/32/Scholia_logo.svg/40px-Scholia_logo.svg.png" decoding="async" width="40" height="39" class="noviewer" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/3/32/Scholia_logo.svg/60px-Scholia_logo.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/3/32/Scholia_logo.svg/80px-Scholia_logo.svg.png 2x" data-file-width="107" data-file-height="104" /></td>
<td class="mbox-text plainlist"><a href="https://www.wikidata.org/wiki/Wikidata:Scholia" class="extiw" title="wikidata:Wikidata:Scholia">Scholia</a> has a <i>topic</i> profile for <i><b><a href="https://tools.wmflabs.org/scholia/topic/Q245748" class="extiw" title="toolforge:scholia/topic/Q245748">Random forest</a></b></i>.</td></tr>
</tbody></table>
<style data-mw-deduplicate="TemplateStyles:r886047268">.mw-parser-output .refbegin{font-size:90%;margin-bottom:0.5em}.mw-parser-output .refbegin-hanging-indents>ul{list-style-type:none;margin-left:0}.mw-parser-output .refbegin-hanging-indents>ul>li,.mw-parser-output .refbegin-hanging-indents>dl>dd{margin-left:0;padding-left:3.2em;text-indent:-3.2em;list-style:none}.mw-parser-output .refbegin-100{font-size:100%}</style><div class="refbegin reflist" style="">
<ul><li><cite id="CITEREFPrinziePoel2007" class="citation conference">Prinzie A, Poel D (2007). <a rel="nofollow" class="external text" href="https://www.researchgate.net/publication/225175169">"Random Multiclass Classification: Generalizing Random Forests to Random MNL and Random NB"</a>. <i>Database and Expert Systems Applications</i>. <a href="/wiki/Lecture_Notes_in_Computer_Science" title="Lecture Notes in Computer Science">Lecture Notes in Computer Science</a>. <b>4653</b>. p.&#160;349. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1007%2F978-3-540-74469-6_35">10.1007/978-3-540-74469-6_35</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-3-540-74467-2" title="Special:BookSources/978-3-540-74467-2"><bdi>978-3-540-74467-2</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=conference&amp;rft.atitle=Random+Multiclass+Classification%3A+Generalizing+Random+Forests+to+Random+MNL+and+Random+NB&amp;rft.btitle=Database+and+Expert+Systems+Applications&amp;rft.series=Lecture+Notes+in+Computer+Science&amp;rft.pages=349&amp;rft.date=2007&amp;rft_id=info%3Adoi%2F10.1007%2F978-3-540-74469-6_35&amp;rft.isbn=978-3-540-74467-2&amp;rft.aulast=Prinzie&amp;rft.aufirst=Anita&amp;rft.au=Poel%2C+Dirk&amp;rft_id=https%3A%2F%2Fwww.researchgate.net%2Fpublication%2F225175169&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></li>
<li><cite id="CITEREFDeniskoHoffman2018" class="citation journal">Denisko D, Hoffman MM (February 2018). <a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC5828645">"Classification and interaction in random forests"</a>. <i>Proceedings of the National Academy of Sciences of the United States of America</i>. <b>115</b> (8): 1690–1692. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1073%2Fpnas.1800256115">10.1073/pnas.1800256115</a>. <a href="/wiki/PMC_(identifier)" class="mw-redirect" title="PMC (identifier)">PMC</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//www.ncbi.nlm.nih.gov/pmc/articles/PMC5828645">5828645</a></span>. <a href="/wiki/PMID_(identifier)" class="mw-redirect" title="PMID (identifier)">PMID</a>&#160;<a rel="nofollow" class="external text" href="//pubmed.ncbi.nlm.nih.gov/29440440">29440440</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+National+Academy+of+Sciences+of+the+United+States+of+America&amp;rft.atitle=Classification+and+interaction+in+random+forests&amp;rft.volume=115&amp;rft.issue=8&amp;rft.pages=1690-1692&amp;rft.date=2018-02&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC5828645&amp;rft_id=info%3Apmid%2F29440440&amp;rft_id=info%3Adoi%2F10.1073%2Fpnas.1800256115&amp;rft.aulast=Denisko&amp;rft.aufirst=D&amp;rft.au=Hoffman%2C+MM&amp;rft_id=%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC5828645&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARandom+forest" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r951705291"/></li></ul>
</div>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Random_forest&amp;action=edit&amp;section=31" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2>
<ul><li><a rel="nofollow" class="external text" href="https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm">Random Forests classifier description</a> (Leo Breiman's site)</li>
<li><a rel="nofollow" class="external text" href="https://cran.r-project.org/doc/Rnews/Rnews_2002-3.pdf">Liaw, Andy &amp; Wiener, Matthew "Classification and Regression by randomForest" R News (2002) Vol. 2/3 p. 18</a> (Discussion of the use of the random forest package for <a href="/wiki/R_programming_language" class="mw-redirect" title="R programming language">R</a>)</li></ul>
<!-- 
NewPP limit report
Parsed by mw1390
Cached time: 20200705152122
Cache expiry: 2592000
Dynamic content: false
Complications: [vary‐revision‐sha1]
CPU time usage: 0.684 seconds
Real time usage: 1.106 seconds
Preprocessor visited node count: 3590/1000000
Post‐expand include size: 118763/2097152 bytes
Template argument size: 2793/2097152 bytes
Highest expansion depth: 17/40
Expensive parser function count: 4/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 156491/5000000 bytes
Lua time usage: 0.253/10.000 seconds
Lua memory usage: 6.12 MB/50 MB
Number of Wikibase entities loaded: 0/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  638.834      1 -total
 51.45%  328.698      1 Template:Reflist
 18.10%  115.624      4 Template:Cite_conference
 14.00%   89.441     21 Template:Cite_journal
  7.16%   45.718      1 Template:Machine_learning_bar
  6.75%   43.102      1 Template:About
  6.67%   42.600      1 Template:Sidebar_with_collapsible_lists
  5.26%   33.620      1 Template:Expand_section
  4.86%   31.075      1 Template:Dead_link
  4.72%   30.141      1 Template:Short_description
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:1363880-0!canonical!math=5 and timestamp 20200705152120 and revision id 966179730
 -->
</div><noscript><img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" /></noscript></div>
		<div class="printfooter">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Random_forest&amp;oldid=966179730">https://en.wikipedia.org/w/index.php?title=Random_forest&amp;oldid=966179730</a>"</div>
		<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Classification_algorithms" title="Category:Classification algorithms">Classification algorithms</a></li><li><a href="/wiki/Category:Ensemble_learning" title="Category:Ensemble learning">Ensemble learning</a></li><li><a href="/wiki/Category:Decision_trees" title="Category:Decision trees">Decision trees</a></li><li><a href="/wiki/Category:Decision_theory" title="Category:Decision theory">Decision theory</a></li><li><a href="/wiki/Category:Computational_statistics" title="Category:Computational statistics">Computational statistics</a></li><li><a href="/wiki/Category:Machine_learning" title="Category:Machine learning">Machine learning</a></li></ul></div><div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul><li><a href="/wiki/Category:CS1_maint:_uses_authors_parameter" title="Category:CS1 maint: uses authors parameter">CS1 maint: uses authors parameter</a></li><li><a href="/wiki/Category:CS1_errors:_missing_periodical" title="Category:CS1 errors: missing periodical">CS1 errors: missing periodical</a></li><li><a href="/wiki/Category:All_articles_with_dead_external_links" title="Category:All articles with dead external links">All articles with dead external links</a></li><li><a href="/wiki/Category:Articles_with_dead_external_links_from_May_2017" title="Category:Articles with dead external links from May 2017">Articles with dead external links from May 2017</a></li><li><a href="/wiki/Category:Articles_with_permanently_dead_external_links" title="Category:Articles with permanently dead external links">Articles with permanently dead external links</a></li><li><a href="/wiki/Category:Articles_with_short_description" title="Category:Articles with short description">Articles with short description</a></li><li><a href="/wiki/Category:Articles_containing_potentially_dated_statements_from_2019" title="Category:Articles containing potentially dated statements from 2019">Articles containing potentially dated statements from 2019</a></li><li><a href="/wiki/Category:All_articles_containing_potentially_dated_statements" title="Category:All articles containing potentially dated statements">All articles containing potentially dated statements</a></li><li><a href="/wiki/Category:Articles_to_be_expanded_from_February_2019" title="Category:Articles to be expanded from February 2019">Articles to be expanded from February 2019</a></li><li><a href="/wiki/Category:All_articles_to_be_expanded" title="Category:All articles to be expanded">All articles to be expanded</a></li></ul></div></div>
		<div class="visualClear"></div>
		
	</div>
</div>
<div id='mw-data-after-content'>
	<div class="read-more-container"></div>
</div>

<div id="mw-navigation">
	<h2>Navigation menu</h2>
	<div id="mw-head">
		<!-- Please do not use role attribute as CSS selector, it is deprecated. -->
<nav id="p-personal" class="vector-menu" aria-labelledby="p-personal-label" role="navigation" 
	 >
	<h3 id="p-personal-label">
		<span>Personal tools</span>
	</h3>
	<!-- Please do not use the .body class, it is deprecated. -->
	<div class="body vector-menu-content">
		<!-- Please do not use the .menu class, it is deprecated. -->
		<ul class="vector-menu-content-list"><li id="pt-anonuserpage">Not logged in</li><li id="pt-anontalk"><a href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]" accesskey="n">Talk</a></li><li id="pt-anoncontribs"><a href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]" accesskey="y">Contributions</a></li><li id="pt-createaccount"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Random+forest" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Random+forest" title="You&#039;re encouraged to log in; however, it&#039;s not mandatory. [o]" accesskey="o">Log in</a></li></ul>
		
	</div>
</nav>


		<div id="left-navigation">
			<!-- Please do not use role attribute as CSS selector, it is deprecated. -->
<nav id="p-namespaces" class="vector-menu vector-menu-tabs vectorTabs" aria-labelledby="p-namespaces-label" role="navigation" 
	 >
	<h3 id="p-namespaces-label">
		<span>Namespaces</span>
	</h3>
	<!-- Please do not use the .body class, it is deprecated. -->
	<div class="body vector-menu-content">
		<!-- Please do not use the .menu class, it is deprecated. -->
		<ul class="vector-menu-content-list"><li id="ca-nstab-main" class="selected"><a href="/wiki/Random_forest" title="View the content page [c]" accesskey="c">Article</a></li><li id="ca-talk"><a href="/wiki/Talk:Random_forest" rel="discussion" title="Discuss improvements to the content page [t]" accesskey="t">Talk</a></li></ul>
		
	</div>
</nav>


			<!-- Please do not use role attribute as CSS selector, it is deprecated. -->
<nav id="p-variants" class="vector-menu-empty emptyPortlet vector-menu vector-menu-dropdown vectorMenu" aria-labelledby="p-variants-label" role="navigation" 
	 >
	<input type="checkbox" class="vector-menu-checkbox vectorMenuCheckbox" aria-labelledby="p-variants-label" />
	<h3 id="p-variants-label">
		<span>Variants</span>
	</h3>
	<!-- Please do not use the .body class, it is deprecated. -->
	<div class="body vector-menu-content">
		<!-- Please do not use the .menu class, it is deprecated. -->
		<ul class="menu vector-menu-content-list"></ul>
		
	</div>
</nav>


		</div>
		<div id="right-navigation">
			<!-- Please do not use role attribute as CSS selector, it is deprecated. -->
<nav id="p-views" class="vector-menu vector-menu-tabs vectorTabs" aria-labelledby="p-views-label" role="navigation" 
	 >
	<h3 id="p-views-label">
		<span>Views</span>
	</h3>
	<!-- Please do not use the .body class, it is deprecated. -->
	<div class="body vector-menu-content">
		<!-- Please do not use the .menu class, it is deprecated. -->
		<ul class="vector-menu-content-list"><li id="ca-view" class="collapsible selected"><a href="/wiki/Random_forest">Read</a></li><li id="ca-edit" class="collapsible"><a href="/w/index.php?title=Random_forest&amp;action=edit" title="Edit this page [e]" accesskey="e">Edit</a></li><li id="ca-history" class="collapsible"><a href="/w/index.php?title=Random_forest&amp;action=history" title="Past revisions of this page [h]" accesskey="h">View history</a></li></ul>
		
	</div>
</nav>


			<!-- Please do not use role attribute as CSS selector, it is deprecated. -->
<nav id="p-cactions" class="vector-menu-empty emptyPortlet vector-menu vector-menu-dropdown vectorMenu" aria-labelledby="p-cactions-label" role="navigation" 
	 >
	<input type="checkbox" class="vector-menu-checkbox vectorMenuCheckbox" aria-labelledby="p-cactions-label" />
	<h3 id="p-cactions-label">
		<span>More</span>
	</h3>
	<!-- Please do not use the .body class, it is deprecated. -->
	<div class="body vector-menu-content">
		<!-- Please do not use the .menu class, it is deprecated. -->
		<ul class="menu vector-menu-content-list"></ul>
		
	</div>
</nav>


			<div id="p-search" role="search">
	<h3 >
		<label for="searchInput">Search</label>
	</h3>
	<form action="/w/index.php" id="searchform">
		<div id="simpleSearch">
			<input type="search" name="search" placeholder="Search Wikipedia" title="Search Wikipedia [f]" accesskey="f" id="searchInput"/>
			<input type="hidden" name="title" value="Special:Search">
			<input type="submit" name="fulltext" value="Search" title="Search Wikipedia for this text" id="mw-searchButton" class="searchButton mw-fallbackSearchButton"/>
			<input type="submit" name="go" value="Go" title="Go to a page with this exact name if it exists" id="searchButton" class="searchButton"/>
		</div>
	</form>
</div>

		</div>
	</div>
	
<div id="mw-panel">
	<div id="p-logo" role="banner">
		<a  title="Visit the main page" class="mw-wiki-logo" href="/wiki/Main_Page"></a>
	</div>
	<!-- Please do not use role attribute as CSS selector, it is deprecated. -->
<nav id="p-navigation" class="vector-menu vector-menu-portal portal portal-first" aria-labelledby="p-navigation-label" role="navigation" 
	 >
	<h3 id="p-navigation-label">
		<span>Navigation</span>
	</h3>
	<!-- Please do not use the .body class, it is deprecated. -->
	<div class="body vector-menu-content">
		<!-- Please do not use the .menu class, it is deprecated. -->
		<ul class="vector-menu-content-list"><li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li><li id="n-contents"><a href="/wiki/Wikipedia:Contents" title="Guides to browsing Wikipedia">Contents</a></li><li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Find background information on current events">Current events</a></li><li id="n-randompage"><a href="/wiki/Special:Random" title="Visit a randomly selected article [x]" accesskey="x">Random article</a></li><li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Learn about Wikipedia and how it works">About Wikipedia</a></li><li id="n-contactpage"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact us</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us by donating to the Wikimedia Foundation">Donate</a></li><li id="n-shoplink"><a href="//shop.wikimedia.org" title="Visit the Wikipedia store">Wikipedia store</a></li></ul>
		
	</div>
</nav>


	<!-- Please do not use role attribute as CSS selector, it is deprecated. -->
<nav id="p-interaction" class="vector-menu vector-menu-portal portal" aria-labelledby="p-interaction-label" role="navigation" 
	 >
	<h3 id="p-interaction-label">
		<span>Contribute</span>
	</h3>
	<!-- Please do not use the .body class, it is deprecated. -->
	<div class="body vector-menu-content">
		<!-- Please do not use the .menu class, it is deprecated. -->
		<ul class="vector-menu-content-list"><li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li><li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="About the project, what you can do, where to find things">Community portal</a></li><li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="A list of recent changes to Wikipedia [r]" accesskey="r">Recent changes</a></li><li id="n-upload"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Add images or other media for use on Wikipedia">Upload file</a></li></ul>
		
	</div>
</nav>

<!-- Please do not use role attribute as CSS selector, it is deprecated. -->
<nav id="p-tb" class="vector-menu vector-menu-portal portal" aria-labelledby="p-tb-label" role="navigation" 
	 >
	<h3 id="p-tb-label">
		<span>Tools</span>
	</h3>
	<!-- Please do not use the .body class, it is deprecated. -->
	<div class="body vector-menu-content">
		<!-- Please do not use the .menu class, it is deprecated. -->
		<ul class="vector-menu-content-list"><li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Random_forest" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li><li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Random_forest" rel="nofollow" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li><li id="t-upload"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]" accesskey="u">Upload file</a></li><li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="A list of all special pages [q]" accesskey="q">Special pages</a></li><li id="t-permalink"><a href="/w/index.php?title=Random_forest&amp;oldid=966179730" title="Permanent link to this revision of this page">Permanent link</a></li><li id="t-info"><a href="/w/index.php?title=Random_forest&amp;action=info" title="More information about this page">Page information</a></li><li id="t-wikibase"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q245748" title="Structured data on this page hosted by Wikidata [g]" accesskey="g">Wikidata item</a></li><li id="t-cite"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Random_forest&amp;id=966179730&amp;wpFormIdentifier=titleform" title="Information on how to cite this page">Cite this page</a></li></ul>
		
	</div>
</nav>

<!-- Please do not use role attribute as CSS selector, it is deprecated. -->
<nav id="p-coll-print_export" class="vector-menu vector-menu-portal portal" aria-labelledby="p-coll-print_export-label" role="navigation" 
	 >
	<h3 id="p-coll-print_export-label">
		<span>Print/export</span>
	</h3>
	<!-- Please do not use the .body class, it is deprecated. -->
	<div class="body vector-menu-content">
		<!-- Please do not use the .menu class, it is deprecated. -->
		<ul class="vector-menu-content-list"><li id="coll-download-as-rl"><a href="/w/index.php?title=Special:ElectronPdf&amp;page=Random+forest&amp;action=show-download-screen" title="Download this page as a PDF file">Download as PDF</a></li><li id="t-print"><a href="/w/index.php?title=Random_forest&amp;printable=yes" title="Printable version of this page [p]" accesskey="p">Printable version</a></li></ul>
		
	</div>
</nav>


	<!-- Please do not use role attribute as CSS selector, it is deprecated. -->
<nav id="p-lang" class="vector-menu vector-menu-portal portal" aria-labelledby="p-lang-label" role="navigation" 
	 >
	<h3 id="p-lang-label">
		<span>Languages</span>
	</h3>
	<!-- Please do not use the .body class, it is deprecated. -->
	<div class="body vector-menu-content">
		<!-- Please do not use the .menu class, it is deprecated. -->
		<ul class="vector-menu-content-list"><li class="interlanguage-link interwiki-cs"><a href="https://cs.wikipedia.org/wiki/N%C3%A1hodn%C3%BD_les" title="Náhodný les – Czech" lang="cs" hreflang="cs" class="interlanguage-link-target">Čeština</a></li><li class="interlanguage-link interwiki-de"><a href="https://de.wikipedia.org/wiki/Random_Forest" title="Random Forest – German" lang="de" hreflang="de" class="interlanguage-link-target">Deutsch</a></li><li class="interlanguage-link interwiki-et"><a href="https://et.wikipedia.org/wiki/Otsustusmets" title="Otsustusmets – Estonian" lang="et" hreflang="et" class="interlanguage-link-target">Eesti</a></li><li class="interlanguage-link interwiki-es"><a href="https://es.wikipedia.org/wiki/Random_forest" title="Random forest – Spanish" lang="es" hreflang="es" class="interlanguage-link-target">Español</a></li><li class="interlanguage-link interwiki-fa"><a href="https://fa.wikipedia.org/wiki/%D8%AC%D9%86%DA%AF%D9%84_%D8%AA%D8%B5%D8%A7%D8%AF%D9%81%DB%8C" title="جنگل تصادفی – Persian" lang="fa" hreflang="fa" class="interlanguage-link-target">فارسی</a></li><li class="interlanguage-link interwiki-fr"><a href="https://fr.wikipedia.org/wiki/For%C3%AAt_d%27arbres_d%C3%A9cisionnels" title="Forêt d&#039;arbres décisionnels – French" lang="fr" hreflang="fr" class="interlanguage-link-target">Français</a></li><li class="interlanguage-link interwiki-gl"><a href="https://gl.wikipedia.org/wiki/Random_Forest" title="Random Forest – Galician" lang="gl" hreflang="gl" class="interlanguage-link-target">Galego</a></li><li class="interlanguage-link interwiki-ko"><a href="https://ko.wikipedia.org/wiki/%EB%9E%9C%EB%8D%A4_%ED%8F%AC%EB%A0%88%EC%8A%A4%ED%8A%B8" title="랜덤 포레스트 – Korean" lang="ko" hreflang="ko" class="interlanguage-link-target">한국어</a></li><li class="interlanguage-link interwiki-id"><a href="https://id.wikipedia.org/wiki/Random_forest" title="Random forest – Indonesian" lang="id" hreflang="id" class="interlanguage-link-target">Bahasa Indonesia</a></li><li class="interlanguage-link interwiki-it"><a href="https://it.wikipedia.org/wiki/Foresta_casuale" title="Foresta casuale – Italian" lang="it" hreflang="it" class="interlanguage-link-target">Italiano</a></li><li class="interlanguage-link interwiki-ja"><a href="https://ja.wikipedia.org/wiki/%E3%83%A9%E3%83%B3%E3%83%80%E3%83%A0%E3%83%95%E3%82%A9%E3%83%AC%E3%82%B9%E3%83%88" title="ランダムフォレスト – Japanese" lang="ja" hreflang="ja" class="interlanguage-link-target">日本語</a></li><li class="interlanguage-link interwiki-pl"><a href="https://pl.wikipedia.org/wiki/Las_losowy" title="Las losowy – Polish" lang="pl" hreflang="pl" class="interlanguage-link-target">Polski</a></li><li class="interlanguage-link interwiki-ru"><a href="https://ru.wikipedia.org/wiki/Random_forest" title="Random forest – Russian" lang="ru" hreflang="ru" class="interlanguage-link-target">Русский</a></li><li class="interlanguage-link interwiki-simple"><a href="https://simple.wikipedia.org/wiki/Random_forest" title="Random forest – Simple English" lang="en-simple" hreflang="en-simple" class="interlanguage-link-target">Simple English</a></li><li class="interlanguage-link interwiki-tr"><a href="https://tr.wikipedia.org/wiki/Rastgele_orman" title="Rastgele orman – Turkish" lang="tr" hreflang="tr" class="interlanguage-link-target">Türkçe</a></li><li class="interlanguage-link interwiki-uk"><a href="https://uk.wikipedia.org/wiki/Random_forest" title="Random forest – Ukrainian" lang="uk" hreflang="uk" class="interlanguage-link-target">Українська</a></li><li class="interlanguage-link interwiki-zh"><a href="https://zh.wikipedia.org/wiki/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97" title="随机森林 – Chinese" lang="zh" hreflang="zh" class="interlanguage-link-target">中文</a></li></ul>
		<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q245748#sitelinks-wikipedia" title="Edit interlanguage links" class="wbc-editpage">Edit links</a></span></div>
	</div>
</nav>


</div>

</div>

<footer id="footer" class="mw-footer" role="contentinfo" >
	<ul id="footer-info" >
		<li id="footer-info-lastmod"> This page was last edited on 5 July 2020, at 15:21<span class="anonymous-show">&#160;(UTC)</span>.</li>
		<li id="footer-info-copyright">Text is available under the <a rel="license" href="//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License">Creative Commons Attribution-ShareAlike License</a><a rel="license" href="//creativecommons.org/licenses/by-sa/3.0/" style="display:none;"></a>;
additional terms may apply.  By using this site, you agree to the <a href="//foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>
	</ul>
	<ul id="footer-places" >
		<li id="footer-places-privacy"><a href="https://foundation.wikimedia.org/wiki/Privacy_policy" class="extiw" title="wmf:Privacy policy">Privacy policy</a></li>
		<li id="footer-places-about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>
		<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>
		<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>
		<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>
		<li id="footer-places-statslink"><a href="https://stats.wikimedia.org/#/en.wikipedia.org">Statistics</a></li>
		<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Cookie_statement">Cookie statement</a></li>
		<li id="footer-places-mobileview"><a href="//en.m.wikipedia.org/w/index.php?title=Random_forest&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile view</a></li>
	</ul>
	<ul id="footer-icons" class="noprint">
		<li id="footer-copyrightico"><a href="https://wikimediafoundation.org/"><img src="/static/images/wikimedia-button.png" srcset="/static/images/wikimedia-button-1.5x.png 1.5x, /static/images/wikimedia-button-2x.png 2x" width="88" height="31" alt="Wikimedia Foundation" loading="lazy" /></a></li>
		<li id="footer-poweredbyico"><a href="https://www.mediawiki.org/"><img src="/static/images/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="/static/images/poweredby_mediawiki_132x47.png 1.5x, /static/images/poweredby_mediawiki_176x62.png 2x" width="88" height="31" loading="lazy"/></a></li>
	</ul>
	<div style="clear: both;"></div>
</footer>


<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.684","walltime":"1.106","ppvisitednodes":{"value":3590,"limit":1000000},"postexpandincludesize":{"value":118763,"limit":2097152},"templateargumentsize":{"value":2793,"limit":2097152},"expansiondepth":{"value":17,"limit":40},"expensivefunctioncount":{"value":4,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":156491,"limit":5000000},"entityaccesscount":{"value":0,"limit":400},"timingprofile":["100.00%  638.834      1 -total"," 51.45%  328.698      1 Template:Reflist"," 18.10%  115.624      4 Template:Cite_conference"," 14.00%   89.441     21 Template:Cite_journal","  7.16%   45.718      1 Template:Machine_learning_bar","  6.75%   43.102      1 Template:About","  6.67%   42.600      1 Template:Sidebar_with_collapsible_lists","  5.26%   33.620      1 Template:Expand_section","  4.86%   31.075      1 Template:Dead_link","  4.72%   30.141      1 Template:Short_description"]},"scribunto":{"limitreport-timeusage":{"value":"0.253","limit":"10.000"},"limitreport-memusage":{"value":6414640,"limit":52428800}},"cachereport":{"origin":"mw1390","timestamp":"20200705152122","ttl":2592000,"transientcontent":false}}});});</script>
<script type="application/ld+json">{"@context":"https:\/\/schema.org","@type":"Article","name":"Random forest","url":"https:\/\/en.wikipedia.org\/wiki\/Random_forest","sameAs":"http:\/\/www.wikidata.org\/entity\/Q245748","mainEntity":"http:\/\/www.wikidata.org\/entity\/Q245748","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\/\/www.wikimedia.org\/static\/images\/wmf-hor-googpub.png"}},"datePublished":"2005-01-05T04:27:10Z","dateModified":"2020-07-05T15:21:18Z","headline":"statistical algorithm that is used to cluster points of data in functional groups"}</script>
<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":147,"wgHostname":"mw1321"});});</script></body></html>
