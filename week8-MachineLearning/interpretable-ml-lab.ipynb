{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T15:10:53.228989Z",
     "start_time": "2020-08-05T15:10:53.176125Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0090be0be85f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mshap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mshap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitjs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import sklearn\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-08-05T18:24:20.340Z"
    }
   },
   "outputs": [],
   "source": [
    "pip install shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the adults dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shap.datasets.adult()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature | Description\n",
    "-------|----------\n",
    "`target`| >50K, <=50K.\n",
    "`age` | continuous.\n",
    "`workclass` | Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "`fnlwgt` |continuous.\n",
    "`education` | Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "`education-num` | continuous.\n",
    "`marital-status` | Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "`occupation` | Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "`relationship` | Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "`race`| White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "`sex`| Female, Male.\n",
    "`capital-gain` | continuous.\n",
    "`capital-loss` | continuous.\n",
    "`hours-per-week` | continuous.\n",
    "`native-country` | United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adults dataset contains information about the population of the United States. We'll try to understand which factors have more impact on predicting whether someone earns more than $50k money or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, you need to use the `train_test_split` to generate a test-dataset containing 20% of the public.\n",
    "\n",
    "\n",
    "This will be helpful to hide some part of your dataset for future evaluation. You want to obtain your scores on this test dataset so as to better simulate the real world data that will come for you to predict in future. \n",
    "\n",
    "Use `from sklearn.model_selection import train_test_split` to obtain your train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a complex model to predict whether someone earns more than $50k\n",
    "\n",
    "Usually, when we are interested in interpretability, we have to rely on simple Machine Learning models like LogisticRegression or DecisionTrees. However, they usually have a lower performance as compared to more complex models. Complex models, however, lack of interpretability. That's where SHAP comes to the rescue.\n",
    "\n",
    "\n",
    "For this example, we'll use one of the most common, but also most complex models in Machine Learning. It is called Lightgbm and it is a complex model based on DecisionTrees. Under the hood, it also performs lots of optimizations to enhance speed and accuracy of your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After installing `lightgbm` (`!pip install lightgbm`) on your machine, you'll be able to use the command `from lightgbm import LGBMClassifier` you'll be able to import the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the model, use it to fit in your training data. You may use the default parameters of the LGBMClassifier for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We want to predict a single row of our dataset and understand why the model chose for that prediction.\n",
    "\n",
    "Select a single row of your test dataset. You may use either a sampling method (for example, `X_test.sample(1)`) to randomly select an observation or you can specify the index of the row (for example, `X_test.iloc[[10],:]` to get the 10th index). The resulting row shall be in the format of a dataframe in this example.\n",
    "\n",
    "Store the result in a variable called `single_row`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_row = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use your model to predict the probabilities that the observation earns more than $50k\n",
    "\n",
    "Using your `model` you have fitted above, use the method `predict_proba` on the observation you stored in the variable `single_row`.\n",
    "\n",
    "_Hint: Try to pick an observation that does not have too high probabilities (like ~0.99) for example. This will increase your understanding when using the `force_plot` below._ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How probable it is for the observation to earn more than $50k. \n",
    "\n",
    "Using a threshold of 50%, would the model decide that this observation received more than $50k a year or not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the TreeExplainer to start explaining the model\n",
    "\n",
    "Shap has a specific class to handle complex models based on trees (namely lightgbm, xgboost and catboost). It is called TreeExplainer. If you have imported the package `shap`, you'll be able to call it via `shap.TreeExplainer()`.\n",
    "\n",
    "The arguments the TreeExplainer expects are the model you are using (in this case, the variable you used stored and fitted the LGBMClassifier) and the training dataset you have used. \n",
    "\n",
    "The results of the shap.TreeExplainer is what is called an `explainer`. You'll use this object to explain the results in near future. Store it in a variable called `explainer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explainer = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the SHAP values for the observation you've selected.\n",
    "\n",
    "Using the SHAP package, you'll be able to calculate the feature importances using your `explainer`. \n",
    "\n",
    "Behind the scenes, it used `Game Theory` to observe how each feature is contributing to the score of the model. Use the method `explainer.shap_values` from your explainer to get these values of importance. As argument, you need to specify the observations you want to explain. For our case, we'll use the `single_row` created above for now. \n",
    "\n",
    "Store it in a variable called `values`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** For 1 single observation, this calculation is pretty fast. However, if you had more data, this computation would take forever. We'll see in the future how to overcome this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the prediction\n",
    "\n",
    "SHAP has a visualization that helps you understand why the model took that decision. It is called `force_plot` because it simulates a (reversed) `tug of war` (cabo de guerra) in which each feature is pulling the chances of the event (in this case, the chances of earning more than $50k a year) of happening. \n",
    "\n",
    "The `force_plot` also used an argument named `base_value` which is the bias of your dataset. That is, the average of your predictions if for example you had no extra information. The features then start to pull and push the value of this `base_value` up or down.\n",
    "\n",
    "The `red features` are the ones that increases the chance of the observation of earning more than $50k, while the `blue features` do the opposite. The size of the bar indicates how strongly that feature contributes to that decision.\n",
    "\n",
    "\n",
    "Use the `shap.force_plot` explaining method to explore why the model decided for that decision. You'll be able to get the `base_value` via the attribute `explainer.expected_value`. It also requires the shapley values you calculated above (stored at `values`) and, finally, if you want to make the plot clearer, you can pass the observation as the argument `features` (`features = single_row` in our case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to explain why the model took the decision you observed before. Remember to use the variables description for that. (Unfortunately, the dataset description is a little bit messy, but try your best =) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok. So far we've understood a single observation. It would be useful if we could understand the decisions as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the shap values for your whole test set!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, we are able to calculate the Shapley values for the whole test dataset! We just have to repeat our process of estimating the Shapley values (via the `explainer.shap_values` method), but this time we need to pass the whole test dataset. \n",
    "\n",
    "**HOWEVER**, if you want to use the pure `shap_values` method, it will try to calculate the exact values and will take too long. If you want to speed up the process, you can calculate an approximation of those values. You just have to pass the argument `approximate=True` (try without it as well if you want to see how long it takes).\n",
    "\n",
    "Store it in a variable called `values_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# values_test = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A new way to visualize the `force_plot`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you use the `force_plot` this time, you'll see a different visualization! Try specifying again, the `explainer.expected_value` (which is the base_value), the `values_test` above and your `test dataset`.\n",
    "\n",
    "**Note**: If your computer slows down too much right now, you may need to select a subsample of your values_test and X_test, for instance by doing a slicing: `... , values_test[0:1000], X_test[0:1000]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot contains a series of `force_plot` for each row. But this time those bars are in the vertical direction. As you move horizontally, though, you are checking each observation of your dataset. This graph is interactive and you can select each row to see the important features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another way to see the information above.\n",
    "\n",
    "The `shap.decision_plot` is a method that tells you almost the same information as above, but with a different perspective. \n",
    "\n",
    "This method creates a plot such that each observation starts from the `base_value` (i.e, as if the observation had no information at all) and as you gather information about that observation, it directs it to its final result. You have to read this graph from botton up. At the botton, all observations collapse at the `base_value` and as you add variables (the first variables you add are the least important ones), the line shows the effect on the chances of the event (in our case, the effect on the chances of earning more than $50k)\n",
    "\n",
    "\n",
    "Plot a `shap.decision_plot` of your test dataset. It requires the same arguments as the `force_plot`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For this first test, let's only plot the single_row example as before. Use the `single_row` and the variable `values`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now select the first 10 rows of the dataset to plot the same graph.\n",
    "\n",
    "You can do that using `values_test[0:10], X_test[0:10]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Highlighting \n",
    "\n",
    "You can also highlight some observations. For example, if you want to highlight the first observation of your dataset, you can specify its index for the argument `highlight` of the `decision_plot`. The `dashed` lines will be the highlighted observations.\n",
    "\n",
    "Plot the `decision_plot` for those same 10 rows of your test data highlighting the observation which has the `index=5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding decisions as a whole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to increase our understanding of the decisions, we can use the `shap.summary_plot`.\n",
    "\n",
    "Specify as arguments to the `shap.summary_plot` the `values_test` and your test dataset to plot a summary of the feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each variable, you can observe how their value affects the predictions. `Blue` points are points in which the feature has a low value. `Red` values are points in which the feature has a high value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_hint: You can use the argument_ `plot_type = 'violin'` _to see the effects._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial Dependence Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The partial dependence plot is used to understand the impact of changing each feature. \n",
    "\n",
    "This plot fixes all other variables and varies the variable you choose on the x-direction. In the y-direction, the plot shows the probability (to be precise, the odds) of the event occurring (i.e, in our case, the odds of earning >= $50k).\n",
    "\n",
    "The color on the plot is related to the interactions of the variable you chose to understand with another variable. By default, it uses the variable in which it sees it has the most correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the effect of Age\n",
    "\n",
    "Use the `shap.dependence_plot` to understand how changing the variable `Age` affects the output of the model.\n",
    "The `dependence_plot` method receives as arguments the name of the variable, the shap values (you stored in `values_test` for example) and the dataset (in our case, your `test dataset, X_test`). For this first example, also specify the argument `interaction_index=None` to remove the color by now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you infer from the graph? How changes in `Age` affects the probabilities of earning more than $50k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substitute `interaction_index=None` by `interaction_index='Education-Num'` to see the interactions between Age and Education. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you interpret the graph? For smaller Ages, what values of Education have higher probabilities of earning > $50k? \n",
    "\n",
    "And what about as you increase the Age? For higher Ages, what values of Education are more likely to earn > $50k?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the argument `interaction_index` from the argument list of the `dependence_plot` to let SHAP decide which feature have the most interactions with the Age variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BONUS:  Check misclassifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A practical application of shap values is that they are usefull for understanding where your' models are performing `poorly`. We'll select the observations that our models guessed wrong and try to understand why it did it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting observations the model guessed wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `model` you created before, you can predict the results for your test dataset.\n",
    "\n",
    "Use the `model.predict()` method on your test data and store the results on a variable called `y_pred`. You'll be able to compare the predictions on `y_pred` with your actual values stored in `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing results\n",
    "\n",
    "Create a mask of comparison between `y_pred` and `y_test`. Test whether they are different. It should be an array containing `True` if your model incorrectly predicted the result and `False` if it did right.\n",
    "\n",
    "Store it in a variable called `misclassifications`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a dataset of your misclassifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new dataset called `X_misclassifications` containing the observations of your `X_test` in which you incorrectly classified the result (i.e., in which the variable `misclassifications` is `True`).\n",
    "\n",
    "You can obtain that dataset by filtering the `X_test` dataset using the variable `misclassifications`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the `force_plot` and the `decision_plot` to understand the wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
